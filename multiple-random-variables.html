<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.7 Multiple random variables | SM-4331 Advanced Statistics</title>
  <meta name="description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="1.7 Multiple random variables | SM-4331 Advanced Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.7 Multiple random variables | SM-4331 Advanced Statistics" />
  
  <meta name="twitter:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

<meta name="author" content="Dr Haziq Jamil" />


<meta name="date" content="2022-01-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="transformations.html"/>
<link rel="next" href="expectations.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="mystyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SM-4331 Advanced Statistics</a></li>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {extensions: ["cancel.js"]}
});
</script>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="" data-path="what-is-statistics.html"><a href="what-is-statistics.html"><i class="fa fa-check"></i>What is statistics?</a>
<ul>
<li class="chapter" data-level="" data-path="learning-statistics.html"><a href="learning-statistics.html"><i class="fa fa-check"></i>Learning statistics</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html"><i class="fa fa-check"></i>Population, sample and parametric models</a>
<ul>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#population-vs-sample"><i class="fa fa-check"></i>Population vs sample</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#parametric-models"><i class="fa fa-check"></i>Parametric models</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#a-sample-a-set-of-data-or-random-variablesa-duality"><i class="fa fa-check"></i>A sample: a set of data or random variables?–A duality</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#variability-of-estimates"><i class="fa fa-check"></i>Variability of estimates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-and-statistics.html"><a href="probability-and-statistics.html"><i class="fa fa-check"></i>Probability and statistics</a></li>
</ul></li>
<li class="part"><span><b>II Prepare</b></span></li>
<li class="chapter" data-level="1" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html"><i class="fa fa-check"></i><b>1</b> Probability theory primer</a>
<ul>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#readings"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html"><i class="fa fa-check"></i><b>1.1</b> Elementary set theory</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#set-operations"><i class="fa fa-check"></i><b>1.1.1</b> Set operations</a></li>
<li class="chapter" data-level="1.1.2" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#partitions"><i class="fa fa-check"></i><b>1.1.2</b> Partitions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html"><i class="fa fa-check"></i><b>1.2</b> Axiomatic probability</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#probability-as-a-measure"><i class="fa fa-check"></i><b>1.2.1</b> Probability as a measure</a></li>
<li class="chapter" data-level="1.2.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>1.2.2</b> Axioms of probability</a></li>
<li class="chapter" data-level="1.2.3" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#derived-probability-results"><i class="fa fa-check"></i><b>1.2.3</b> Derived probability results</a></li>
<li class="chapter" data-level="1.2.4" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#why-measure-theory"><i class="fa fa-check"></i><b>1.2.4</b> Why measure theory?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html"><i class="fa fa-check"></i><b>1.3</b> Conditioning and independence</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#bayes-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Bayes Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#independence"><i class="fa fa-check"></i><b>1.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>1.4</b> Random variables</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="random-variables.html"><a href="random-variables.html#distribution-functions"><i class="fa fa-check"></i><b>1.4.1</b> Distribution functions</a></li>
<li class="chapter" data-level="1.4.2" data-path="random-variables.html"><a href="random-variables.html#identically-distributed-r.v."><i class="fa fa-check"></i><b>1.4.2</b> Identically distributed r.v.</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-functions.html"><a href="probability-functions.html"><i class="fa fa-check"></i><b>1.5</b> Probability functions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probability-functions.html"><a href="probability-functions.html#probability-mass-function"><i class="fa fa-check"></i><b>1.5.1</b> Probability mass function</a></li>
<li class="chapter" data-level="1.5.2" data-path="probability-functions.html"><a href="probability-functions.html#probability-density-functions"><i class="fa fa-check"></i><b>1.5.2</b> Probability density functions</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>1.6</b> Transformations</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="transformations.html"><a href="transformations.html#probability-integral-transform"><i class="fa fa-check"></i><b>1.6.1</b> Probability integral transform</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html"><i class="fa fa-check"></i><b>1.7</b> Multiple random variables</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#bivariate-distributions"><i class="fa fa-check"></i><b>1.7.1</b> Bivariate distributions</a></li>
<li class="chapter" data-level="1.7.2" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#marginal-distributions"><i class="fa fa-check"></i><b>1.7.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="1.7.3" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#conditional-distributions"><i class="fa fa-check"></i><b>1.7.3</b> Conditional distributions</a></li>
<li class="chapter" data-level="1.7.4" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>1.7.4</b> Independent random variables</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="expectations.html"><a href="expectations.html"><i class="fa fa-check"></i><b>1.8</b> Expectations</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="expectations.html"><a href="expectations.html#expectations-of-functions-of-r.v."><i class="fa fa-check"></i><b>1.8.1</b> Expectations of functions of r.v.</a></li>
<li class="chapter" data-level="1.8.2" data-path="expectations.html"><a href="expectations.html#properties-of-expectations"><i class="fa fa-check"></i><b>1.8.2</b> Properties of expectations</a></li>
<li class="chapter" data-level="1.8.3" data-path="expectations.html"><a href="expectations.html#variance"><i class="fa fa-check"></i><b>1.8.3</b> Variance</a></li>
<li class="chapter" data-level="1.8.4" data-path="expectations.html"><a href="expectations.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.8.4</b> Covariance and correlation</a></li>
<li class="chapter" data-level="1.8.5" data-path="expectations.html"><a href="expectations.html#properties-of-variances-and-covariances"><i class="fa fa-check"></i><b>1.8.5</b> Properties of variances and covariances</a></li>
<li class="chapter" data-level="1.8.6" data-path="expectations.html"><a href="expectations.html#multivariate-means-and-covariances"><i class="fa fa-check"></i><b>1.8.6</b> Multivariate means and covariances</a></li>
<li class="chapter" data-level="1.8.7" data-path="expectations.html"><a href="expectations.html#conditional-expectations-and-variance"><i class="fa fa-check"></i><b>1.8.7</b> Conditional expectations and variance</a></li>
<li class="chapter" data-level="1.8.8" data-path="expectations.html"><a href="expectations.html#additional-explainers"><i class="fa fa-check"></i><b>1.8.8</b> Additional explainers</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html"><i class="fa fa-check"></i><b>1.9</b> Moment generating functions</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#moment-generating-functions-1"><i class="fa fa-check"></i><b>1.9.1</b> Moment generating functions</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.10</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#hand-in-questions"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html"><i class="fa fa-check"></i><b>2</b> Commonly-used probability models</a>
<ul>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#learning-objectives-1"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#readings-1"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="2.1" data-path="discrete-models.html"><a href="discrete-models.html"><i class="fa fa-check"></i><b>2.1</b> Discrete models</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="discrete-models.html"><a href="discrete-models.html#point-mass-distribution"><i class="fa fa-check"></i><b>2.1.1</b> Point mass distribution</a></li>
<li class="chapter" data-level="2.1.2" data-path="discrete-models.html"><a href="discrete-models.html#uniform-distribution"><i class="fa fa-check"></i><b>2.1.2</b> Uniform distribution</a></li>
<li class="chapter" data-level="2.1.3" data-path="discrete-models.html"><a href="discrete-models.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.1.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.1.4" data-path="discrete-models.html"><a href="discrete-models.html#binomial-distribution"><i class="fa fa-check"></i><b>2.1.4</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.1.5" data-path="discrete-models.html"><a href="discrete-models.html#geometric-distribution"><i class="fa fa-check"></i><b>2.1.5</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.1.6" data-path="discrete-models.html"><a href="discrete-models.html#negative-binomial"><i class="fa fa-check"></i><b>2.1.6</b> Negative binomial</a></li>
<li class="chapter" data-level="2.1.7" data-path="discrete-models.html"><a href="discrete-models.html#poisson-distribution"><i class="fa fa-check"></i><b>2.1.7</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continuous-models.html"><a href="continuous-models.html"><i class="fa fa-check"></i><b>2.2</b> Continuous models</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="continuous-models.html"><a href="continuous-models.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>2.2.1</b> Continuous uniform distribution</a></li>
<li class="chapter" data-level="2.2.2" data-path="continuous-models.html"><a href="continuous-models.html#exponential-distribution"><i class="fa fa-check"></i><b>2.2.2</b> Exponential distribution</a></li>
<li class="chapter" data-level="2.2.3" data-path="continuous-models.html"><a href="continuous-models.html#gamma-distribution"><i class="fa fa-check"></i><b>2.2.3</b> Gamma distribution</a></li>
<li class="chapter" data-level="2.2.4" data-path="continuous-models.html"><a href="continuous-models.html#beta-distribution"><i class="fa fa-check"></i><b>2.2.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="normal-distribution.html"><a href="normal-distribution.html#location-and-scale-parameter"><i class="fa fa-check"></i><b>2.3.1</b> Location and scale parameter</a></li>
<li class="chapter" data-level="2.3.2" data-path="normal-distribution.html"><a href="normal-distribution.html#linear-transformations-of-normal-random-variables"><i class="fa fa-check"></i><b>2.3.2</b> Linear transformations of normal random variables</a></li>
<li class="chapter" data-level="2.3.3" data-path="normal-distribution.html"><a href="normal-distribution.html#the-normal-cdf"><i class="fa fa-check"></i><b>2.3.3</b> The normal cdf</a></li>
<li class="chapter" data-level="2.3.4" data-path="normal-distribution.html"><a href="normal-distribution.html#rule"><i class="fa fa-check"></i><b>2.3.4</b> 68–95–99.7 Rule</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="some-relationships.html"><a href="some-relationships.html"><i class="fa fa-check"></i><b>2.4</b> Some relationships</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="some-relationships.html"><a href="some-relationships.html#poisson-binomial-relationship"><i class="fa fa-check"></i><b>2.4.1</b> Poisson-Binomial relationship</a></li>
<li class="chapter" data-level="2.4.2" data-path="some-relationships.html"><a href="some-relationships.html#poisson-exponential"><i class="fa fa-check"></i><b>2.4.2</b> Poisson-Exponential</a></li>
<li class="chapter" data-level="2.4.3" data-path="some-relationships.html"><a href="some-relationships.html#poisson-gamma"><i class="fa fa-check"></i><b>2.4.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="2.4.4" data-path="some-relationships.html"><a href="some-relationships.html#normal-approximations"><i class="fa fa-check"></i><b>2.4.4</b> Normal approximations</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#hand-in-questions-1"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html"><i class="fa fa-check"></i><b>3</b> Inequalities, convergences, and normal random samples</a>
<ul>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#readings-2"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#independent-and-identical-random-variable"><i class="fa fa-check"></i><b>3.1.1</b> Independent and identical random variable</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#statistic"><i class="fa fa-check"></i><b>3.1.2</b> Statistic</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Sampling distribution</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#large-sample-approximation"><i class="fa fa-check"></i><b>3.1.4</b> Large-sample approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>3.2</b> Inequalities</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inequalities.html"><a href="inequalities.html#markovs-inequality"><i class="fa fa-check"></i><b>3.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="3.2.2" data-path="inequalities.html"><a href="inequalities.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>3.2.2</b> Chebyshev’s inequality</a></li>
<li class="chapter" data-level="3.2.3" data-path="inequalities.html"><a href="inequalities.html#cauchy-schwartz-inequality"><i class="fa fa-check"></i><b>3.2.3</b> Cauchy-Schwartz inequality</a></li>
<li class="chapter" data-level="3.2.4" data-path="inequalities.html"><a href="inequalities.html#jensens-inequality"><i class="fa fa-check"></i><b>3.2.4</b> Jensen’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html"><i class="fa fa-check"></i><b>3.3</b> Convergence of random variables</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.3.1</b> Convergence in probability</a></li>
<li class="chapter" data-level="3.3.2" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Convergence in distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#mean-square-convergence"><i class="fa fa-check"></i><b>3.3.3</b> Mean-square convergence</a></li>
<li class="chapter" data-level="3.3.4" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#relationship-between-convergences"><i class="fa fa-check"></i><b>3.3.4</b> Relationship between convergences</a></li>
<li class="chapter" data-level="3.3.5" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#slutzkys-theorem"><i class="fa fa-check"></i><b>3.3.5</b> Slutzky’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>3.4</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="limit-theorems.html"><a href="limit-theorems.html#the-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>3.4.1</b> The (weak) Law of Large Numbers</a></li>
<li class="chapter" data-level="3.4.2" data-path="limit-theorems.html"><a href="limit-theorems.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="3.4.3" data-path="limit-theorems.html"><a href="limit-theorems.html#gauging-the-error-of-sample-mean-estimator"><i class="fa fa-check"></i><b>3.4.3</b> Gauging the error of sample mean estimator</a></li>
<li class="chapter" data-level="3.4.4" data-path="limit-theorems.html"><a href="limit-theorems.html#clt-with-sigma2-unknown"><i class="fa fa-check"></i><b>3.4.4</b> CLT with <span class="math inline">\(\sigma^2\)</span> unknown</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>3.5</b> Delta method</a></li>
<li class="chapter" data-level="3.6" data-path="normal-random-samples.html"><a href="normal-random-samples.html"><i class="fa fa-check"></i><b>3.6</b> Normal random samples</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="normal-random-samples.html"><a href="normal-random-samples.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6.1</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.2" data-path="normal-random-samples.html"><a href="normal-random-samples.html#students-t-distribution"><i class="fa fa-check"></i><b>3.6.2</b> Student’s <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.3" data-path="normal-random-samples.html"><a href="normal-random-samples.html#proof-of-theorem-refthmpropertynormalsamp"><i class="fa fa-check"></i><b>3.6.3</b> Proof of Theorem @ref(thm:propertynormalsamp)</a></li>
<li class="chapter" data-level="3.6.4" data-path="normal-random-samples.html"><a href="normal-random-samples.html#f-distribution"><i class="fa fa-check"></i><b>3.6.4</b> <span class="math inline">\(F\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.5" data-path="normal-random-samples.html"><a href="normal-random-samples.html#the-analysis-of-variance"><i class="fa fa-check"></i><b>3.6.5</b> The analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#hand-in-questions-2"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Inference</b></span></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#readings-3"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="4.1" data-path="the-likelihood.html"><a href="the-likelihood.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="the-likelihood.html"><a href="the-likelihood.html#calculating-the-likelihood"><i class="fa fa-check"></i><b>4.1.1</b> Calculating the likelihood</a></li>
<li class="chapter" data-level="4.1.2" data-path="the-likelihood.html"><a href="the-likelihood.html#likelihood-ratio"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood ratio</a></li>
<li class="chapter" data-level="4.1.3" data-path="the-likelihood.html"><a href="the-likelihood.html#log-likelihood"><i class="fa fa-check"></i><b>4.1.3</b> Log likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sufficiency.html"><a href="sufficiency.html"><i class="fa fa-check"></i><b>4.2</b> Sufficiency</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sufficiency.html"><a href="sufficiency.html#the-factorisation-theorem"><i class="fa fa-check"></i><b>4.2.1</b> The factorisation theorem</a></li>
<li class="chapter" data-level="4.2.2" data-path="sufficiency.html"><a href="sufficiency.html#minimal-sufficient-statistic"><i class="fa fa-check"></i><b>4.2.2</b> Minimal sufficient statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="point-estimators.html"><a href="point-estimators.html"><i class="fa fa-check"></i><b>4.3</b> Point estimators</a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>4.4</b> Method of moments</a></li>
<li class="chapter" data-level="4.5" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>4.5</b> Method of maximum likelihood</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#finding-the-mle"><i class="fa fa-check"></i><b>4.5.1</b> Finding the MLE</a></li>
<li class="chapter" data-level="4.5.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#invariance-of-mle"><i class="fa fa-check"></i><b>4.5.2</b> Invariance of MLE</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html"><i class="fa fa-check"></i><b>4.6</b> Evaluating estimators</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#bias"><i class="fa fa-check"></i><b>4.6.1</b> Bias</a></li>
<li class="chapter" data-level="4.6.2" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#variance-and-standard-error"><i class="fa fa-check"></i><b>4.6.2</b> Variance and standard error</a></li>
<li class="chapter" data-level="4.6.3" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>4.6.3</b> Mean squared error</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html"><i class="fa fa-check"></i><b>4.7</b> Cramér-Rao lower bound (CRLB)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#fisher-information"><i class="fa fa-check"></i><b>4.7.1</b> Fisher information</a></li>
<li class="chapter" data-level="4.7.2" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#variance-reduction-rao-blackwellisation"><i class="fa fa-check"></i><b>4.7.2</b> Variance reduction: Rao-Blackwellisation</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html"><i class="fa fa-check"></i><b>4.8</b> Large sample properties of estimators</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency"><i class="fa fa-check"></i><b>4.8.1</b> Consistency</a></li>
<li class="chapter" data-level="4.8.2" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-vs-unbiasedness"><i class="fa fa-check"></i><b>4.8.2</b> Consistency vs unbiasedness</a></li>
<li class="chapter" data-level="4.8.3" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-of-mles"><i class="fa fa-check"></i><b>4.8.3</b> Consistency of MLEs</a></li>
<li class="chapter" data-level="4.8.4" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency"><i class="fa fa-check"></i><b>4.8.4</b> Efficiency</a></li>
<li class="chapter" data-level="4.8.5" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#asymptotic-normality-and-consistency"><i class="fa fa-check"></i><b>4.8.5</b> Asymptotic normality and consistency</a></li>
<li class="chapter" data-level="4.8.6" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-mle"><i class="fa fa-check"></i><b>4.8.6</b> Efficiency of MLE</a></li>
<li class="chapter" data-level="4.8.7" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-transformations-of-mle"><i class="fa fa-check"></i><b>4.8.7</b> Efficiency of transformations of MLE</a></li>
<li class="chapter" data-level="4.8.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#application-of-asymptotic-normality"><i class="fa fa-check"></i><b>4.8.8</b> Application of asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-3.html"><a href="exercises-3.html#hand-in-questions-3"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#readings-4"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="5.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-1.html"><a href="introduction-1.html#a-general-paradigm"><i class="fa fa-check"></i><b>5.1.1</b> A general paradigm</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-1.html"><a href="introduction-1.html#p-values"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-1.html"><a href="introduction-1.html#accept-h_0"><i class="fa fa-check"></i><b>5.1.3</b> Accept <span class="math inline">\(H_0\)</span>?</a></li>
<li class="chapter" data-level="5.1.4" data-path="introduction-1.html"><a href="introduction-1.html#uniformity-of-p-values"><i class="fa fa-check"></i><b>5.1.4</b> Uniformity of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>5.2</b> Likelihood ratio test</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#log-likelihood-ratio-test-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Log likelihood ratio test statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.2</b> Example: Normal with known variance</a></li>
<li class="chapter" data-level="5.2.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-unknown-variance-t-test"><i class="fa fa-check"></i><b>5.2.3</b> Example: Normal with unknown variance (<span class="math inline">\(t\)</span>-test)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html"><i class="fa fa-check"></i><b>5.3</b> The Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#performance-of-a-test"><i class="fa fa-check"></i><b>5.3.1</b> Performance of a test</a></li>
<li class="chapter" data-level="5.3.2" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#relation-to-p-values"><i class="fa fa-check"></i><b>5.3.2</b> Relation to <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html"><i class="fa fa-check"></i><b>5.4</b> Type I and II errors</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#minimising-errors"><i class="fa fa-check"></i><b>5.4.1</b> Minimising errors</a></li>
<li class="chapter" data-level="5.4.2" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#optimality-of-the-lr-test"><i class="fa fa-check"></i><b>5.4.2</b> Optimality of the LR test</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sided-tests.html"><a href="one-sided-tests.html"><i class="fa fa-check"></i><b>5.5</b> One-sided tests</a></li>
<li class="chapter" data-level="5.6" data-path="approximate-tests.html"><a href="approximate-tests.html"><i class="fa fa-check"></i><b>5.6</b> Approximate tests</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="approximate-tests.html"><a href="approximate-tests.html#asymptotic-distribution-of-lrts"><i class="fa fa-check"></i><b>5.6.1</b> Asymptotic distribution of LRTs</a></li>
<li class="chapter" data-level="5.6.2" data-path="approximate-tests.html"><a href="approximate-tests.html#wilks-theorem"><i class="fa fa-check"></i><b>5.6.2</b> Wilk’s theorem</a></li>
<li class="chapter" data-level="5.6.3" data-path="approximate-tests.html"><a href="approximate-tests.html#the-wald-test"><i class="fa fa-check"></i><b>5.6.3</b> The Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-4.html"><a href="exercises-4.html#hand-in-questions-4"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>6</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#readings-5"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="6.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-2.html"><a href="introduction-2.html#coverage-probability"><i class="fa fa-check"></i><b>6.1.1</b> Coverage probability</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-2.html"><a href="introduction-2.html#confidence-regions"><i class="fa fa-check"></i><b>6.1.2</b> Confidence regions</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-2.html"><a href="introduction-2.html#methods-for-obtaining-confidence-regions"><i class="fa fa-check"></i><b>6.1.3</b> Methods for obtaining confidence regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pivots.html"><a href="pivots.html"><i class="fa fa-check"></i><b>6.2</b> Pivots</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pivots.html"><a href="pivots.html#from-pivot-to-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> From pivot to confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Inverting a test statistic</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html#discrete-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Discrete distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="desirable-confidence-sets.html"><a href="desirable-confidence-sets.html"><i class="fa fa-check"></i><b>6.4</b> Desirable confidence sets</a></li>
<li class="chapter" data-level="6.5" data-path="intervals-based-on-ml-methods.html"><a href="intervals-based-on-ml-methods.html"><i class="fa fa-check"></i><b>6.5</b> Intervals based on ML methods</a></li>
<li class="chapter" data-level="6.6" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>6.6</b> The bootstrap method</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#empirical-distribution"><i class="fa fa-check"></i><b>6.6.1</b> Empirical distribution</a></li>
<li class="chapter" data-level="6.6.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-variance-estimation"><i class="fa fa-check"></i><b>6.6.2</b> Bootstrap variance estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap confidence intervals</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#normal-bootstrap-interval"><i class="fa fa-check"></i><b>6.7.1</b> Normal bootstrap interval</a></li>
<li class="chapter" data-level="6.7.2" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-percentile-interval"><i class="fa fa-check"></i><b>6.7.2</b> Bootstrap percentile interval</a></li>
<li class="chapter" data-level="6.7.3" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-pivotal-interval"><i class="fa fa-check"></i><b>6.7.3</b> Bootstrap pivotal interval</a></li>
<li class="chapter" data-level="6.7.4" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#which-one-to-use"><i class="fa fa-check"></i><b>6.7.4</b> Which one to use?</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-5.html"><a href="exercises-5.html#hand-in-questions-5"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="exam-tips.html"><a href="exam-tips.html"><i class="fa fa-check"></i><b>A</b> Exam tips</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SM-4331 Advanced Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-random-variables" class="section level2" number="1.7">
<h2><span class="header-section-number">1.7</span> Multiple random variables</h2>
<p>In the real world, data collection often involves more than one variable, so methods to analyse these kinds of data do exist.
In particular, probability models may well be extended to involve more than one random variable.
These are known as <em>multivariate models</em>.</p>
<div id="bivariate-distributions" class="section level3" number="1.7.1">
<h3><span class="header-section-number">1.7.1</span> Bivariate distributions</h3>
<p>Consider the simplest kind, where we deal with only two random variables in each the discrete and continuous case.</p>
<div class="definition">
<p><span id="def:unlabeled-div-36" class="definition"><strong>Definition 1.11  (Joint mass function) </strong></span>Given a pair of discrete r.v. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the joint mass function or joint pmf is defined by
<span class="math display">\[
f_{X,Y}(x,y) = \mathbb{P}(X=x,Y=y).
\]</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-37" class="definition"><strong>Definition 1.12  (Joint density function) </strong></span>A function <span class="math inline">\(f_{X,Y}:\mathbb{R}^2\to\mathbb{R}\)</span> is called a joint probability density function (pdf) of the continuous random vector <span class="math inline">\((X,Y)\)</span> if for any set <span class="math inline">\(A\subseteq\mathbb{R}^2\)</span>,
<span class="math display">\[
  \mathbb{P}((X,Y) \in A) = \iint_{A} f_{X,Y}(x,y)\mathop{\mathrm{d}}\hspace{0.5pt}\!x \mathop{\mathrm{d}}\hspace{0.5pt}\!y.
\]</span></p>
</div>
<p>To be clear, bivariate random variables occur in <strong>pairs</strong>, so that <span class="math inline">\((X,Y)\)</span> is treated as one entity.
Luckily, all the univariate properties carry over to the bivariate (and even multivariate) case, such as:</p>
<ul>
<li><span class="math inline">\(f_{X,Y}(x,y) \geq 0\)</span> for all <span class="math inline">\((x,y) \in \mathbb{R}^2\)</span></li>
<li><span class="math inline">\(\sum_x\sum_y f(x,y) = 1\)</span> if discrete, <span class="math inline">\(\iint f(x,y)\mathop{\mathrm{d}}\hspace{0.5pt}\!x \mathop{\mathrm{d}}\hspace{0.5pt}\!y = 1\)</span> if continuous</li>
<li>The joint cdf is defined as
<span class="math display">\[\begin{align*}
F_{X,Y}(x,y) &amp;=  \mathbb{P}(X\leq x, Y\leq y) \\
&amp;= \begin{cases}
\sum_{u\leq x}\sum_{v\leq x} f_{X,Y}(u,v) &amp;\text{discrete case} \\
\int_{u\leq x}\int_{v\leq x} f_{X,Y}(u,v) \mathop{\mathrm{d}}\hspace{0.5pt}\!u \mathop{\mathrm{d}}\hspace{0.5pt}\!v &amp;\text{continuous case} \\
\end{cases}
\end{align*}\]</span></li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-38" class="example"><strong>Example 1.20  </strong></span>A bivariate distribution for two discrete random variable <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> each taking values 0 or 1 can be summarised in the <span class="math inline">\(2\times 2\)</span> table below.</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th align="center"><span class="math inline">\(Y=0\)</span></th>
<th align="center"><span class="math inline">\(Y=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><span class="math inline">\(X=0\)</span></td>
<td align="center">1/9</td>
<td align="center">2/9</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(X=1\)</span></td>
<td align="center">2/9</td>
<td align="center">4/9</td>
</tr>
</tbody>
</table>
<p>For instance, <span class="math inline">\(\mathbb{P}(X=1,Y=1) = f(1,1) = 4/9\)</span>.</p>
<p>A different way of expressing the above table is by explicitly listing out the probabilities, as follows:
<span class="math display">\[
f(x,y) = \begin{cases}
1/9 &amp; x=0,y=0 \\
2/9 &amp; x=0,y=1 \\
2/9 &amp; x=1,y=0 \\
4/9 &amp; x=1,y=1 \\
\end{cases}
\]</span></p>
</div>
<div class="example">
<p><span id="exm:unitsquare" class="example"><strong>Example 1.21  </strong></span>Consider a uniform distribution on the unit square <span class="math inline">\([0,1] \times [0,1]\)</span>. It has pdf given by
<span class="math display">\[
f(x,y) = \begin{cases}
  1 &amp;0\leq x \leq 1, 0\leq y \leq 1 \\
  0 &amp;\text{otherwise}
\end{cases}
\]</span><br />
This is a well-defined pdf, as <span class="math inline">\(f\geq 0\)</span> and <span class="math inline">\(\int\int f(x,y)\mathop{\mathrm{d}}\hspace{0.5pt}\!x \mathop{\mathrm{d}}\hspace{0.5pt}\!y = 1\)</span>.
Suppose we want to find <span class="math inline">\(\mathbb{P}(X&lt;1/2, Y&lt;1/2)\)</span> and <span class="math inline">\(\mathbb{P}(X + Y &lt; 1)\)</span>.</p>
<p>For the first probability, we integrate in the set <span class="math inline">\(\{(x,y) \mid 0 &lt; x &lt;1/2,0&lt; y&lt;1/2\}\)</span>:
<span class="math display">\[\begin{align*}
\mathbb{P}(X&lt;1/2, Y&lt;1/2) &amp;= \int_0^{1/2} \int_0^{1/2} \mathop{\mathrm{d}}\hspace{0.5pt}\!x \mathop{\mathrm{d}}\hspace{0.5pt}\!y \\
&amp;= \left[ \left[ xy \right]_{0}^{1/2} \right]_{0}^{1/2} = 1/4.
\end{align*}\]</span></p>
<p>For the second probability, note that the set <span class="math inline">\(\{(x,y) \mid x+y&lt;1\}\)</span> corresponds to <span class="math inline">\(\{(x,y) \mid 0&lt;y&lt;1, 0&lt;x &lt; 1-y\}\)</span>. So
<span class="math display">\[\begin{align*}
  \mathbb{P}(X+Y&lt;1) &amp;= \int_0^{1} \mathop{\mathrm{d}}\hspace{0.5pt}\!y \int_0^{1-y}  \mathop{\mathrm{d}}\hspace{0.5pt}\!x \\
  &amp;= \int_0^{1} \mathop{\mathrm{d}}\hspace{0.5pt}\!y [x]_0^{1-y} \\
  &amp;= \int_0^{1} (1-y) \mathop{\mathrm{d}}\hspace{0.5pt}\!y = \big[y - y^2/2\big]_0^1 = 1/2.
\end{align*}\]</span></p>
</div>
<p>Another way of understanding these probabilities is by thinking about them geometrically.
If we plot the pdf surface, it would look something like the following sketch:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="figure/bivariateunif.png" alt="Pdf surface plot of the uniform distribution on the unit square." width="80%" />
<p class="caption">
Figure 1.9: Pdf surface plot of the uniform distribution on the unit square.
</p>
</div>
<p>Any probability of interest would be calculated by finding the volume of interest.
For instance, consider again the probability <span class="math inline">\(\mathbb{P}(X + Y &lt; 1)\)</span>.
Viewing the surface from above effectively concentrates on the two dimensions of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.
It’s straightforward to realise that the region of interest is anything occuring below the line <span class="math inline">\(y=x\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bivariateprob"></span>
<img src="bookdown-adv-stats_files/figure-html/bivariateprob-1.png" alt="View of the pdf surface from above, focussing on the X and Y axis." width="60%" />
<p class="caption">
Figure 1.10: View of the pdf surface from above, focussing on the X and Y axis.
</p>
</div>
<p>Correspondingly, we ask what is the volume of this wedge?
It is the area of the shaded region (half of the unit square) multiplied by the height of the surface (1), so we get the same answer of 1/2.</p>
</div>
<div id="marginal-distributions" class="section level3" number="1.7.2">
<h3><span class="header-section-number">1.7.2</span> Marginal distributions</h3>
<p>We may think of multivariate distributions as several random variables “stitched” together, whose distribution as a whole is dependent on each of the components.
Having said this, it is possible recover the distribution for one of the components in a bivariate (or multivariate) model by summing or integrating over the remaining probability distribution, depending on whether or not the other components are discrete or continuous.</p>
<div class="definition">
<p><span id="def:unlabeled-div-39" class="definition"><strong>Definition 1.13  (Marginal distribution) </strong></span>For a bivariate random variable <span class="math inline">\((X,Y)\)</span>, the marginal distributions of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> may be obtained respectively as
<span class="math display">\[
f_X(x) = 
\begin{cases}
  \sum_y f_{X,Y}(x,y) &amp;\text{if $Y$ is discrete} \\
  \int_y f_{X,Y}(x,y) \mathop{\mathrm{d}}\hspace{0.5pt}\!y &amp;\text{if $Y$ is continuous} \\    
\end{cases}
\]</span>
<span class="math display">\[
f_Y(y) = 
\begin{cases}
  \sum_x f_{X,Y}(x,y) &amp;\text{if $X$ is discrete} \\
  \int_x f_{X,Y}(x,y) \mathop{\mathrm{d}}\hspace{0.5pt}\!x &amp;\text{if $X$ is continuous} \\    
\end{cases}
\]</span></p>
</div>
<p>A note to say that since the joint cdf is defined to be
<span class="math display">\[
  F(x,y) = \mathbb{P}(X \leq x, Y\leq y),
\]</span>
the <em>marginal cdfs</em> can be obtained from the joint cdf for <span class="math inline">\(X\)</span> by summing over all the components of <span class="math inline">\(Y\)</span> in the joint cdf, i.e.
<span class="math display">\[\begin{align*}
F_X(x) 
&amp;= \sum_{k\leq x} \left( \sum_y f_{X,Y}(k,y) \right) \\
&amp;= \mathbb{P}(X \leq x, Y \leq \infty) \\
&amp;=F_{X,Y}(x,\infty)
\end{align*}\]</span>
Similarly, we sum up over the components of <span class="math inline">\(X\)</span> to obtain the marginal cdf for <span class="math inline">\(Y\)</span>, <span class="math inline">\(F_Y(y)=F_{X,Y}(\infty,y)\)</span>.
Note that for continuous random variables, we integrate instead: <span class="math inline">\(F_X(x) = \int_{-\infty}^x \left(\int f_{X,Y}(\tilde x,y) \mathop{\mathrm{d}}\hspace{0.5pt}\!y \right) \mathop{\mathrm{d}}\hspace{0.5pt}\!\tilde x\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-40" class="example"><strong>Example 1.22  </strong></span>Define a joint pdf by
<span class="math display">\[
f(x,y) = \begin{cases}
cxy^2 &amp; 0&lt;x&lt;1, 0&lt;y&lt;1\\
0 &amp;\text{otherwise}
\end{cases}
\]</span>
Let’s compute the marginal distributions of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
We’ll have to use integration here since the geometry of the pdf surface in 3-dimensions is a bit complex to work with.</p>
<p>Firstly, we need to find the <em>normalising constant</em> <span class="math inline">\(c\)</span>, such that the joint integral of the pdf is 1.
That is, we need to find the value of <span class="math inline">\(c\)</span> satisfying
<span class="math display">\[
\int_{x=0}^1 \int_{y=0}^1 cxy^2 \mathop{\mathrm{d}}\hspace{0.5pt}\!x \mathop{\mathrm{d}}\hspace{0.5pt}\!y = c\left[ \left[ \frac{x^2y^3}{6} \right]_{0}^{1} \right]_{0}^{1} = 1.
\]</span>
We work out that <span class="math inline">\(c=6\)</span>.</p>
<p>To work out the marginal distribution of <span class="math inline">\(X\)</span>, we integrate the pdf over all possible values of <span class="math inline">\(Y\)</span>, i.e.
<span class="math display">\[\begin{align*}
f_X(x) &amp;= \int_{y=0}^1 6xy^2 \mathop{\mathrm{d}}\hspace{0.5pt}\!y \\
&amp;= \left[\frac{6xy^3}{3} \right]_0^1 \\
&amp;= 2x.
\end{align*}\]</span>
Note that <span class="math inline">\(f_X(x)=2x\)</span> for <span class="math inline">\(0&lt;x&lt;1\)</span> is indeed a valid pdf (it integrates to 1, and also satisfies all the properties of a pdf).
We can now use this to calculate probabilities involving only <span class="math inline">\(X\)</span>, for instance
<span class="math display">\[
\mathbb{P}\left(\frac{1}{2} &lt; X &lt; \frac{3}{4}\right) = \int_{1/2}^{3/4} 2x \mathop{\mathrm{d}}\hspace{0.5pt}\!x = \frac{5}{16}.
\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-41" class="example"><strong>Example 1.23  </strong></span>Here’s a trickier example.
Consider the joint pdf defined by
<span class="math display">\[
f(x,y) = \begin{cases}
e^{-y} &amp; 0&lt;x&lt;y&lt;\infty \\
0 &amp; \text{otherwise.}
\end{cases}
\]</span>
At first glance, it does not seem that the pdf depends on <span class="math inline">\(x\)</span> at all.
But actually, it does.
If we look at the values at which this pdf is non-zero, it is conditional on the positive values of <span class="math inline">\(x\)</span> such that it is lesser than <span class="math inline">\(y\)</span>.
To put it more precisely, we could write the pdf as
<span class="math display">\[
f(x,y) = \mathop{\mathrm{\unicode{x1D7D9}}}_{[\{(u,v) | 0&lt;u&lt;v&lt;\infty\}]}(x,y) e^{-y}
\]</span>
so we can clearly see the dependence of the pdf on both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.
Here, we have used the <em>indicator function</em> <span class="math inline">\(\mathop{\mathrm{\unicode{x1D7D9}}}_A(x)\)</span> defined as
<span class="math display">\[
\mathop{\mathrm{\unicode{x1D7D9}}}_A(x) = \begin{cases}
1 &amp; x\in A \\
0 &amp; x\not\in A.
\end{cases}
\]</span></p>
<p>To calculate the joint cdf of this bivariate distribution, we compute the integral
<span class="math display">\[
F_{X,Y}(x,y) = \int_{u=0}^x \int_{v=u}^y e^{-v} \mathop{\mathrm{d}}\hspace{0.5pt}\!u \mathop{\mathrm{d}}\hspace{0.5pt}\!v 
\]</span>
The limits of integration are obtained as follows: For the random variable <span class="math inline">\(X\)</span> (using the integrating variable <span class="math inline">\(u\)</span>) we start at the smallest value it can take (<span class="math inline">\(u=0\)</span>) and proceed upwards to some arbitrary point <span class="math inline">\(u=x\)</span>. For <span class="math inline">\(Y\)</span> (using the <span class="math inline">\(v\)</span> as the variable of integration), the smallest possible value it can take is <span class="math inline">\(v=u\)</span>, since <span class="math inline">\(x&lt;y&lt;\infty\)</span> and the integration depends on what happens to <span class="math inline">\(X\)</span>. From here, proceed upwards to some arbitrary point <span class="math inline">\(v=y\)</span>.
Working through this integral gives us
<span class="math display">\[
F_{X,Y}(x,y) = 1 - (e^{-x}+xe^{-y}), \hspace{2em} 0&lt;x&lt;y&lt;\infty.
\]</span>
This is a valid cdf, since</p>
<ul>
<li><span class="math inline">\(\lim_{x,y\to 0} F(x,y) = 1-\left(\lim_{x,y\to 0}e^{-x} + \lim_{x,y\to 0} xe^{-y} \right) = 1 - (1 + 0) = 0.\)</span></li>
<li><span class="math inline">\(\lim_{x,y\to \infty} F(x,y) = 1-\left(\lim_{x,y\to \infty}e^{-x} + \lim_{x,y\to \infty} xe^{-y} \right) = 1 - (0 + 0) = 1.\)</span></li>
<li><span class="math inline">\(F(x,y)&gt;0\)</span> in that range.</li>
</ul>
<p>From here, the marginal cdf of <span class="math inline">\(X\)</span> is obtained as <span class="math inline">\(F_X(x)=F_{X,Y}(x,+\infty)= 1-e^{-x}\)</span> for <span class="math inline">\(0&lt;x&lt;\infty\)</span>.
Noting that the maximum value <span class="math inline">\(x\)</span> can take is <span class="math inline">\(y\)</span>, we can similarly obtain the marginal cdf of <span class="math inline">\(Y\)</span> as <span class="math inline">\(F_Y(y)=F_{X,Y}(+\infty,y) = F(+\infty,y)= F(y,y) = 1-(e^{-y}+ye^{-y})\)</span> for <span class="math inline">\(0&lt;y&lt;\infty\)</span>.
It’s easily checked that both of these functions are indeed cdfs.</p>
</div>
<div class="mynote">
<p>In the continuous case, the joint cdf of <span class="math inline">\((X,Y)\)</span> is related to the joint pdf by the relationship
<span class="math display">\[
F_{X,Y}(x,y) = \int_{-\infty}^x \int_{-\infty}^y f_{X,Y}(u,v) \mathop{\mathrm{d}}\hspace{0.5pt}\!u \mathop{\mathrm{d}}\hspace{0.5pt}\!v.
\]</span>
By the (bivariate) Fundamental Theorem of Calculus, this implies that
<span class="math display">\[
\frac{\partial^2}{\partial x \partial y}F_{X,Y}(x,y) = f_{X,Y}(x,y).
\]</span></p>
</div>
</div>
<div id="conditional-distributions" class="section level3" number="1.7.3">
<h3><span class="header-section-number">1.7.3</span> Conditional distributions</h3>
<p>Oftentimes when two r.v. <span class="math inline">\((X,Y)\)</span> are observed, the values of the two variables are “related”.
What we mean by this is that knowledge about the value of <span class="math inline">\(Y\)</span> gives us some information about the value of <span class="math inline">\(X\)</span> and vice versa.
Some examples:</p>
<ul>
<li>Height (<span class="math inline">\(X\)</span>) and weight (<span class="math inline">\(Y\)</span>) of a person;</li>
<li>A level points score (<span class="math inline">\(X\)</span>) and socio-economic status (<span class="math inline">\(Y\)</span>);</li>
<li>Heart rate (<span class="math inline">\(X\)</span>) and oxygen saturation levels (<span class="math inline">\(Y\)</span>).</li>
</ul>
<p>To make this idea a little more concrete, think about what values the heart rate (<span class="math inline">\(X\)</span>) of an individual can take.
For a healthy individual, this might be anywhere between 40 bpm to 200 bpm (depending on their age, what activity they are doing, and so on).
On average, <span class="math inline">\(X\)</span> is 72 bpm.
Oxygen saturation levels on the other hand are usually between 95 and 100 percent, but drops below this range when an intense activity is performed.
Consequently, if we were to guess what the heart rate <span class="math inline">\(X\)</span> value would be given <span class="math inline">\(Y&lt;0.95\)</span>, it would make more sense to guess that <span class="math inline">\(X=160\)</span> rather than <span class="math inline">\(X=72\)</span>.
This concept should sound familiar!</p>
<p>Define the conditional distributions for discrete and continuous random variables as follows.</p>
<div class="definition">
<p><span id="def:unlabeled-div-42" class="definition"><strong>Definition 1.14  (Conditional distributions, discrete) </strong></span>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete, the <em>conditional pmf</em> of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span> is
<span class="math display">\[
  f_{X|Y}(x|y) = \mathbb{P}(X=x|Y=y) = \frac{\mathbb{P}(X=x, Y=y)}{\mathbb{P}(Y=y)} = \frac{f_{X,Y}(x, y)}{f_Y(y)},
\]</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-43" class="definition"><strong>Definition 1.15  (Conditional distributions, continuous) </strong></span>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous, the <em>conditional pdf</em> of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span> is
<span class="math display">\[
  f_{X|Y}(x|y) =  \frac{f_{X,Y}(x, y)}{f_Y(y)}.
\]</span></p>
</div>
<p>In the discrete case, the conditional distribution is derived in a similar way to how the conditional probabilities were (see Definition <a href="conditioning-and-independence.html#def:condprob">1.4</a>).
Interestingly in the continuous case, the definition still looks familiar but it should be noted that plugging <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values into the definition will not yield probabilities–one still requires integration over a set:
<span class="math display">\[
\mathbb{P}(X \in A|Y=y) = \int_A f_{X|Y}(x|y) \mathop{\mathrm{d}}\hspace{0.5pt}\!x. 
\]</span></p>
<p>Note that as a function of <span class="math inline">\(x\)</span>, <span class="math inline">\(f_{X|Y}(x|y)\)</span> is indeed a pdf, since in the discrete case
<span class="math display">\[
\sum_x f_{X|Y}(x|y) = \sum_x \frac{\mathbb{P}(X=x, Y=y)}{\mathbb{P}(Y=y)} = \frac{\mathbb{P}(Y=y)}{\mathbb{P}(Y=y)} = 1,
\]</span>
and in the continuous case,
<span class="math display">\[
\int f_{X|Y}(x|y) \mathop{\mathrm{d}}\hspace{0.5pt}\!x = \int \frac{f_{X,Y}(x, y)}{f_Y(y)} \mathop{\mathrm{d}}\hspace{0.5pt}\!x = \frac{f_Y(y)}{f_Y(y)} = 1.
\]</span></p>
<p>Finally, it’s convenient to note that, just like as we saw for conditional probabilities, we can rearrange the equations to yield <span class="math display">\[f_{X|Y}(x|y)f_Y(y)=f_{Y|X}(y|x)f_X(x).\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-44" class="example"><strong>Example 1.24  </strong></span>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have the joint pdf <span class="math inline">\(f(x,y)=x+y\)</span> for <span class="math inline">\(0\leq x,y\leq 1\)</span>.
Suppose <span class="math inline">\(Y=a\)</span> has been observed, where <span class="math inline">\(a\in[0,1]\)</span>.
Firstly, the the pdf of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
f_Y(y) = \int_0^1 (x+y) \mathop{\mathrm{d}}\hspace{0.5pt}\!x = \left[xy +y^2/2\right]_0^1 = y + 1/2.
\]</span></p>
<p>The conditional pdf for <span class="math inline">\(X\)</span> is
<span class="math display">\[
f_{X|Y}(x|Y=a) = \frac{f_{X,Y}(x,Y=a)}{f_Y(a)} = \frac{x+a}{a + 1/2}.
\]</span></p>
<p>We can compute <span class="math inline">\(\mathbb{P}(X&lt;1/4|Y=1/3)\)</span> by
<span class="math display">\[\begin{align*}
\mathbb{P}(X&lt;1/4|Y=1/3) = (1/3 + 1/2)^{-1} \int_{0}^{1/4} (x+1/3) \mathop{\mathrm{d}}\hspace{0.5pt}\!x = 11/80.
\end{align*}\]</span></p>
</div>
<p>It is possible to also describe <em>conditional cdfs</em>.
If we treat the conditional pmf/pdf <span class="math inline">\(f(x|y)\)</span> as a new pmf/pdf <span class="math inline">\(g(x)\)</span>, then the cdf can be easily obtained in the usual way: <span class="math inline">\(F(x|y)=G(x)=\mathbb{P}(X\in A|y)\)</span>.</p>
</div>
<div id="independent-random-variables" class="section level3" number="1.7.4">
<h3><span class="header-section-number">1.7.4</span> Independent random variables</h3>
<p>Previously we came across the concept of independence of probabilistic events.
We can extend this notion to random variables using the conditional pmf/pdf definitions.</p>
<div class="definition">
<p><span id="def:unlabeled-div-45" class="definition"><strong>Definition 1.16  (Independece of r.v.) </strong></span>Two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent if and only if for every <span class="math inline">\(x\in\mathbb{R}\)</span> and <span class="math inline">\(y\in\mathbb{R}\)</span>,
<span class="math display">\[
  f_{X,Y}(x,y) = f_X(x)f_Y(y).
\]</span>
We write <span class="math inline">\(X \perp Y\)</span>.</p>
</div>
<p>Apparently, if there exists functions <span class="math inline">\(g(x)\)</span> and <span class="math inline">\(h(y)\)</span> (not necessarily pdfs) such that <span class="math inline">\(f(x,y)=g(x)h(y)\)</span> for all <span class="math inline">\(x,y\)</span>, then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent.
This is proven in Lemma 4.2.7 of C&amp;B.
Hence, verifying whether two random variables are independent is made easier, since we only need to separate out the components of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in the joint pdf without needing to check whether or not the components themselves are pdfs.</p>
<p>The assumption of independence is used very often in statistical inference as it simplifies calculations quite a lot.
We’ll circle back to this thought when we talk about likelihood estimation.</p>
<div class="example">
<p><span id="exm:unlabeled-div-46" class="example"><strong>Example 1.25  </strong></span>Recall the bivariate distribution on the unit square (c.f. Example <a href="multiple-random-variables.html#exm:unitsquare">1.21</a>).
Note that the pdf of <span class="math inline">\(X\)</span> is <span class="math inline">\(f_X(x) = \int_0^1 \mathop{\mathrm{d}}\hspace{0.5pt}\!y = 1\)</span>, and similarly <span class="math inline">\(f_Y(y)=1\)</span>.
It is easy to see that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, since
<span class="math display">\[
f_{X,Y}(x,y) = 1 = f_X(x)f_Y(y).
\]</span>
As a consequence, to generate a random sample from <span class="math inline">\((X,Y)\)</span>, one can randomly sample values <span class="math inline">\(X\sim\mathop{\mathrm{Unif}}(0,1)\)</span>, and independently sample <span class="math inline">\(Y\sim\mathop{\mathrm{Unif}}(0,1)\)</span>.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="transformations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="expectations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/haziqj/adv-stats/edit/main/02-prob_theory.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-adv-stats.pdf", "bookdown-adv-stats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
