<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.3 Conditioning and independence | SM-4331 Advanced Statistics</title>
  <meta name="description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="1.3 Conditioning and independence | SM-4331 Advanced Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.3 Conditioning and independence | SM-4331 Advanced Statistics" />
  
  <meta name="twitter:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

<meta name="author" content="Dr Haziq Jamil" />


<meta name="date" content="2022-02-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="axiomatic-probability.html"/>
<link rel="next" href="random-variables.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="mystyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SM-4331 Advanced Statistics</a></li>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {extensions: ["cancel.js"]}
});
</script>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="" data-path="what-is-statistics.html"><a href="what-is-statistics.html"><i class="fa fa-check"></i>What is statistics?</a>
<ul>
<li class="chapter" data-level="" data-path="learning-statistics.html"><a href="learning-statistics.html"><i class="fa fa-check"></i>Learning statistics</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html"><i class="fa fa-check"></i>Population, sample and parametric models</a>
<ul>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#population-vs-sample"><i class="fa fa-check"></i>Population vs sample</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#parametric-models"><i class="fa fa-check"></i>Parametric models</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#a-sample-a-set-of-data-or-random-variablesa-duality"><i class="fa fa-check"></i>A sample: a set of data or random variables?–A duality</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#variability-of-estimates"><i class="fa fa-check"></i>Variability of estimates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-and-statistics.html"><a href="probability-and-statistics.html"><i class="fa fa-check"></i>Probability and statistics</a></li>
</ul></li>
<li class="part"><span><b>II Prepare</b></span></li>
<li class="chapter" data-level="1" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html"><i class="fa fa-check"></i><b>1</b> Probability theory primer</a>
<ul>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#readings"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html"><i class="fa fa-check"></i><b>1.1</b> Elementary set theory</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#set-operations"><i class="fa fa-check"></i><b>1.1.1</b> Set operations</a></li>
<li class="chapter" data-level="1.1.2" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#partitions"><i class="fa fa-check"></i><b>1.1.2</b> Partitions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html"><i class="fa fa-check"></i><b>1.2</b> Axiomatic probability</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#probability-as-a-measure"><i class="fa fa-check"></i><b>1.2.1</b> Probability as a measure</a></li>
<li class="chapter" data-level="1.2.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>1.2.2</b> Axioms of probability</a></li>
<li class="chapter" data-level="1.2.3" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#derived-probability-results"><i class="fa fa-check"></i><b>1.2.3</b> Derived probability results</a></li>
<li class="chapter" data-level="1.2.4" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#why-measure-theory"><i class="fa fa-check"></i><b>1.2.4</b> Why measure theory?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html"><i class="fa fa-check"></i><b>1.3</b> Conditioning and independence</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#bayes-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Bayes Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#independence"><i class="fa fa-check"></i><b>1.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>1.4</b> Random variables</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="random-variables.html"><a href="random-variables.html#distribution-functions"><i class="fa fa-check"></i><b>1.4.1</b> Distribution functions</a></li>
<li class="chapter" data-level="1.4.2" data-path="random-variables.html"><a href="random-variables.html#identically-distributed-r.v."><i class="fa fa-check"></i><b>1.4.2</b> Identically distributed r.v.</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-functions.html"><a href="probability-functions.html"><i class="fa fa-check"></i><b>1.5</b> Probability functions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probability-functions.html"><a href="probability-functions.html#probability-mass-function"><i class="fa fa-check"></i><b>1.5.1</b> Probability mass function</a></li>
<li class="chapter" data-level="1.5.2" data-path="probability-functions.html"><a href="probability-functions.html#probability-density-functions"><i class="fa fa-check"></i><b>1.5.2</b> Probability density functions</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>1.6</b> Transformations</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="transformations.html"><a href="transformations.html#probability-integral-transform"><i class="fa fa-check"></i><b>1.6.1</b> Probability integral transform</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html"><i class="fa fa-check"></i><b>1.7</b> Multiple random variables</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#bivariate-distributions"><i class="fa fa-check"></i><b>1.7.1</b> Bivariate distributions</a></li>
<li class="chapter" data-level="1.7.2" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#marginal-distributions"><i class="fa fa-check"></i><b>1.7.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="1.7.3" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#conditional-distributions"><i class="fa fa-check"></i><b>1.7.3</b> Conditional distributions</a></li>
<li class="chapter" data-level="1.7.4" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>1.7.4</b> Independent random variables</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="expectations.html"><a href="expectations.html"><i class="fa fa-check"></i><b>1.8</b> Expectations</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="expectations.html"><a href="expectations.html#expectations-of-functions-of-r.v."><i class="fa fa-check"></i><b>1.8.1</b> Expectations of functions of r.v.</a></li>
<li class="chapter" data-level="1.8.2" data-path="expectations.html"><a href="expectations.html#properties-of-expectations"><i class="fa fa-check"></i><b>1.8.2</b> Properties of expectations</a></li>
<li class="chapter" data-level="1.8.3" data-path="expectations.html"><a href="expectations.html#variance"><i class="fa fa-check"></i><b>1.8.3</b> Variance</a></li>
<li class="chapter" data-level="1.8.4" data-path="expectations.html"><a href="expectations.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.8.4</b> Covariance and correlation</a></li>
<li class="chapter" data-level="1.8.5" data-path="expectations.html"><a href="expectations.html#properties-of-variances-and-covariances"><i class="fa fa-check"></i><b>1.8.5</b> Properties of variances and covariances</a></li>
<li class="chapter" data-level="1.8.6" data-path="expectations.html"><a href="expectations.html#multivariate-means-and-covariances"><i class="fa fa-check"></i><b>1.8.6</b> Multivariate means and covariances</a></li>
<li class="chapter" data-level="1.8.7" data-path="expectations.html"><a href="expectations.html#conditional-expectations-and-variance"><i class="fa fa-check"></i><b>1.8.7</b> Conditional expectations and variance</a></li>
<li class="chapter" data-level="1.8.8" data-path="expectations.html"><a href="expectations.html#additional-explainers"><i class="fa fa-check"></i><b>1.8.8</b> Additional explainers</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html"><i class="fa fa-check"></i><b>1.9</b> Moment generating functions</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#moment-generating-functions-1"><i class="fa fa-check"></i><b>1.9.1</b> Moment generating functions</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.10</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#hand-in-questions"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html"><i class="fa fa-check"></i><b>2</b> Commonly-used probability models</a>
<ul>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#learning-objectives-1"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#readings-1"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="2.1" data-path="discrete-models.html"><a href="discrete-models.html"><i class="fa fa-check"></i><b>2.1</b> Discrete models</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="discrete-models.html"><a href="discrete-models.html#point-mass-distribution"><i class="fa fa-check"></i><b>2.1.1</b> Point mass distribution</a></li>
<li class="chapter" data-level="2.1.2" data-path="discrete-models.html"><a href="discrete-models.html#uniform-distribution"><i class="fa fa-check"></i><b>2.1.2</b> Uniform distribution</a></li>
<li class="chapter" data-level="2.1.3" data-path="discrete-models.html"><a href="discrete-models.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.1.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.1.4" data-path="discrete-models.html"><a href="discrete-models.html#binomial-distribution"><i class="fa fa-check"></i><b>2.1.4</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.1.5" data-path="discrete-models.html"><a href="discrete-models.html#geometric-distribution"><i class="fa fa-check"></i><b>2.1.5</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.1.6" data-path="discrete-models.html"><a href="discrete-models.html#negative-binomial"><i class="fa fa-check"></i><b>2.1.6</b> Negative binomial</a></li>
<li class="chapter" data-level="2.1.7" data-path="discrete-models.html"><a href="discrete-models.html#poisson-distribution"><i class="fa fa-check"></i><b>2.1.7</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continuous-models.html"><a href="continuous-models.html"><i class="fa fa-check"></i><b>2.2</b> Continuous models</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="continuous-models.html"><a href="continuous-models.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>2.2.1</b> Continuous uniform distribution</a></li>
<li class="chapter" data-level="2.2.2" data-path="continuous-models.html"><a href="continuous-models.html#exponential-distribution"><i class="fa fa-check"></i><b>2.2.2</b> Exponential distribution</a></li>
<li class="chapter" data-level="2.2.3" data-path="continuous-models.html"><a href="continuous-models.html#gamma-distribution"><i class="fa fa-check"></i><b>2.2.3</b> Gamma distribution</a></li>
<li class="chapter" data-level="2.2.4" data-path="continuous-models.html"><a href="continuous-models.html#beta-distribution"><i class="fa fa-check"></i><b>2.2.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="normal-distribution.html"><a href="normal-distribution.html#location-and-scale-parameter"><i class="fa fa-check"></i><b>2.3.1</b> Location and scale parameter</a></li>
<li class="chapter" data-level="2.3.2" data-path="normal-distribution.html"><a href="normal-distribution.html#linear-transformations-of-normal-random-variables"><i class="fa fa-check"></i><b>2.3.2</b> Linear transformations of normal random variables</a></li>
<li class="chapter" data-level="2.3.3" data-path="normal-distribution.html"><a href="normal-distribution.html#the-normal-cdf"><i class="fa fa-check"></i><b>2.3.3</b> The normal cdf</a></li>
<li class="chapter" data-level="2.3.4" data-path="normal-distribution.html"><a href="normal-distribution.html#rule"><i class="fa fa-check"></i><b>2.3.4</b> 68–95–99.7 Rule</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="some-relationships.html"><a href="some-relationships.html"><i class="fa fa-check"></i><b>2.4</b> Some relationships</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="some-relationships.html"><a href="some-relationships.html#poisson-binomial-relationship"><i class="fa fa-check"></i><b>2.4.1</b> Poisson-Binomial relationship</a></li>
<li class="chapter" data-level="2.4.2" data-path="some-relationships.html"><a href="some-relationships.html#poisson-exponential"><i class="fa fa-check"></i><b>2.4.2</b> Poisson-Exponential</a></li>
<li class="chapter" data-level="2.4.3" data-path="some-relationships.html"><a href="some-relationships.html#poisson-gamma"><i class="fa fa-check"></i><b>2.4.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="2.4.4" data-path="some-relationships.html"><a href="some-relationships.html#normal-approximations"><i class="fa fa-check"></i><b>2.4.4</b> Normal approximations</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#hand-in-questions-1"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html"><i class="fa fa-check"></i><b>3</b> Inequalities, convergences, and normal random samples</a>
<ul>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#readings-2"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#independent-and-identical-random-variable"><i class="fa fa-check"></i><b>3.1.1</b> Independent and identical random variable</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#statistic"><i class="fa fa-check"></i><b>3.1.2</b> Statistic</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Sampling distribution</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#large-sample-approximation"><i class="fa fa-check"></i><b>3.1.4</b> Large-sample approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>3.2</b> Inequalities</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inequalities.html"><a href="inequalities.html#markovs-inequality"><i class="fa fa-check"></i><b>3.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="3.2.2" data-path="inequalities.html"><a href="inequalities.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>3.2.2</b> Chebyshev’s inequality</a></li>
<li class="chapter" data-level="3.2.3" data-path="inequalities.html"><a href="inequalities.html#cauchy-schwartz-inequality"><i class="fa fa-check"></i><b>3.2.3</b> Cauchy-Schwartz inequality</a></li>
<li class="chapter" data-level="3.2.4" data-path="inequalities.html"><a href="inequalities.html#jensens-inequality"><i class="fa fa-check"></i><b>3.2.4</b> Jensen’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html"><i class="fa fa-check"></i><b>3.3</b> Convergence of random variables</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.3.1</b> Convergence in probability</a></li>
<li class="chapter" data-level="3.3.2" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Convergence in distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#mean-square-convergence"><i class="fa fa-check"></i><b>3.3.3</b> Mean-square convergence</a></li>
<li class="chapter" data-level="3.3.4" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#relationship-between-convergences"><i class="fa fa-check"></i><b>3.3.4</b> Relationship between convergences</a></li>
<li class="chapter" data-level="3.3.5" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#slutzkys-theorem"><i class="fa fa-check"></i><b>3.3.5</b> Slutzky’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>3.4</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="limit-theorems.html"><a href="limit-theorems.html#the-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>3.4.1</b> The (weak) Law of Large Numbers</a></li>
<li class="chapter" data-level="3.4.2" data-path="limit-theorems.html"><a href="limit-theorems.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="3.4.3" data-path="limit-theorems.html"><a href="limit-theorems.html#gauging-the-error-of-sample-mean-estimator"><i class="fa fa-check"></i><b>3.4.3</b> Gauging the error of sample mean estimator</a></li>
<li class="chapter" data-level="3.4.4" data-path="limit-theorems.html"><a href="limit-theorems.html#clt-with-sigma2-unknown"><i class="fa fa-check"></i><b>3.4.4</b> CLT with <span class="math inline">\(\sigma^2\)</span> unknown</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>3.5</b> Delta method</a></li>
<li class="chapter" data-level="3.6" data-path="normal-random-samples.html"><a href="normal-random-samples.html"><i class="fa fa-check"></i><b>3.6</b> Normal random samples</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="normal-random-samples.html"><a href="normal-random-samples.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6.1</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.2" data-path="normal-random-samples.html"><a href="normal-random-samples.html#students-t-distribution"><i class="fa fa-check"></i><b>3.6.2</b> Student’s <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.3" data-path="normal-random-samples.html"><a href="normal-random-samples.html#proof-of-theorem-refthmpropertynormalsamp"><i class="fa fa-check"></i><b>3.6.3</b> Proof of Theorem @ref(thm:propertynormalsamp)</a></li>
<li class="chapter" data-level="3.6.4" data-path="normal-random-samples.html"><a href="normal-random-samples.html#f-distribution"><i class="fa fa-check"></i><b>3.6.4</b> <span class="math inline">\(F\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.5" data-path="normal-random-samples.html"><a href="normal-random-samples.html#the-analysis-of-variance"><i class="fa fa-check"></i><b>3.6.5</b> The analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#hand-in-questions-2"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Inference</b></span></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#readings-3"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="4.1" data-path="the-likelihood.html"><a href="the-likelihood.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="the-likelihood.html"><a href="the-likelihood.html#calculating-the-likelihood"><i class="fa fa-check"></i><b>4.1.1</b> Calculating the likelihood</a></li>
<li class="chapter" data-level="4.1.2" data-path="the-likelihood.html"><a href="the-likelihood.html#likelihood-ratio"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood ratio</a></li>
<li class="chapter" data-level="4.1.3" data-path="the-likelihood.html"><a href="the-likelihood.html#log-likelihood"><i class="fa fa-check"></i><b>4.1.3</b> Log likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sufficiency.html"><a href="sufficiency.html"><i class="fa fa-check"></i><b>4.2</b> Sufficiency</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sufficiency.html"><a href="sufficiency.html#the-factorisation-theorem"><i class="fa fa-check"></i><b>4.2.1</b> The factorisation theorem</a></li>
<li class="chapter" data-level="4.2.2" data-path="sufficiency.html"><a href="sufficiency.html#minimal-sufficient-statistic"><i class="fa fa-check"></i><b>4.2.2</b> Minimal sufficient statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="point-estimators.html"><a href="point-estimators.html"><i class="fa fa-check"></i><b>4.3</b> Point estimators</a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>4.4</b> Method of moments</a></li>
<li class="chapter" data-level="4.5" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>4.5</b> Method of maximum likelihood</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#finding-the-mle"><i class="fa fa-check"></i><b>4.5.1</b> Finding the MLE</a></li>
<li class="chapter" data-level="4.5.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#invariance-of-mle"><i class="fa fa-check"></i><b>4.5.2</b> Invariance of MLE</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html"><i class="fa fa-check"></i><b>4.6</b> Evaluating estimators</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#bias"><i class="fa fa-check"></i><b>4.6.1</b> Bias</a></li>
<li class="chapter" data-level="4.6.2" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#variance-and-standard-error"><i class="fa fa-check"></i><b>4.6.2</b> Variance and standard error</a></li>
<li class="chapter" data-level="4.6.3" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>4.6.3</b> Mean squared error</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html"><i class="fa fa-check"></i><b>4.7</b> Cramér-Rao lower bound (CRLB)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#fisher-information"><i class="fa fa-check"></i><b>4.7.1</b> Fisher information</a></li>
<li class="chapter" data-level="4.7.2" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#variance-reduction-rao-blackwellisation"><i class="fa fa-check"></i><b>4.7.2</b> Variance reduction: Rao-Blackwellisation</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html"><i class="fa fa-check"></i><b>4.8</b> Large sample properties of estimators</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency"><i class="fa fa-check"></i><b>4.8.1</b> Consistency</a></li>
<li class="chapter" data-level="4.8.2" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-vs-unbiasedness"><i class="fa fa-check"></i><b>4.8.2</b> Consistency vs unbiasedness</a></li>
<li class="chapter" data-level="4.8.3" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-of-mles"><i class="fa fa-check"></i><b>4.8.3</b> Consistency of MLEs</a></li>
<li class="chapter" data-level="4.8.4" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency"><i class="fa fa-check"></i><b>4.8.4</b> Efficiency</a></li>
<li class="chapter" data-level="4.8.5" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#asymptotic-normality-and-consistency"><i class="fa fa-check"></i><b>4.8.5</b> Asymptotic normality and consistency</a></li>
<li class="chapter" data-level="4.8.6" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-mle"><i class="fa fa-check"></i><b>4.8.6</b> Efficiency of MLE</a></li>
<li class="chapter" data-level="4.8.7" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-transformations-of-mle"><i class="fa fa-check"></i><b>4.8.7</b> Efficiency of transformations of MLE</a></li>
<li class="chapter" data-level="4.8.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#application-of-asymptotic-normality"><i class="fa fa-check"></i><b>4.8.8</b> Application of asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-3.html"><a href="exercises-3.html#hand-in-questions-3"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#readings-4"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="5.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-1.html"><a href="introduction-1.html#a-general-paradigm"><i class="fa fa-check"></i><b>5.1.1</b> A general paradigm</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-1.html"><a href="introduction-1.html#p-values"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-1.html"><a href="introduction-1.html#accept-h_0"><i class="fa fa-check"></i><b>5.1.3</b> Accept <span class="math inline">\(H_0\)</span>?</a></li>
<li class="chapter" data-level="5.1.4" data-path="introduction-1.html"><a href="introduction-1.html#uniformity-of-p-values"><i class="fa fa-check"></i><b>5.1.4</b> Uniformity of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>5.2</b> Likelihood ratio test</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#log-likelihood-ratio-test-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Log likelihood ratio test statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.2</b> Example: Normal with known variance</a></li>
<li class="chapter" data-level="5.2.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-unknown-variance-t-test"><i class="fa fa-check"></i><b>5.2.3</b> Example: Normal with unknown variance (<span class="math inline">\(t\)</span>-test)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html"><i class="fa fa-check"></i><b>5.3</b> The Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#performance-of-a-test"><i class="fa fa-check"></i><b>5.3.1</b> Performance of a test</a></li>
<li class="chapter" data-level="5.3.2" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#relation-to-p-values"><i class="fa fa-check"></i><b>5.3.2</b> Relation to <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html"><i class="fa fa-check"></i><b>5.4</b> Type I and II errors</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#minimising-errors"><i class="fa fa-check"></i><b>5.4.1</b> Minimising errors</a></li>
<li class="chapter" data-level="5.4.2" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#optimality-of-the-lr-test"><i class="fa fa-check"></i><b>5.4.2</b> Optimality of the LR test</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sided-tests.html"><a href="one-sided-tests.html"><i class="fa fa-check"></i><b>5.5</b> One-sided tests</a></li>
<li class="chapter" data-level="5.6" data-path="approximate-tests.html"><a href="approximate-tests.html"><i class="fa fa-check"></i><b>5.6</b> Approximate tests</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="approximate-tests.html"><a href="approximate-tests.html#asymptotic-distribution-of-lrts"><i class="fa fa-check"></i><b>5.6.1</b> Asymptotic distribution of LRTs</a></li>
<li class="chapter" data-level="5.6.2" data-path="approximate-tests.html"><a href="approximate-tests.html#wilks-theorem"><i class="fa fa-check"></i><b>5.6.2</b> Wilk’s theorem</a></li>
<li class="chapter" data-level="5.6.3" data-path="approximate-tests.html"><a href="approximate-tests.html#the-wald-test"><i class="fa fa-check"></i><b>5.6.3</b> The Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-4.html"><a href="exercises-4.html#hand-in-questions-4"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>6</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#readings-5"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="6.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-2.html"><a href="introduction-2.html#coverage-probability"><i class="fa fa-check"></i><b>6.1.1</b> Coverage probability</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-2.html"><a href="introduction-2.html#confidence-regions"><i class="fa fa-check"></i><b>6.1.2</b> Confidence regions</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-2.html"><a href="introduction-2.html#methods-for-obtaining-confidence-regions"><i class="fa fa-check"></i><b>6.1.3</b> Methods for obtaining confidence regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pivots.html"><a href="pivots.html"><i class="fa fa-check"></i><b>6.2</b> Pivots</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pivots.html"><a href="pivots.html#from-pivot-to-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> From pivot to confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Inverting a test statistic</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html#discrete-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Discrete distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="desirable-confidence-sets.html"><a href="desirable-confidence-sets.html"><i class="fa fa-check"></i><b>6.4</b> Desirable confidence sets</a></li>
<li class="chapter" data-level="6.5" data-path="intervals-based-on-ml-methods.html"><a href="intervals-based-on-ml-methods.html"><i class="fa fa-check"></i><b>6.5</b> Intervals based on ML methods</a></li>
<li class="chapter" data-level="6.6" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>6.6</b> The bootstrap method</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#empirical-distribution"><i class="fa fa-check"></i><b>6.6.1</b> Empirical distribution</a></li>
<li class="chapter" data-level="6.6.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-variance-estimation"><i class="fa fa-check"></i><b>6.6.2</b> Bootstrap variance estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap confidence intervals</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#normal-bootstrap-interval"><i class="fa fa-check"></i><b>6.7.1</b> Normal bootstrap interval</a></li>
<li class="chapter" data-level="6.7.2" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-percentile-interval"><i class="fa fa-check"></i><b>6.7.2</b> Bootstrap percentile interval</a></li>
<li class="chapter" data-level="6.7.3" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-pivotal-interval"><i class="fa fa-check"></i><b>6.7.3</b> Bootstrap pivotal interval</a></li>
<li class="chapter" data-level="6.7.4" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#which-one-to-use"><i class="fa fa-check"></i><b>6.7.4</b> Which one to use?</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-5.html"><a href="exercises-5.html#hand-in-questions-5"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="exam-tips.html"><a href="exam-tips.html"><i class="fa fa-check"></i><b>A</b> Exam tips</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SM-4331 Advanced Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="conditioning-and-independence" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Conditioning and independence</h2>
<p>In the previous section, the probabilities we encountered are <em>unconditional</em>, in the sense that the probabilities do not depend on any other external factors or information, and only on the (fixed) information in the sample space.
In contrast, we may talk about <em>conditional probabilities</em>.
If the sample space gets updated based on observation of new information, then this will sure impact probability calculations.</p>
<div class="definition">
<p><span id="def:condprob" class="definition"><strong>Definition 1.4  (Conditional probabilities) </strong></span>Let <span class="math inline">\((\Omega,{\mathcal F},\mathbb{P})\)</span> be a probability space. For any <span class="math inline">\(A,B \in{\mathcal F}\)</span> such that <span class="math inline">\(\mathbb{P}(B)&gt;0\)</span>, the <em>conditional probability</em> of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, written <span class="math inline">\(\mathbb{P}(A | B)\)</span>, is defined to be
<span class="math display">\[
  \mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}.
\]</span></p>
</div>
<p>The event <span class="math inline">\(B\)</span> is known as the <em>conditioning event</em>.
For all intents and purposes, we may view <span class="math inline">\(\mathbb{P}(A | B)\)</span> as “the probability that <span class="math inline">\(A\)</span> occurs, given that we know that <span class="math inline">\(B\)</span> has <u>already</u> occurred”.
In this sense, the given information forms an updated sample space (as <span class="math inline">\(\mathbb{P}(B | B) = 1\)</span>):
All further occurrences are calibrated with respect to their relation to <span class="math inline">\(B\)</span>.
Thus, <span class="math inline">\(\mathbb{P}(A | B)\)</span> as <em>the fraction of times <span class="math inline">\(A\)</span> occurs among those in which <span class="math inline">\(B\)</span> occurs</em>.</p>
<p>Note that for mutually exclusive events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, <span class="math inline">\(\mathbb{P}(A | B)=\mathbb{P}(B | A)=0\)</span> since <span class="math inline">\(\mathbb{P}(A \cap B) = 0\)</span>.
This makes sense because as the two events are disjoint, they have “nothing to do with each other”.</p>
<div class="myalert">
<p>In general, <span class="math display">\[\mathbb{P}(A | B) \neq \mathbb{P}(A).\]</span> This is only true when dealing with independent events. Furthermore, in general <span class="math display">\[\mathbb{P}(A | B) \neq \mathbb{P}(B | A).\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-15" class="example"><strong>Example 1.9  </strong></span>A medical test for a disease <span class="math inline">\(D\)</span> has outcomes ‘<span class="math inline">\(+\)</span>’ and ‘<span class="math inline">\(-\)</span>’. The probabilities are as follows:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center"><span class="math inline">\(D\)</span></th>
<th align="center"><span class="math inline">\(D^c\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(+\)</span></td>
<td align="center">0.009</td>
<td align="center">0.099</td>
</tr>
<tr class="even">
<td><span class="math inline">\(-\)</span></td>
<td align="center">0.001</td>
<td align="center">0.891</td>
</tr>
</tbody>
</table>
<p><em>note: each cell represents <span class="math inline">\(\mathbb{P}(A \cap B)\)</span>.</em></p>
<p>From the definition of conditional probability,
<span class="math display">\[
  \mathbb{P}(+|D) = \frac{\mathbb{P}(+ \cap D)}{\mathbb{P}(D)} = \frac{0.009}{0.009 + 0.001} = 0.90
\]</span>
and
<span class="math display">\[
  \mathbb{P}(-|D^c) = \frac{\mathbb{P}(- \cap D^c)}{\mathbb{P}(D^c)} = \frac{0.891}{0.099 + 0.891} \approx 0.90.
\]</span></p>
<p>Suppose you go for a test and get a positive result.
What is the probability you have the disease?
Most will answer 0.90.
Actually,
<span class="math display">\[
  \mathbb{P}(D|+) = \frac{\mathbb{P}(D \cap +)}{\mathbb{P}(+)} = \frac{0.009}{0.009 + 0.099} = 0.08.
\]</span></p>
</div>
<p>Notice that</p>
<ul>
<li><span class="math inline">\(\mathbb{P}(D \cap +) = \mathbb{P}(+|D)\mathbb{P}(D)\)</span> after some rearranging; and</li>
<li><span class="math inline">\(\mathbb{P}(+) = \mathbb{P}(+ \cap D) + \mathbb{P}(+ \cap D^c)\)</span> since <span class="math inline">\(D\)</span> and <span class="math inline">\(D^c\)</span> are disjoint.</li>
</ul>
<p>We can therefore write
<span class="math display">\[
\mathbb{P}(D|+) = \frac{\mathbb{P}(+|D)\mathbb{P}(D)}{\mathbb{P}(+|D)\mathbb{P}(D) + \mathbb{P}(+|D^c)\mathbb{P}(D^c)}.
\]</span>
For <span class="math inline">\(\mathbb{P}(D|+)\)</span> to be large, it seems <span class="math inline">\(\mathbb{P}(D)\)</span> needs to be large in addition to <span class="math inline">\(\mathbb{P}(+|D)\)</span>, i.e. disease is prevalent.</p>
<div id="bayes-theorem" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Bayes Theorem</h3>
<p>Following that previous example, and from the definitions of conditional probabilities, we have that, after some rearranging,
<span class="math display">\[
\mathbb{P}(A | B)\mathbb{P}(B) = \mathbb{P}(A \cap B),
\]</span>
and
<span class="math display">\[
\mathbb{P}(B | A) \mathbb{P}(A)= \mathbb{P}(A \cap B).
\]</span>
So equating the two together, one can relate the two conditional probabilities <span class="math inline">\(\mathbb{P}(A | B)\)</span> and <span class="math inline">\(\mathbb{P}(B | A)\)</span> by
<span class="math display">\[
\mathbb{P}(A | B) = \frac{\mathbb{P}(B|A)\mathbb{P}(A)}{\mathbb{P}(B)}.
\]</span></p>
<p>Furthermore, by using the law of total probability, we can now state Bayes’ Theorem.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-16" class="theorem"><strong>Theorem 1.4  (Bayes' Theorem) </strong></span>Let <span class="math inline">\((\Omega,{\mathcal F},\mathbb{P})\)</span> be a probability space, <span class="math inline">\(A_1,A_2,\dots\)</span> a partition of the sample space, and <span class="math inline">\(B\)</span> be any set in <span class="math inline">\({\mathcal F}\)</span> such that <span class="math inline">\(\mathbb{P}(B)&gt;0\)</span>.
Then, for each <span class="math inline">\(i=1,2,\dots\)</span>,
<span class="math display">\[
  \mathbb{P}(A_i|B) = \frac{\mathbb{P}(B|A_i)\mathbb{P}(A_i)}{\sum_{j=1}^\infty \mathbb{P}(B|A_j)\mathbb{P}(A_j)}.
\]</span></p>
</div>
<p>The above rule provides a convenient way of computing conditional probability <span class="math inline">\(\mathbb{P}(A|B)\)</span> if knowledge regarding the “reverse” conditional probability <span class="math inline">\(\mathbb{P}(B|A)\)</span> is readily available.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:revthomasbayes"></span>
<img src="figure/bayes.jpg" alt="(Probably not) Rev. Thomas Bayes c. 1701--7 April 1761. This picture is commonly used to depict Thomas Bayes, but historians believe this not to be an accurate depiction." width="50%" />
<p class="caption">
Figure 1.3: (Probably not) Rev. Thomas Bayes c. 1701–7 April 1761. This picture is commonly used to depict Thomas Bayes, but historians believe this not to be an accurate depiction.
</p>
</div>
<div class="mynote">
<p>Some will call <span class="math inline">\(\mathbb{P}(A_i)\)</span> the <em>prior probability</em>, and the <span class="math inline">\(\mathbb{P}(A_i|B)\)</span> <em>posterior probability</em>, especially in the context of Bayesian statistics. The terms refer to our state of knowledge before and after learning new information (respectively) that is used to update our beliefs.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-17" class="example"><strong>Example 1.10  </strong></span>In a certain selection of flower seeds, 2/3 have been treated to improve germination and 1/3 have been left untreated.
For the purpose of this example, we may treat these numbers as probabilities of selecting a treated or untreated flower seed.</p>
<p>Furthermore, the seeds which have been treated have a probability of germination of 0.8, whereas the untreated seeds have a probability of germination of 0.5.</p>
<p>Let’s calculate the probability that a seed, selected at random:</p>
<ol style="list-style-type: lower-alpha">
<li>will germinate (assuming the seeds were sown and given time to germinate).</li>
<li>a germinated seed had been treated.</li>
</ol>
<p>First, let us define the following events:</p>
<ul>
<li><span class="math inline">\(T=\)</span> a seed has been treated</li>
<li><span class="math inline">\(T^c=\)</span> a seed has not been treated</li>
<li><span class="math inline">\(G=\)</span> a seed has germinated</li>
<li><span class="math inline">\(G^c=\)</span> a seed has not germinated</li>
</ul>
<p>We note that the events <span class="math inline">\(T\)</span> and <span class="math inline">\(T^c\)</span> are disjoint and partitions the sample space (a seed can either be treated or not), and so too the case with <span class="math inline">\(G\)</span> and <span class="math inline">\(G^c\)</span>.
After some careful reading of the question, we are actually presented with the probabilities <span class="math inline">\(\mathbb{P}(G|T)=0.8\)</span> and <span class="math inline">\(\mathbb{P}(G|T^c)=0.5\)</span>.</p>
<p>To answer a., we require <span class="math inline">\(\mathbb{P}(G)\)</span>, which is obtained using the law of total probability:
<span class="math display">\[\begin{align*}
\mathbb{P}(G) 
&amp;= \mathbb{P}(G \cap T) + \mathbb{P}(G\cap T^c) \\
&amp;= \mathbb{P}(G |T)\mathbb{P}(T) + \mathbb{P}(G|T^c)\mathbb{P}(T^c) \\
&amp;= 2/3 \times 0.8 + 1/3 \times 0.5 = 0.7
\end{align*}\]</span></p>
<p>In answering b., we realise that we are after the quantity <span class="math inline">\(\mathbb{P}(T|G)\)</span>. Using Bayes’ Theorem,
<span class="math display">\[\begin{align*}
\mathbb{P}(T|G)
&amp;= \frac{\mathbb{P}(G|T)\mathbb{P}(T)}{\mathbb{P}(G)} \\
&amp;= \frac{0.8 \times 2/3}{0.7} \\
&amp;= 0.762
\end{align*}\]</span></p>
</div>
<p>It’s important to note here that <span class="math inline">\(\mathbb{P}(G|T) \neq 1 - \mathbb{P}(G|T^c)\)</span>, and this is true in most cases. We cannot take complements with respect to the conditioning event!</p>
</div>
<div id="independence" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Independence</h3>
<p>In some cases, the occurrence of a particular event <span class="math inline">\(B\)</span> has <em>no effect</em> on the probability of another event <span class="math inline">\(A\)</span>. Mathematically, we can denote this as
<span class="math display">\[
  \mathbb{P}(A | B) = \mathbb{P}(A).
\]</span>
If this were true, we can use the relationship <span class="math inline">\(\mathbb{P}(A \cap B) = \mathbb{P}(A | B)\mathbb{P}(B)\)</span> to derive the following definition.</p>
<div class="definition">
<p><span id="def:unlabeled-div-18" class="definition"><strong>Definition 1.5  </strong></span>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <em>statistically independent</em> if and only if
<span class="math display">\[
  \mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B).
\]</span></p>
</div>
<p>What’s nice about this definition is that in order to check whether to events are independent, it is sufficient to check whether their probabilities multiply out in the manner above.
Note that (and it is easily checked!) that if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent then so too are</p>
<ul>
<li><span class="math inline">\(A\)</span> and <span class="math inline">\(B^c\)</span>;</li>
<li><span class="math inline">\(A^c\)</span> and <span class="math inline">\(B\)</span>; and</li>
<li><span class="math inline">\(A^c\)</span> and <span class="math inline">\(B^c\)</span>.</li>
</ul>
<p>Here’s an experiment we can do to examine the concept of independent events.
Consider tossing a fair die.
Let <span class="math inline">\(A = \{2, 4, 6\}\)</span> and <span class="math inline">\(B = \{1,2,3,4\}\)</span>.
You should be able to work out, using the above probability results and the definition of conditional probabilities, that <span class="math inline">\(\mathbb{P}(A)=1/2\)</span>, <span class="math inline">\(\mathbb{P}(B)=2/3\)</span>, and <span class="math inline">\(\mathbb{P}(A \cap B)=1/3\)</span>.
Hence, we deduce that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, since the product of each probability event is the probability of their intersection.</p>
<p>If you were feeling bored and had a lot of time to spare, you could verify this empirically using an actual die.
While this would be an afternoon well spent, let’s use <code>R</code> to simulate some draws from the sample space <span class="math inline">\(\Omega = \{1,2,3,4,5,6\}\)</span>, and count the number of times each events <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(A \cap B\)</span> occurs.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="conditioning-and-independence.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Throw a dice 10 times</span></span>
<span id="cb1-2"><a href="conditioning-and-independence.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##  [1] 3 6 3 2 2 6 3 5 4 6</code></pre>
<p>From the above, <span class="math inline">\(n(A) = 6\)</span>, <span class="math inline">\(n(B)=6\)</span>, and <span class="math inline">\(n(A \cap B)=3\)</span>.
Here I’ve used the notation <span class="math inline">\(n(\cdot)\)</span> to mean the count of the event.
Do this 1,000 times, and count events automatically using the following code.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="conditioning-and-independence.html#cb3-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">size =</span> <span class="dv">1000</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-2"><a href="conditioning-and-independence.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(x, <span class="dv">100</span>)  <span class="co"># show the first 100 outcomes</span></span></code></pre></div>
<pre><code>##   [1] 6 1 2 3 5 3 3 1 4 1 1 5 3 2 2 1 6 3 4 6 1 3 5 4 2 5 1 1 2 3 4 5 5 3 6 1 2
##  [38] 5 5 4 5 2 1 1 3 1 6 5 1 2 4 4 6 6 3 6 6 1 6 2 1 2 4 5 5 6 3 1 4 6 1 6 1 3
##  [75] 6 4 1 6 6 3 6 5 3 6 2 5 5 3 2 2 2 4 2 2 6 4 4 6 1 6</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="conditioning-and-independence.html#cb5-1" aria-hidden="true" tabindex="-1"></a>nA <span class="ot">&lt;-</span> <span class="fu">sum</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>))  <span class="co"># counts the frequency of 2, 4, 6</span></span>
<span id="cb5-2"><a href="conditioning-and-independence.html#cb5-2" aria-hidden="true" tabindex="-1"></a>nB <span class="ot">&lt;-</span> <span class="fu">sum</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>))  <span class="co"># counts the frequency of 1, 2, 3, 4</span></span>
<span id="cb5-3"><a href="conditioning-and-independence.html#cb5-3" aria-hidden="true" tabindex="-1"></a>nAB <span class="ot">&lt;-</span> <span class="fu">sum</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>))  <span class="co"># counts the frequency of 2, 4</span></span>
<span id="cb5-4"><a href="conditioning-and-independence.html#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="conditioning-and-independence.html#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Results</span></span>
<span id="cb5-6"><a href="conditioning-and-independence.html#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">A =</span> nA, <span class="at">B =</span> nB, <span class="at">AnB =</span> nAB) <span class="sc">/</span> <span class="dv">1000</span></span></code></pre></div>
<pre><code>##     A     B   AnB 
## 0.495 0.674 0.333</code></pre>
<p>Empirically, we have <span class="math inline">\(\hat{\mathbb{P}}(A)\hat{\mathbb{P}}(B) =\)</span> 0.495 <span class="math inline">\(\times\)</span> 0.674<span class="math inline">\(=\)</span> 0.33363.
This matches with the value of <span class="math inline">\(\hat{\mathbb{P}}(A \cap B)\)</span> in the table, as well as the theoretical value of 1/3.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="axiomatic-probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/haziqj/adv-stats/edit/main/02-prob_theory.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-adv-stats.pdf", "bookdown-adv-stats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
