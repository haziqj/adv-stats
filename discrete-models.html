<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.1 Discrete models | SM-4331 Advanced Statistics</title>
  <meta name="description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="2.1 Discrete models | SM-4331 Advanced Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.1 Discrete models | SM-4331 Advanced Statistics" />
  
  <meta name="twitter:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

<meta name="author" content="Dr Haziq Jamil" />


<meta name="date" content="2022-03-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="commonly-used-probability-models.html"/>
<link rel="next" href="continuous-models.html"/>
<script src="libs/header-attrs-2.12/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="mystyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SM-4331 Advanced Statistics</a></li>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {extensions: ["cancel.js"]}
});
</script>

<li class="divider"></li>
<li><a href="index.html#about">About<span></span></a></li>
<li class="part"><span><b>I Introduction<span></span></b></span></li>
<li><a href="what-is-statistics.html#what-is-statistics">What is statistics?<span></span></a>
<ul>
<li><a href="learning-statistics.html#learning-statistics">Learning statistics<span></span></a></li>
<li><a href="population-sample-and-parametric-models.html#population-sample-and-parametric-models">Population, sample and parametric models<span></span></a>
<ul>
<li><a href="population-sample-and-parametric-models.html#population-vs-sample">Population vs sample<span></span></a></li>
<li><a href="population-sample-and-parametric-models.html#parametric-models">Parametric models<span></span></a></li>
<li><a href="population-sample-and-parametric-models.html#a-sample-a-set-of-data-or-random-variablesa-duality">A sample: a set of data or random variables?–A duality<span></span></a></li>
<li><a href="population-sample-and-parametric-models.html#variability-of-estimates">Variability of estimates<span></span></a></li>
</ul></li>
<li><a href="probability-and-statistics.html#probability-and-statistics">Probability and statistics<span></span></a></li>
</ul></li>
<li class="part"><span><b>II Prepare<span></span></b></span></li>
<li class="chapter" data-level="1" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html"><i class="fa fa-check"></i><b>1</b> Probability theory primer<span></span></a>
<ul>
<li><a href="probability-theory-primer.html#learning-objectives">Learning objectives<span></span></a></li>
<li><a href="probability-theory-primer.html#readings">Readings<span></span></a></li>
<li class="chapter" data-level="1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html"><i class="fa fa-check"></i><b>1.1</b> Elementary set theory<span></span></a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#set-operations"><i class="fa fa-check"></i><b>1.1.1</b> Set operations<span></span></a></li>
<li class="chapter" data-level="1.1.2" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#partitions"><i class="fa fa-check"></i><b>1.1.2</b> Partitions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html"><i class="fa fa-check"></i><b>1.2</b> Axiomatic probability<span></span></a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#probability-as-a-measure"><i class="fa fa-check"></i><b>1.2.1</b> Probability as a measure<span></span></a></li>
<li class="chapter" data-level="1.2.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>1.2.2</b> Axioms of probability<span></span></a></li>
<li class="chapter" data-level="1.2.3" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#derived-probability-results"><i class="fa fa-check"></i><b>1.2.3</b> Derived probability results<span></span></a></li>
<li class="chapter" data-level="1.2.4" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#why-measure-theory"><i class="fa fa-check"></i><b>1.2.4</b> Why measure theory?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html"><i class="fa fa-check"></i><b>1.3</b> Conditioning and independence<span></span></a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#bayes-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Bayes Theorem<span></span></a></li>
<li class="chapter" data-level="1.3.2" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#independence"><i class="fa fa-check"></i><b>1.3.2</b> Independence<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>1.4</b> Random variables<span></span></a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="random-variables.html"><a href="random-variables.html#distribution-functions"><i class="fa fa-check"></i><b>1.4.1</b> Distribution functions<span></span></a></li>
<li class="chapter" data-level="1.4.2" data-path="random-variables.html"><a href="random-variables.html#identically-distributed-r.v."><i class="fa fa-check"></i><b>1.4.2</b> Identically distributed r.v.<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-functions.html"><a href="probability-functions.html"><i class="fa fa-check"></i><b>1.5</b> Probability functions<span></span></a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probability-functions.html"><a href="probability-functions.html#probability-mass-function"><i class="fa fa-check"></i><b>1.5.1</b> Probability mass function<span></span></a></li>
<li class="chapter" data-level="1.5.2" data-path="probability-functions.html"><a href="probability-functions.html#probability-density-functions"><i class="fa fa-check"></i><b>1.5.2</b> Probability density functions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>1.6</b> Transformations<span></span></a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="transformations.html"><a href="transformations.html#probability-integral-transform"><i class="fa fa-check"></i><b>1.6.1</b> Probability integral transform<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html"><i class="fa fa-check"></i><b>1.7</b> Multiple random variables<span></span></a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#bivariate-distributions"><i class="fa fa-check"></i><b>1.7.1</b> Bivariate distributions<span></span></a></li>
<li class="chapter" data-level="1.7.2" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#marginal-distributions"><i class="fa fa-check"></i><b>1.7.2</b> Marginal distributions<span></span></a></li>
<li class="chapter" data-level="1.7.3" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#conditional-distributions"><i class="fa fa-check"></i><b>1.7.3</b> Conditional distributions<span></span></a></li>
<li class="chapter" data-level="1.7.4" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>1.7.4</b> Independent random variables<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="expectations.html"><a href="expectations.html"><i class="fa fa-check"></i><b>1.8</b> Expectations<span></span></a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="expectations.html"><a href="expectations.html#expectations-of-functions-of-r.v."><i class="fa fa-check"></i><b>1.8.1</b> Expectations of functions of r.v.<span></span></a></li>
<li class="chapter" data-level="1.8.2" data-path="expectations.html"><a href="expectations.html#properties-of-expectations"><i class="fa fa-check"></i><b>1.8.2</b> Properties of expectations<span></span></a></li>
<li class="chapter" data-level="1.8.3" data-path="expectations.html"><a href="expectations.html#variance"><i class="fa fa-check"></i><b>1.8.3</b> Variance<span></span></a></li>
<li class="chapter" data-level="1.8.4" data-path="expectations.html"><a href="expectations.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.8.4</b> Covariance and correlation<span></span></a></li>
<li class="chapter" data-level="1.8.5" data-path="expectations.html"><a href="expectations.html#properties-of-variances-and-covariances"><i class="fa fa-check"></i><b>1.8.5</b> Properties of variances and covariances<span></span></a></li>
<li class="chapter" data-level="1.8.6" data-path="expectations.html"><a href="expectations.html#multivariate-means-and-covariances"><i class="fa fa-check"></i><b>1.8.6</b> Multivariate means and covariances<span></span></a></li>
<li class="chapter" data-level="1.8.7" data-path="expectations.html"><a href="expectations.html#conditional-expectations-and-variance"><i class="fa fa-check"></i><b>1.8.7</b> Conditional expectations and variance<span></span></a></li>
<li class="chapter" data-level="1.8.8" data-path="expectations.html"><a href="expectations.html#additional-explainers"><i class="fa fa-check"></i><b>1.8.8</b> Additional explainers<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html"><i class="fa fa-check"></i><b>1.9</b> Moment generating functions<span></span></a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#moment-generating-functions-1"><i class="fa fa-check"></i><b>1.9.1</b> Moment generating functions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.10</b> Exercises<span></span></a>
<ul>
<li><a href="exercises.html#hand-in-questions">Hand-in questions<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html"><i class="fa fa-check"></i><b>2</b> Commonly-used probability models<span></span></a>
<ul>
<li><a href="commonly-used-probability-models.html#learning-objectives-1">Learning objectives<span></span></a></li>
<li><a href="commonly-used-probability-models.html#readings-1">Readings<span></span></a></li>
<li class="chapter" data-level="2.1" data-path="discrete-models.html"><a href="discrete-models.html"><i class="fa fa-check"></i><b>2.1</b> Discrete models<span></span></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="discrete-models.html"><a href="discrete-models.html#point-mass-distribution"><i class="fa fa-check"></i><b>2.1.1</b> Point mass distribution<span></span></a></li>
<li class="chapter" data-level="2.1.2" data-path="discrete-models.html"><a href="discrete-models.html#uniform-distribution"><i class="fa fa-check"></i><b>2.1.2</b> Uniform distribution<span></span></a></li>
<li class="chapter" data-level="2.1.3" data-path="discrete-models.html"><a href="discrete-models.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.1.3</b> Bernoulli distribution<span></span></a></li>
<li class="chapter" data-level="2.1.4" data-path="discrete-models.html"><a href="discrete-models.html#binomial-distribution"><i class="fa fa-check"></i><b>2.1.4</b> Binomial distribution<span></span></a></li>
<li class="chapter" data-level="2.1.5" data-path="discrete-models.html"><a href="discrete-models.html#geometric-distribution"><i class="fa fa-check"></i><b>2.1.5</b> Geometric distribution<span></span></a></li>
<li class="chapter" data-level="2.1.6" data-path="discrete-models.html"><a href="discrete-models.html#negative-binomial"><i class="fa fa-check"></i><b>2.1.6</b> Negative binomial<span></span></a></li>
<li class="chapter" data-level="2.1.7" data-path="discrete-models.html"><a href="discrete-models.html#poisson-distribution"><i class="fa fa-check"></i><b>2.1.7</b> Poisson distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continuous-models.html"><a href="continuous-models.html"><i class="fa fa-check"></i><b>2.2</b> Continuous models<span></span></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="continuous-models.html"><a href="continuous-models.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>2.2.1</b> Continuous uniform distribution<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="continuous-models.html"><a href="continuous-models.html#exponential-distribution"><i class="fa fa-check"></i><b>2.2.2</b> Exponential distribution<span></span></a></li>
<li class="chapter" data-level="2.2.3" data-path="continuous-models.html"><a href="continuous-models.html#gamma-distribution"><i class="fa fa-check"></i><b>2.2.3</b> Gamma distribution<span></span></a></li>
<li class="chapter" data-level="2.2.4" data-path="continuous-models.html"><a href="continuous-models.html#beta-distribution"><i class="fa fa-check"></i><b>2.2.4</b> Beta distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Normal distribution<span></span></a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="normal-distribution.html"><a href="normal-distribution.html#location-and-scale-parameter"><i class="fa fa-check"></i><b>2.3.1</b> Location and scale parameter<span></span></a></li>
<li class="chapter" data-level="2.3.2" data-path="normal-distribution.html"><a href="normal-distribution.html#linear-transformations-of-normal-random-variables"><i class="fa fa-check"></i><b>2.3.2</b> Linear transformations of normal random variables<span></span></a></li>
<li class="chapter" data-level="2.3.3" data-path="normal-distribution.html"><a href="normal-distribution.html#the-normal-cdf"><i class="fa fa-check"></i><b>2.3.3</b> The normal cdf<span></span></a></li>
<li class="chapter" data-level="2.3.4" data-path="normal-distribution.html"><a href="normal-distribution.html#rule"><i class="fa fa-check"></i><b>2.3.4</b> 68–95–99.7 Rule<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="some-relationships.html"><a href="some-relationships.html"><i class="fa fa-check"></i><b>2.4</b> Some relationships<span></span></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="some-relationships.html"><a href="some-relationships.html#poisson-binomial-relationship"><i class="fa fa-check"></i><b>2.4.1</b> Poisson-Binomial relationship<span></span></a></li>
<li class="chapter" data-level="2.4.2" data-path="some-relationships.html"><a href="some-relationships.html#poisson-exponential"><i class="fa fa-check"></i><b>2.4.2</b> Poisson-Exponential<span></span></a></li>
<li class="chapter" data-level="2.4.3" data-path="some-relationships.html"><a href="some-relationships.html#poisson-gamma"><i class="fa fa-check"></i><b>2.4.3</b> Poisson-Gamma<span></span></a></li>
<li class="chapter" data-level="2.4.4" data-path="some-relationships.html"><a href="some-relationships.html#normal-approximations"><i class="fa fa-check"></i><b>2.4.4</b> Normal approximations<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.5</b> Exercises<span></span></a>
<ul>
<li><a href="exercises-1.html#hand-in-questions-1">Hand-in questions<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html"><i class="fa fa-check"></i><b>3</b> Inequalities, convergences, and normal random samples<span></span></a>
<ul>
<li><a href="inequalities-convergences-and-normal-random-samples.html#learning-objectives-2">Learning objectives<span></span></a></li>
<li><a href="inequalities-convergences-and-normal-random-samples.html#readings-2">Readings<span></span></a></li>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction<span></span></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#independent-and-identical-random-variable"><i class="fa fa-check"></i><b>3.1.1</b> Independent and identical random variable<span></span></a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#statistic"><i class="fa fa-check"></i><b>3.1.2</b> Statistic<span></span></a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Sampling distribution<span></span></a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#large-sample-approximation"><i class="fa fa-check"></i><b>3.1.4</b> Large-sample approximation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>3.2</b> Inequalities<span></span></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inequalities.html"><a href="inequalities.html#markovs-inequality"><i class="fa fa-check"></i><b>3.2.1</b> Markov’s inequality<span></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="inequalities.html"><a href="inequalities.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>3.2.2</b> Chebyshev’s inequality<span></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="inequalities.html"><a href="inequalities.html#cauchy-schwartz-inequality"><i class="fa fa-check"></i><b>3.2.3</b> Cauchy-Schwartz inequality<span></span></a></li>
<li class="chapter" data-level="3.2.4" data-path="inequalities.html"><a href="inequalities.html#jensens-inequality"><i class="fa fa-check"></i><b>3.2.4</b> Jensen’s inequality<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html"><i class="fa fa-check"></i><b>3.3</b> Convergence of random variables<span></span></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.3.1</b> Convergence in probability<span></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Convergence in distribution<span></span></a></li>
<li class="chapter" data-level="3.3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#mean-square-convergence"><i class="fa fa-check"></i><b>3.3.3</b> Mean-square convergence<span></span></a></li>
<li class="chapter" data-level="3.3.4" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#relationship-between-convergences"><i class="fa fa-check"></i><b>3.3.4</b> Relationship between convergences<span></span></a></li>
<li class="chapter" data-level="3.3.5" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#slutzkys-theorem"><i class="fa fa-check"></i><b>3.3.5</b> Slutzky’s Theorem<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>3.4</b> Limit theorems<span></span></a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="limit-theorems.html"><a href="limit-theorems.html#the-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>3.4.1</b> The (weak) Law of Large Numbers<span></span></a></li>
<li class="chapter" data-level="3.4.2" data-path="limit-theorems.html"><a href="limit-theorems.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4.2</b> The Central Limit Theorem<span></span></a></li>
<li class="chapter" data-level="3.4.3" data-path="limit-theorems.html"><a href="limit-theorems.html#gauging-the-error-of-sample-mean-estimator"><i class="fa fa-check"></i><b>3.4.3</b> Gauging the error of sample mean estimator<span></span></a></li>
<li class="chapter" data-level="3.4.4" data-path="limit-theorems.html"><a href="limit-theorems.html#clt-with-sigma2-unknown"><i class="fa fa-check"></i><b>3.4.4</b> CLT with <span class="math inline">\(\sigma^2\)</span> unknown<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>3.5</b> Delta method<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="normal-random-samples.html"><a href="normal-random-samples.html"><i class="fa fa-check"></i><b>3.6</b> Normal random samples<span></span></a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="normal-random-samples.html"><a href="normal-random-samples.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6.1</b> <span class="math inline">\(\chi^2\)</span>-distribution<span></span></a></li>
<li class="chapter" data-level="3.6.2" data-path="normal-random-samples.html"><a href="normal-random-samples.html#students-t-distribution"><i class="fa fa-check"></i><b>3.6.2</b> Student’s <span class="math inline">\(t\)</span>-distribution<span></span></a></li>
<li class="chapter" data-level="3.6.3" data-path="normal-random-samples.html"><a href="normal-random-samples.html#proof-of-theorem-refthmpropertynormalsamp"><i class="fa fa-check"></i><b>3.6.3</b> Proof of Theorem @ref(thm:propertynormalsamp)<span></span></a></li>
<li class="chapter" data-level="3.6.4" data-path="normal-random-samples.html"><a href="normal-random-samples.html#f-distribution"><i class="fa fa-check"></i><b>3.6.4</b> <span class="math inline">\(F\)</span>-distribution<span></span></a></li>
<li class="chapter" data-level="3.6.5" data-path="normal-random-samples.html"><a href="normal-random-samples.html#the-analysis-of-variance"><i class="fa fa-check"></i><b>3.6.5</b> The analysis of variance<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.7</b> Exercises<span></span></a>
<ul>
<li><a href="exercises-2.html#hand-in-questions-2">Hand-in questions<span></span></a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Inference<span></span></b></span></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation<span></span></a>
<ul>
<li><a href="point-estimation.html#learning-objectives-3">Learning objectives<span></span></a></li>
<li><a href="point-estimation.html#readings-3">Readings<span></span></a></li>
<li class="chapter" data-level="4.1" data-path="the-likelihood.html"><a href="the-likelihood.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood<span></span></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="the-likelihood.html"><a href="the-likelihood.html#calculating-the-likelihood"><i class="fa fa-check"></i><b>4.1.1</b> Calculating the likelihood<span></span></a></li>
<li class="chapter" data-level="4.1.2" data-path="the-likelihood.html"><a href="the-likelihood.html#likelihood-ratio"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood ratio<span></span></a></li>
<li class="chapter" data-level="4.1.3" data-path="the-likelihood.html"><a href="the-likelihood.html#log-likelihood"><i class="fa fa-check"></i><b>4.1.3</b> Log likelihood<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sufficiency.html"><a href="sufficiency.html"><i class="fa fa-check"></i><b>4.2</b> Sufficiency<span></span></a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sufficiency.html"><a href="sufficiency.html#the-factorisation-theorem"><i class="fa fa-check"></i><b>4.2.1</b> The factorisation theorem<span></span></a></li>
<li class="chapter" data-level="4.2.2" data-path="sufficiency.html"><a href="sufficiency.html#minimal-sufficient-statistic"><i class="fa fa-check"></i><b>4.2.2</b> Minimal sufficient statistic<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="point-estimators.html"><a href="point-estimators.html"><i class="fa fa-check"></i><b>4.3</b> Point estimators<span></span></a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>4.4</b> Method of moments<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>4.5</b> Method of maximum likelihood<span></span></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#finding-the-mle"><i class="fa fa-check"></i><b>4.5.1</b> Finding the MLE<span></span></a></li>
<li class="chapter" data-level="4.5.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#invariance-of-mle"><i class="fa fa-check"></i><b>4.5.2</b> Invariance of MLE<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html"><i class="fa fa-check"></i><b>4.6</b> Evaluating estimators<span></span></a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#bias"><i class="fa fa-check"></i><b>4.6.1</b> Bias<span></span></a></li>
<li class="chapter" data-level="4.6.2" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#variance-and-standard-error"><i class="fa fa-check"></i><b>4.6.2</b> Variance and standard error<span></span></a></li>
<li class="chapter" data-level="4.6.3" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>4.6.3</b> Mean squared error<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html"><i class="fa fa-check"></i><b>4.7</b> Cramér-Rao lower bound (CRLB)<span></span></a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#fisher-information"><i class="fa fa-check"></i><b>4.7.1</b> Fisher information<span></span></a></li>
<li class="chapter" data-level="4.7.2" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#variance-reduction-rao-blackwellisation"><i class="fa fa-check"></i><b>4.7.2</b> Variance reduction: Rao-Blackwellisation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html"><i class="fa fa-check"></i><b>4.8</b> Large sample properties of estimators<span></span></a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency"><i class="fa fa-check"></i><b>4.8.1</b> Consistency<span></span></a></li>
<li class="chapter" data-level="4.8.2" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-vs-unbiasedness"><i class="fa fa-check"></i><b>4.8.2</b> Consistency vs unbiasedness<span></span></a></li>
<li class="chapter" data-level="4.8.3" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-of-mles"><i class="fa fa-check"></i><b>4.8.3</b> Consistency of MLEs<span></span></a></li>
<li class="chapter" data-level="4.8.4" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency"><i class="fa fa-check"></i><b>4.8.4</b> Efficiency<span></span></a></li>
<li class="chapter" data-level="4.8.5" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#asymptotic-normality-and-consistency"><i class="fa fa-check"></i><b>4.8.5</b> Asymptotic normality and consistency<span></span></a></li>
<li class="chapter" data-level="4.8.6" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-mle"><i class="fa fa-check"></i><b>4.8.6</b> Efficiency of MLE<span></span></a></li>
<li class="chapter" data-level="4.8.7" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-transformations-of-mle"><i class="fa fa-check"></i><b>4.8.7</b> Efficiency of transformations of MLE<span></span></a></li>
<li class="chapter" data-level="4.8.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#application-of-asymptotic-normality"><i class="fa fa-check"></i><b>4.8.8</b> Application of asymptotic normality<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.9</b> Exercises<span></span></a>
<ul>
<li><a href="exercises-3.html#hand-in-questions-3">Hand-in questions<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing<span></span></a>
<ul>
<li><a href="hypothesis-testing.html#learning-objectives-4">Learning objectives<span></span></a></li>
<li><a href="hypothesis-testing.html#readings-4">Readings<span></span></a></li>
<li class="chapter" data-level="5.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction<span></span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-1.html"><a href="introduction-1.html#a-general-paradigm"><i class="fa fa-check"></i><b>5.1.1</b> A general paradigm<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-1.html"><a href="introduction-1.html#p-values"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(p\)</span>-values<span></span></a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-1.html"><a href="introduction-1.html#accept-h_0"><i class="fa fa-check"></i><b>5.1.3</b> Accept <span class="math inline">\(H_0\)</span>?<span></span></a></li>
<li class="chapter" data-level="5.1.4" data-path="introduction-1.html"><a href="introduction-1.html#uniformity-of-p-values"><i class="fa fa-check"></i><b>5.1.4</b> Uniformity of <span class="math inline">\(p\)</span>-values<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>5.2</b> Likelihood ratio test<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#log-likelihood-ratio-test-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Log likelihood ratio test statistic<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.2</b> Example: Normal with known variance<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-unknown-variance-t-test"><i class="fa fa-check"></i><b>5.2.3</b> Example: Normal with unknown variance (<span class="math inline">\(t\)</span>-test)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html"><i class="fa fa-check"></i><b>5.3</b> The Neyman-Pearson approach<span></span></a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#performance-of-a-test"><i class="fa fa-check"></i><b>5.3.1</b> Performance of a test<span></span></a></li>
<li class="chapter" data-level="5.3.2" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#relation-to-p-values"><i class="fa fa-check"></i><b>5.3.2</b> Relation to <span class="math inline">\(p\)</span>-values<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html"><i class="fa fa-check"></i><b>5.4</b> Type I and II errors<span></span></a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#minimising-errors"><i class="fa fa-check"></i><b>5.4.1</b> Minimising errors<span></span></a></li>
<li class="chapter" data-level="5.4.2" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#optimality-of-the-lr-test"><i class="fa fa-check"></i><b>5.4.2</b> Optimality of the LR test<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sided-tests.html"><a href="one-sided-tests.html"><i class="fa fa-check"></i><b>5.5</b> One-sided tests<span></span></a></li>
<li class="chapter" data-level="5.6" data-path="approximate-tests.html"><a href="approximate-tests.html"><i class="fa fa-check"></i><b>5.6</b> Approximate tests<span></span></a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="approximate-tests.html"><a href="approximate-tests.html#asymptotic-distribution-of-lrts"><i class="fa fa-check"></i><b>5.6.1</b> Asymptotic distribution of LRTs<span></span></a></li>
<li class="chapter" data-level="5.6.2" data-path="approximate-tests.html"><a href="approximate-tests.html#wilks-theorem"><i class="fa fa-check"></i><b>5.6.2</b> Wilk’s theorem<span></span></a></li>
<li class="chapter" data-level="5.6.3" data-path="approximate-tests.html"><a href="approximate-tests.html#the-wald-test"><i class="fa fa-check"></i><b>5.6.3</b> The Wald test<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.7</b> Exercises<span></span></a>
<ul>
<li><a href="exercises-4.html#hand-in-questions-4">Hand-in questions<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>6</b> Interval estimation<span></span></a>
<ul>
<li><a href="interval-estimation.html#learning-objectives-5">Learning objectives<span></span></a></li>
<li><a href="interval-estimation.html#readings-5">Readings<span></span></a></li>
<li class="chapter" data-level="6.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>6.1</b> Introduction<span></span></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-2.html"><a href="introduction-2.html#coverage-probability"><i class="fa fa-check"></i><b>6.1.1</b> Coverage probability<span></span></a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-2.html"><a href="introduction-2.html#confidence-regions"><i class="fa fa-check"></i><b>6.1.2</b> Confidence regions<span></span></a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-2.html"><a href="introduction-2.html#methods-for-obtaining-confidence-regions"><i class="fa fa-check"></i><b>6.1.3</b> Methods for obtaining confidence regions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pivots.html"><a href="pivots.html"><i class="fa fa-check"></i><b>6.2</b> Pivots<span></span></a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pivots.html"><a href="pivots.html#from-pivot-to-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> From pivot to confidence interval<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Inverting a test statistic<span></span></a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html#discrete-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Discrete distributions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="desirable-confidence-sets.html"><a href="desirable-confidence-sets.html"><i class="fa fa-check"></i><b>6.4</b> Desirable confidence sets<span></span></a></li>
<li class="chapter" data-level="6.5" data-path="intervals-based-on-ml-methods.html"><a href="intervals-based-on-ml-methods.html"><i class="fa fa-check"></i><b>6.5</b> Intervals based on ML methods<span></span></a></li>
<li class="chapter" data-level="6.6" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>6.6</b> The bootstrap method<span></span></a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#empirical-distribution"><i class="fa fa-check"></i><b>6.6.1</b> Empirical distribution<span></span></a></li>
<li class="chapter" data-level="6.6.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-variance-estimation"><i class="fa fa-check"></i><b>6.6.2</b> Bootstrap variance estimation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap confidence intervals<span></span></a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#normal-bootstrap-interval"><i class="fa fa-check"></i><b>6.7.1</b> Normal bootstrap interval<span></span></a></li>
<li class="chapter" data-level="6.7.2" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-percentile-interval"><i class="fa fa-check"></i><b>6.7.2</b> Bootstrap percentile interval<span></span></a></li>
<li class="chapter" data-level="6.7.3" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-pivotal-interval"><i class="fa fa-check"></i><b>6.7.3</b> Bootstrap pivotal interval<span></span></a></li>
<li class="chapter" data-level="6.7.4" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#which-one-to-use"><i class="fa fa-check"></i><b>6.7.4</b> Which one to use?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises<span></span></a>
<ul>
<li><a href="exercises-5.html#hand-in-questions-5">Hand-in questions<span></span></a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix<span></span></b></span></li>
<li class="chapter" data-level="A" data-path="exam-tips.html"><a href="exam-tips.html"><i class="fa fa-check"></i><b>A</b> Exam tips<span></span></a></li>
<li><a href="references.html#references">References<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SM-4331 Advanced Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discrete-models" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Discrete models<a href="discrete-models.html#discrete-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we’ll be describing commonly used <strong>discrete</strong> probability distributions.</p>
<div id="point-mass-distribution" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Point mass distribution<a href="discrete-models.html#point-mass-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The random variable <span class="math inline">\(X\)</span> has a point mass distribution at <span class="math inline">\(a\)</span>, written <span class="math inline">\(X\sim \delta_a\)</span>, if <span class="math inline">\(\Pr(X=a) = 1\)</span>, in which case
<span class="math display">\[
F(x) = \begin{cases}
0 &amp;x&lt;a \\
1 &amp;x\geq a.
\end{cases}
\]</span></p>
<p>The probability mass function is <span class="math inline">\(f(x)=1\)</span> for <span class="math inline">\(x=a\)</span>, and 0 otherwise.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pointmasspdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/pointmasspdfcdf-1.png" alt="Pdf and cdf of the point mass distribution." width="100%" />
<p class="caption">
Figure 2.1: Pdf and cdf of the point mass distribution.
</p>
</div>
<p>The mean and variance are trivial: <span class="math inline">\(\mathop{\mathrm{E}}(X)=a\)</span> and <span class="math inline">\(\mathop{\mathrm{Var}}(X)=0\)</span>, because the “random” variable <span class="math inline">\(X\)</span> takes on the value <span class="math inline">\(a\)</span> with probability 1 (certainty).</p>
<p>There isn’t much practical use for point mass distributions to be honest, but sometimes they are used to describe <em>mixture</em> distributions.
For example, a random variable might be equal to <span class="math inline">\(0\)</span> half of the time, but may be normally distributed the other half of the time.</p>
</div>
<div id="uniform-distribution" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Uniform distribution<a href="discrete-models.html#uniform-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(k&gt;1\)</span> be a given integer. The discrete uniform distribution on <span class="math inline">\(\{1,\dots,k\}\)</span> has pmf
<span class="math display">\[
f(x) = \frac{1}{k}, \hspace{2em} x=1,\dots,k.
\]</span>
We write <span class="math inline">\(X\sim\mathop{\mathrm{Unif}}\{1,\dots,k\}\)</span>. Its mean and variance are</p>
<ul>
<li><span class="math inline">\(\mathop{\mathrm{E}}(X)=\frac{k+1}{2}\)</span>; and</li>
<li><span class="math inline">\(\mathop{\mathrm{Var}}(X)=\frac{k^2-1}{12}\)</span>.</li>
</ul>
<p>The mean of the discrete uniform is intuitive; it is the half-way point between 1 and <span class="math inline">\(k\)</span>.
The discrete uniform (and the point mass) is appeallingly simple but has relatively few “real” statistical applications.</p>
<div class="proof">
<p><span id="unlabeled-div-69" class="proof"><em>Proof</em>. </span>Using the arithmetic series formulae <span class="math inline">\(\sum_{i=1}^n x = n(n+1)/2\)</span> and <span class="math inline">\(\sum_{i=1}^n x^2 = n(n+1)(2n+1)/6\)</span>, we have</p>
<p><span class="math display">\[\begin{align*}
\mathop{\mathrm{E}}(X) &amp;= \sum_{x=1}^k \frac{x}{k}\\
&amp;= \frac{k(k+1)}{2k}  \\
&amp;= \frac{k+1}{2},
\end{align*}\]</span>
and
<span class="math display">\[\begin{align*}
\mathop{\mathrm{E}}(X^2) &amp;= \sum_{x=1}^k  \frac{x^2}{k}\\
&amp;= \frac{k(k+1)(2k+1)}{6k}  \\
&amp;= \frac{(k+1)(2k+1)}{6},
\end{align*}\]</span>
hence
<span class="math display">\[\begin{align*}
\mathop{\mathrm{Var}}(X) &amp;= \mathop{\mathrm{E}}(X^2) - \mathop{\mathrm{E}}^2(X) \\
&amp;= \frac{(k+1)(2k+1)}{6} - \frac{(k+1)^2}{4} \\
&amp;= \frac{2(k+1)(2k+1)-3(k+1)^2}{12} \\
&amp;= \frac{k^2-1}{12}.
\end{align*}\]</span></p>
</div>
<p><br></p>
<div class="mynote">
<p>If <span class="math inline">\(k=1\)</span>, then it is the point mass distribution. But actually, we can use whatever labels we want for the values <span class="math inline">\(1,2,\dots,k\)</span>. For example, suppose we are picking between 3 colours uniformly, then we can describe a uniform distribution on <span class="math inline">\(\{1 = \text{red}, 2= \text{green}, 3=\text{blue} \}\)</span>.</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:uniformpdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/uniformpdfcdf-1.png" alt="Pdf and cdf of the discrete uniform distribution for \(k=4\)." width="100%" />
<p class="caption">
Figure 2.2: Pdf and cdf of the discrete uniform distribution for <span class="math inline">\(k=4\)</span>.
</p>
</div>
</div>
<div id="bernoulli-distribution" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Bernoulli distribution<a href="discrete-models.html#bernoulli-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we are interested in the outcome of a (single) random trial, which can either be <span class="myrtlegreen">“success”</span> or <span class="solidpink">“failure”</span> only. Examples include</p>
<ul>
<li>A coin flip can land either <span class="myrtlegreen">Heads</span> or <span class="solidpink">Tails</span>.</li>
<li>The colour of the suit of a randomly drawn card from a pack of playing cards can be either <span class="myrtlegreen">Red</span> or <span class="solidpink">Black</span></li>
<li>A dice roll outcome can either be an <span class="myrtlegreen">Even</span> or an <span class="solidpink">Odd</span> number.</li>
<li>Babies being born being <span class="myrtlegreen">Girl</span> or <span class="solidpink">Boy</span>.</li>
</ul>
<p>Typically we assign the value ‘1’ to denote success, and ‘0’ to denote failure.
This has no qualitative meaning whatsoever, the important thing is that there are only two distinct possible outcomes.
As a consequence, any discrete random variable that can take on only two possible outcomes is a Bernoulli random variable.</p>
<p>Let <span class="math inline">\(X\)</span> be the r.v. denoting the outcome of success (<span class="math inline">\(X=1\)</span>) or failure (<span class="math inline">\(X=0\)</span>) of a binary trial.
Further let the pmf for <span class="math inline">\(X\)</span> be
<span class="math display">\[
f(x|p) = \begin{cases}
p &amp; x=1\text{ (success)}\\
1-p &amp;x=0 \text{ (failure)}
\end{cases}
\]</span>
We say that <span class="math inline">\(X\)</span> has a Bernoulli distribution written <span class="math inline">\(X\sim\mathop{\mathrm{Bern}}(p)\)</span>.</p>
<ul>
<li>The expectation is
<span class="math display">\[
\mathop{\mathrm{E}}(X) = \sum_x xf(x) = 1\cdot p + 0 \cdot (1-p) = p.
\]</span></li>
<li>The variance is
<span class="math display">\[
\mathop{\mathrm{Var}}(X) = \sum_x (x-\mu)^2f(x) = (1-p)^2\cdot p + (0-p)^2 \cdot (1-p) = p(1-p).
\]</span></li>
</ul>
<p>Again the expectation is intuitive here.
If a proportion <span class="math inline">\(p\)</span> of the time we get success, then surely the expectation must be this proportion <span class="math inline">\(p\)</span>.</p>
<div class="mycheck">
<p>The pmf for the Bernoulli distribution can also be written <span class="math inline">\(f(x)=p^x(1-p)^{1-x}\)</span>.
Try plugging in <span class="math inline">\(x=1\)</span> and <span class="math inline">\(x=0\)</span> into this function.
Do you get the appropriate probabilities?</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bernoullipdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/bernoullipdfcdf-1.png" alt="Pdf and cdf of the Bernoulli distribution." width="100%" />
<p class="caption">
Figure 2.3: Pdf and cdf of the Bernoulli distribution.
</p>
</div>
</div>
<div id="binomial-distribution" class="section level3 hasAnchor" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> Binomial distribution<a href="discrete-models.html#binomial-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A related distribution to the Bernoulli is the binomial distribution.
It describes the distribution of the number of “successes” in <span class="math inline">\(n\)</span> independent and identical binary “trials”.
That is, suppose we have a situation such that</p>
<ul>
<li>A finite number <span class="math inline">\(n\)</span> trials are carried out.</li>
<li>Each trial is independent of each other.</li>
<li>The outcome of each trial is either success or failure (binary trials).</li>
<li>The probability <span class="math inline">\(0 \leq p\leq 1\)</span> of a successful outcome is the same for each trial.</li>
</ul>
<p>Let <span class="math inline">\(X\)</span> be the number of success outcomes in <span class="math inline">\(n\)</span> trials. Then <span class="math inline">\(X\)</span> has a binomial distribution, written <span class="math inline">\(X\sim\mathop{\mathrm{Bin}}(n,p)\)</span>.
The pmf of <span class="math inline">\(X\)</span> is
<span class="math display">\[
f(x|n,p) = {n \choose x}p^x (1-p)^{n-x}.
\]</span>
<span class="math inline">\(X\)</span> has support (possible values it can take) over <span class="math inline">\(\{0,1,2,\dots,n\}\)</span>.
The mean and variance are <span class="math inline">\(\mathop{\mathrm{E}}(X)=np\)</span> and <span class="math inline">\(\mathop{\mathrm{Var}}(X)=np(1-p)\)</span>.</p>
<div class="proof">
<p><span id="unlabeled-div-70" class="proof"><em>Proof</em>. </span>Here’s the proof for the mean.
<span class="math display">\[\begin{align*}
\mathop{\mathrm{E}}(X) 
&amp;= \sum_{x=0}^n x \frac{n!}{x!(n-x)!} p^x (1-p)^{n-x} \\
&amp;= \sum_{x=1}^n x \frac{n!}{x!(n-x)!} p^x (1-p)^{n-x} \\
&amp;=\sum_{x=1}^n n \cdot \overbrace{\frac{(n-1)!}{(x-1)!(n-x)!}}^{{n-1 \choose x-1}} \cdot p^{x-1+1} (1-p)^{(n-1)-(x-1)} \\
&amp;= np \overbrace{\sum_{x-1=0}^n  {n-1 \choose x-1} p^{x-1} (1-p)^{n-x}}^{=1} \\
&amp;= np. 
\end{align*}\]</span>
Obtaining the variance follows similar steps.</p>
</div>
<div class="mycheck">
<p>Try to replicate the proof above and obtain <span class="math inline">\(\mathop{\mathrm{E}}(X^2)\)</span> for the binomial distribution. After that, you may obtain <span class="math inline">\(\mathop{\mathrm{Var}}(X)\)</span> using the usual formula.
An alternative way is to use mgfs–keep on reading.</p>
</div>
<p>For the more astute of you, you might have realised that the binomial distribution is simply counting the number of successes in many independent Bernoulli trials.
Indeed, that is the case.</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-71" class="lemma"><strong>Lemma 2.1  </strong></span>Let <span class="math inline">\(X_1,\dots,X_n\,\overset{\text{iid}}{\sim}\,\mathop{\mathrm{Bern}}(p)\)</span>, then
<span class="math display">\[
X = \sum_{i=1}^n X_i \sim \mathop{\mathrm{Bin}}(n,p)
\]</span></p>
</div>
<div class="mycheck">
<p>The lemma is proven using mgfs, and is left to you as an exercise.
First, obtain the mgf for Bernoulli and binomial distributions.
Then use the sum property of the mgfs characterise the distribution of the sum.</p>
</div>
<p>Using the lemma above, we can more easily derive that
<span class="math display">\[
\mathop{\mathrm{E}}(X) = \mathop{\mathrm{E}}\left(\sum_{i=1}^n X_i \right) = \sum_{i=1}^n \mathop{\mathrm{E}}(X_i) = np
\]</span>
and
<span class="math display">\[
\mathop{\mathrm{Var}}(X) = \mathop{\mathrm{Var}}\left(\sum_{i=1}^n X_i \right) = \sum_{i=1}^n \mathop{\mathrm{Var}}(X_i) = np(1-p)
\]</span>
simply using properties of expectations and variances.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:binomialpdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/binomialpdfcdf-1.png" alt="Pdf and cdf of the binomial distribution with \(p=0.3\)." width="100%" />
<p class="caption">
Figure 2.4: Pdf and cdf of the binomial distribution with <span class="math inline">\(p=0.3\)</span>.
</p>
</div>
</div>
<div id="geometric-distribution" class="section level3 hasAnchor" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Geometric distribution<a href="discrete-models.html#geometric-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The geometric distribution is a type of “waiting time” distribution.
It involves counting the number of Bernoulli trials to get the first success.
Let <span class="math inline">\(X\)</span> be distributed geometrically, <span class="math inline">\(X\sim\mathop{\mathrm{Geom}}(p)\)</span>, where <span class="math inline">\(p\)</span> is the probability of success. Clearly,
<span class="math display">\[
  f(x|p)=(1-p)^{x-1}p.
\]</span>
The support of <span class="math inline">\(X\)</span> is <span class="math inline">\(\{1,2,3,\dots\}\)</span>; it is countably infinite.</p>
<p>This is a valid pmf since
<span class="math display">\[\begin{align*}
\sum_{x=1}^\infty f(x|p) 
&amp;= \sum_{x=1}^\infty (1-p)^{x-1}p  \\
&amp;= \frac{p}{1-(1-p)} = 1.
\end{align*}\]</span></p>
<p>This required knowledge of the infinite geometric series <span class="math inline">\(\sum_{k=0}^\infty ar^k = a/(1-r)\)</span> for <span class="math inline">\(|r|&lt;1\)</span>.
The mean and variance of the geometric distribution are:</p>
<ul>
<li><span class="math inline">\(\mathop{\mathrm{E}}(X)=\frac{1}{p}\)</span>. The smaller the <span class="math inline">\(p\)</span>, the longer we have to wait for a success.</li>
<li><span class="math inline">\(\mathop{\mathrm{Var}}(X)=\frac{1-p}{p^2}\)</span>.</li>
</ul>
<div class="mywarning">
<p>There is another formulation for the geometric distribution: Let <span class="math inline">\(Y\)</span> be the number of failures before the first success occurs. Then
<span class="math display">\[
f(y|p) = (1-p)^yp.
\]</span>
<span class="math inline">\(Y\)</span> has support <span class="math inline">\(\{0,1,2,\dots\}\)</span>. <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are related through <span class="math inline">\(Y=X-1\)</span>. Thus it is easy to check
that
<span class="math display">\[
\mathop{\mathrm{E}}(Y) = \frac{1-p}{p} \text{ and } \mathop{\mathrm{Var}}(Y)=\frac{1-p}{p^2}.
\]</span>
We shall mainly use the first version of the geometric distribution in this course, but be aware of the alternative version as well.</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:geometricpdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/geometricpdfcdf-1.png" alt="Pdf and cdf of the geometric distribution with \(p=0.4\)." width="100%" />
<p class="caption">
Figure 2.5: Pdf and cdf of the geometric distribution with <span class="math inline">\(p=0.4\)</span>.
</p>
</div>
</div>
<div id="negative-binomial" class="section level3 hasAnchor" number="2.1.6">
<h3><span class="header-section-number">2.1.6</span> Negative binomial<a href="discrete-models.html#negative-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we count the number of Bernoulli trials required to get a fixed number of successes, <span class="math inline">\(r\)</span>, each with probability of success <span class="math inline">\(p\)</span>.
This leads to the negative binomial distribution.
Denote this by <span class="math inline">\(X\sim\mathop{\mathrm{NBin}}(r,p)\)</span>. The pmf is
<span class="math display">\[
  f(x|r,p)= {x-1 \choose r-1} p^r (1-p)^{x-r}.
\]</span></p>
<p>The pmf is easy to justify: In order to get <span class="math inline">\(X=x\)</span>, a total of <span class="math inline">\(r-1\)</span> successes must have occurred in the previous <span class="math inline">\(x-1\)</span> number of trials. Then, the pmf follows directly from the binomial pmf.</p>
<p>Clearly, the support of <span class="math inline">\(X\)</span> is <span class="math inline">\(\{r, r+1, r+2, \dots \}\)</span>.
The expectation and variance of <span class="math inline">\(X\)</span> are</p>
<ul>
<li><span class="math inline">\(\mathop{\mathrm{E}}(X)=\frac{r}{p}\)</span>.</li>
<li><span class="math inline">\(\mathop{\mathrm{Var}}(X)=\frac{r(1-p)}{p^2}\)</span>.</li>
</ul>
<p>Note that if <span class="math inline">\(r=1\)</span>, then <span class="math inline">\(X\)</span> is the geometric distribution.</p>
<div class="mynote">
<p>The name ‘negative binomial’ comes from noting that <span class="math inline">\(Y=X-r\)</span>, the number of failures seen before the <span class="math inline">\(r\)</span>th success, has pmf
<span class="math display">\[
  f(y|r,p) = (-1)^y{-r \choose y} p^r(1-p)^{r-y},
\]</span>
which looks suspiciously close to the binomial pmf<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a>.</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:negbinomialpdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/negbinomialpdfcdf-1.png" alt="Pdf and cdf of the negative binomial distribution with \(p=0.3\) and \(r=5\)." width="100%" />
<p class="caption">
Figure 2.6: Pdf and cdf of the negative binomial distribution with <span class="math inline">\(p=0.3\)</span> and <span class="math inline">\(r=5\)</span>.
</p>
</div>
<div class="mywarning">
<p>Just a caution to say that the negative binomial has many different parameterisations.
It all depends whether</p>
<ul>
<li>The random variable <span class="math inline">\(X\)</span> is counting the number of trials until a fixed success, or counting the number of successes before a fixed number of failures occur;</li>
<li><span class="math inline">\(p\)</span> denotes success or failure;</li>
<li><span class="math inline">\(r\)</span> denotes success or failure.</li>
</ul>
<p>See here for more details: <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations" class="uri">https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations</a></p>
</div>
</div>
<div id="poisson-distribution" class="section level3 hasAnchor" number="2.1.7">
<h3><span class="header-section-number">2.1.7</span> Poisson distribution<a href="discrete-models.html#poisson-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Poisson is the most standard assumption for the distribution of a count of events that occur (separately and independently, by assumption) in time or space. Some examples:</p>
<ul>
<li>Amount of e-mails received in 24-hour period.</li>
<li>Number of calls received by a call centre per hour.</li>
<li>The number of photons hitting a detector in a particular time interval.</li>
<li>The number of patients arriving in an emergency room between 10pm and 11pm.</li>
</ul>
<p>Let <span class="math inline">\(X\)</span> be the number of occurrences in this interval, such that the mean number of occurrences <span class="math inline">\(\lambda\)</span> in the given interval (sometimes called the rate or intensity) is known and is finite. Then <span class="math inline">\(X\sim\mathop{\mathrm{Poi}}(\lambda),\)</span> and
<span class="math display">\[
f(x|\lambda) = \frac{e^{-\lambda}\lambda^x}{x!},
\]</span>
for <span class="math inline">\(x=0,1,2,\dots\)</span></p>
<p>To work out the mean, we make use of the Taylor series expansion.
Recall that <span class="math inline">\(e^x=\sum_{k=0}^\infty \frac{x^k}{k!}\)</span>.
Using this fact we can derive the moments through the mgf.</p>
<p><span class="math display">\[\begin{align*}
M_X(t)
&amp;= \sum_{x=0}^\infty \frac{e^{tx} e^{-\lambda}\lambda^x}{x!} \\
&amp;= e^{-\lambda} \sum_{x=0}^\infty \frac{(\lambda e^t)^x}{x!} \\
&amp;= e^{-\lambda}e^{\lambda e^t} = \exp\{\lambda(e^t - 1) \}.
\end{align*}\]</span></p>
<p>Hence <span class="math inline">\(\mathop{\mathrm{E}}(X)=M_X&#39;(0)=\lambda\)</span> and <span class="math inline">\(\mathop{\mathrm{E}}(X^2)=M_X&#39;&#39;(0)=\lambda^2+\lambda\)</span>, so <span class="math inline">\(\mathop{\mathrm{Var}}(X)=\mathop{\mathrm{E}}(X^2)-\mathop{\mathrm{E}}(X)=\lambda\)</span>.</p>
<p>The Poisson family is closed under addition.
If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent Poisson r.v. with means <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span>, then
<span class="math display">\[
X+Y \sim \mathop{\mathrm{Poi}}(\lambda + \mu)
\]</span></p>
<p>The proof uses mgf and the characterizing property of the mgf.</p>
<div class="mycheck">
<p>Have a go at the proof using properties of the mgf.</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:poissonpdfcdf"></span>
<img src="bookdown-adv-stats_files/figure-html/poissonpdfcdf-1.png" alt="Pdf and cdf of the negative binomial distribution with \(\lambda=3\)." width="100%" />
<p class="caption">
Figure 2.7: Pdf and cdf of the negative binomial distribution with <span class="math inline">\(\lambda=3\)</span>.
</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="26">
<li id="fn26"><p>Details in C&amp;B, p.95<a href="discrete-models.html#fnref26" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="commonly-used-probability-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="continuous-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/haziqj/adv-stats/edit/main/03-common_prob_models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-adv-stats.pdf", "bookdown-adv-stats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
