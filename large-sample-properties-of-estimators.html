<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.8 Large sample properties of estimators | SM-4331 Advanced Statistics</title>
  <meta name="description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.8 Large sample properties of estimators | SM-4331 Advanced Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.8 Large sample properties of estimators | SM-4331 Advanced Statistics" />
  
  <meta name="twitter:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

<meta name="author" content="Dr Haziq Jamil" />


<meta name="date" content="2021-12-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cramér-rao-lower-bound-crlb.html"/>
<link rel="next" href="exercises-3.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="mystyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SM-4331 Advanced Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html"><i class="fa fa-check"></i>Contents</a>
<ul>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html#goals"><i class="fa fa-check"></i>Goals</a></li>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html#incidental-learning-outcomes"><i class="fa fa-check"></i>Incidental learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html"><i class="fa fa-check"></i>Module information</a>
<ul>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#class-format"><i class="fa fa-check"></i>Class format</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#assessment"><i class="fa fa-check"></i>Assessment</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#key-data"><i class="fa fa-check"></i>Key data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html"><i class="fa fa-check"></i>Course policy</a>
<ul>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#communication-policy"><i class="fa fa-check"></i>Communication policy</a></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#attendance-policy"><i class="fa fa-check"></i>Attendance policy</a></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#conduct"><i class="fa fa-check"></i>Conduct</a></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#learning-management-system"><i class="fa fa-check"></i>Learning Management System</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html"><i class="fa fa-check"></i>Resources</a>
<ul>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html#this-course"><i class="fa fa-check"></i>This course</a></li>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html#textbooks"><i class="fa fa-check"></i>Textbooks</a></li>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html#miscellaneous"><i class="fa fa-check"></i>Miscellaneous</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="" data-path="what-is-statistics.html"><a href="what-is-statistics.html"><i class="fa fa-check"></i>What is statistics?</a>
<ul>
<li class="chapter" data-level="" data-path="learning-statistics.html"><a href="learning-statistics.html"><i class="fa fa-check"></i>Learning statistics</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html"><i class="fa fa-check"></i>Population, sample and parametric models</a>
<ul>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#population-vs-sample"><i class="fa fa-check"></i>Population vs sample</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#parametric-models"><i class="fa fa-check"></i>Parametric models</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#a-sample-a-set-of-data-or-random-variablesa-duality"><i class="fa fa-check"></i>A sample: a set of data or random variables?–A duality</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#variability-of-estimates"><i class="fa fa-check"></i>Variability of estimates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-and-statistics.html"><a href="probability-and-statistics.html"><i class="fa fa-check"></i>Probability and statistics</a></li>
</ul></li>
<li class="part"><span><b>II Prepare</b></span></li>
<li class="chapter" data-level="1" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html"><i class="fa fa-check"></i><b>1</b> Probability theory primer</a>
<ul>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#readings"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html"><i class="fa fa-check"></i><b>1.1</b> Elementary set theory</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#set-operations"><i class="fa fa-check"></i><b>1.1.1</b> Set operations</a></li>
<li class="chapter" data-level="1.1.2" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#partitions"><i class="fa fa-check"></i><b>1.1.2</b> Partitions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html"><i class="fa fa-check"></i><b>1.2</b> Axiomatic probability</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#probability-as-a-measure"><i class="fa fa-check"></i><b>1.2.1</b> Probability as a measure</a></li>
<li class="chapter" data-level="1.2.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>1.2.2</b> Axioms of probability</a></li>
<li class="chapter" data-level="1.2.3" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#derived-probability-results"><i class="fa fa-check"></i><b>1.2.3</b> Derived probability results</a></li>
<li class="chapter" data-level="1.2.4" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#why-measure-theory"><i class="fa fa-check"></i><b>1.2.4</b> Why measure theory?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html"><i class="fa fa-check"></i><b>1.3</b> Conditioning and independence</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#bayes-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Bayes Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#independence"><i class="fa fa-check"></i><b>1.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>1.4</b> Random variables</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="random-variables.html"><a href="random-variables.html#distribution-functions"><i class="fa fa-check"></i><b>1.4.1</b> Distribution functions</a></li>
<li class="chapter" data-level="1.4.2" data-path="random-variables.html"><a href="random-variables.html#identically-distributed-r.v."><i class="fa fa-check"></i><b>1.4.2</b> Identically distributed r.v.</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-functions.html"><a href="probability-functions.html"><i class="fa fa-check"></i><b>1.5</b> Probability functions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probability-functions.html"><a href="probability-functions.html#probability-mass-function"><i class="fa fa-check"></i><b>1.5.1</b> Probability mass function</a></li>
<li class="chapter" data-level="1.5.2" data-path="probability-functions.html"><a href="probability-functions.html#probability-density-functions"><i class="fa fa-check"></i><b>1.5.2</b> Probability density functions</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>1.6</b> Transformations</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="transformations.html"><a href="transformations.html#probability-integral-transform"><i class="fa fa-check"></i><b>1.6.1</b> Probability integral transform</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html"><i class="fa fa-check"></i><b>1.7</b> Multiple random variables</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#bivariate-distributions"><i class="fa fa-check"></i><b>1.7.1</b> Bivariate distributions</a></li>
<li class="chapter" data-level="1.7.2" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#marginal-distributions"><i class="fa fa-check"></i><b>1.7.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="1.7.3" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#conditional-distributions"><i class="fa fa-check"></i><b>1.7.3</b> Conditional distributions</a></li>
<li class="chapter" data-level="1.7.4" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>1.7.4</b> Independent random variables</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="expectations.html"><a href="expectations.html"><i class="fa fa-check"></i><b>1.8</b> Expectations</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="expectations.html"><a href="expectations.html#expectations-of-functions-of-r.v."><i class="fa fa-check"></i><b>1.8.1</b> Expectations of functions of r.v.</a></li>
<li class="chapter" data-level="1.8.2" data-path="expectations.html"><a href="expectations.html#properties-of-expectations"><i class="fa fa-check"></i><b>1.8.2</b> Properties of expectations</a></li>
<li class="chapter" data-level="1.8.3" data-path="expectations.html"><a href="expectations.html#variance"><i class="fa fa-check"></i><b>1.8.3</b> Variance</a></li>
<li class="chapter" data-level="1.8.4" data-path="expectations.html"><a href="expectations.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.8.4</b> Covariance and correlation</a></li>
<li class="chapter" data-level="1.8.5" data-path="expectations.html"><a href="expectations.html#properties-of-variances-and-covariances"><i class="fa fa-check"></i><b>1.8.5</b> Properties of variances and covariances</a></li>
<li class="chapter" data-level="1.8.6" data-path="expectations.html"><a href="expectations.html#multivariate-means-and-covariances"><i class="fa fa-check"></i><b>1.8.6</b> Multivariate means and covariances</a></li>
<li class="chapter" data-level="1.8.7" data-path="expectations.html"><a href="expectations.html#conditional-expectations-and-variance"><i class="fa fa-check"></i><b>1.8.7</b> Conditional expectations and variance</a></li>
<li class="chapter" data-level="1.8.8" data-path="expectations.html"><a href="expectations.html#additional-explainers"><i class="fa fa-check"></i><b>1.8.8</b> Additional explainers</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html"><i class="fa fa-check"></i><b>1.9</b> Moment generating functions</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#moment-generating-functions-1"><i class="fa fa-check"></i><b>1.9.1</b> Moment generating functions</a></li>
<li class="chapter" data-level="1.9.2" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#generating-moments"><i class="fa fa-check"></i><b>1.9.2</b> Generating moments</a></li>
<li class="chapter" data-level="1.9.3" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#properties-of-mgf"><i class="fa fa-check"></i><b>1.9.3</b> Properties of mgf</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.10</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#hand-in-questions"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html"><i class="fa fa-check"></i><b>2</b> Commonly-used probability models</a>
<ul>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#learning-objectives-1"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#readings-1"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="discrete-models.html"><a href="discrete-models.html"><i class="fa fa-check"></i><b>2.2</b> Discrete models</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="discrete-models.html"><a href="discrete-models.html#point-mass-distribution"><i class="fa fa-check"></i><b>2.2.1</b> Point mass distribution</a></li>
<li class="chapter" data-level="2.2.2" data-path="discrete-models.html"><a href="discrete-models.html#uniform-distribution"><i class="fa fa-check"></i><b>2.2.2</b> Uniform distribution</a></li>
<li class="chapter" data-level="2.2.3" data-path="discrete-models.html"><a href="discrete-models.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.2.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.2.4" data-path="discrete-models.html"><a href="discrete-models.html#binomial-distribution"><i class="fa fa-check"></i><b>2.2.4</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.2.5" data-path="discrete-models.html"><a href="discrete-models.html#geometric-distribution"><i class="fa fa-check"></i><b>2.2.5</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.2.6" data-path="discrete-models.html"><a href="discrete-models.html#negative-binomial"><i class="fa fa-check"></i><b>2.2.6</b> Negative binomial</a></li>
<li class="chapter" data-level="2.2.7" data-path="discrete-models.html"><a href="discrete-models.html#poisson-distribution"><i class="fa fa-check"></i><b>2.2.7</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="continuous-models.html"><a href="continuous-models.html"><i class="fa fa-check"></i><b>2.3</b> Continuous models</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="continuous-models.html"><a href="continuous-models.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>2.3.1</b> Continuous uniform distribution</a></li>
<li class="chapter" data-level="2.3.2" data-path="continuous-models.html"><a href="continuous-models.html#exponential-distribution"><i class="fa fa-check"></i><b>2.3.2</b> Exponential distribution</a></li>
<li class="chapter" data-level="2.3.3" data-path="continuous-models.html"><a href="continuous-models.html#gamma-distribution"><i class="fa fa-check"></i><b>2.3.3</b> Gamma distribution</a></li>
<li class="chapter" data-level="2.3.4" data-path="continuous-models.html"><a href="continuous-models.html#beta-distribution"><i class="fa fa-check"></i><b>2.3.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>2.4</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="normal-distribution.html"><a href="normal-distribution.html#location-parameter"><i class="fa fa-check"></i><b>2.4.1</b> Location parameter</a></li>
<li class="chapter" data-level="2.4.2" data-path="normal-distribution.html"><a href="normal-distribution.html#scale-parameter"><i class="fa fa-check"></i><b>2.4.2</b> Scale parameter</a></li>
<li class="chapter" data-level="2.4.3" data-path="normal-distribution.html"><a href="normal-distribution.html#linear-transformations-of-normal-random-variables"><i class="fa fa-check"></i><b>2.4.3</b> Linear transformations of normal random variables</a></li>
<li class="chapter" data-level="2.4.4" data-path="normal-distribution.html"><a href="normal-distribution.html#the-normal-cdf"><i class="fa fa-check"></i><b>2.4.4</b> The normal cdf</a></li>
<li class="chapter" data-level="2.4.5" data-path="normal-distribution.html"><a href="normal-distribution.html#rule"><i class="fa fa-check"></i><b>2.4.5</b> 68–95–99.7 Rule</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="some-relationships.html"><a href="some-relationships.html"><i class="fa fa-check"></i><b>2.5</b> Some relationships</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="some-relationships.html"><a href="some-relationships.html#poisson-binomial-relationship"><i class="fa fa-check"></i><b>2.5.1</b> Poisson-Binomial relationship</a></li>
<li class="chapter" data-level="2.5.2" data-path="some-relationships.html"><a href="some-relationships.html#poisson-exponential"><i class="fa fa-check"></i><b>2.5.2</b> Poisson-Exponential</a></li>
<li class="chapter" data-level="2.5.3" data-path="some-relationships.html"><a href="some-relationships.html#poisson-gamma"><i class="fa fa-check"></i><b>2.5.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="2.5.4" data-path="some-relationships.html"><a href="some-relationships.html#normal-approximations"><i class="fa fa-check"></i><b>2.5.4</b> Normal approximations</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.6</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#hand-in-questions-1"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html"><i class="fa fa-check"></i><b>3</b> Inequalities, convergences, and normal random samples</a>
<ul>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#readings-2"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="3.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-1.html"><a href="introduction-1.html#random-sampling"><i class="fa fa-check"></i><b>3.1.1</b> Random sampling</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-1.html"><a href="introduction-1.html#independent-and-identical-r.v."><i class="fa fa-check"></i><b>3.1.2</b> Independent and identical r.v.</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-1.html"><a href="introduction-1.html#statistic"><i class="fa fa-check"></i><b>3.1.3</b> Statistic</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-1.html"><a href="introduction-1.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1.4</b> Sampling distribution</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction-1.html"><a href="introduction-1.html#large-sample-approximation"><i class="fa fa-check"></i><b>3.1.5</b> Large-sample approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>3.2</b> Inequalities</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inequalities.html"><a href="inequalities.html#markovs-inequality"><i class="fa fa-check"></i><b>3.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="3.2.2" data-path="inequalities.html"><a href="inequalities.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>3.2.2</b> Chebyshev’s inequality</a></li>
<li class="chapter" data-level="3.2.3" data-path="inequalities.html"><a href="inequalities.html#cauchy-schwartz-inequality"><i class="fa fa-check"></i><b>3.2.3</b> Cauchy-Schwartz inequality</a></li>
<li class="chapter" data-level="3.2.4" data-path="inequalities.html"><a href="inequalities.html#jensens-inequality"><i class="fa fa-check"></i><b>3.2.4</b> Jensen’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html"><i class="fa fa-check"></i><b>3.3</b> Convergence of random variables</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.3.1</b> Convergence in probability</a></li>
<li class="chapter" data-level="3.3.2" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Convergence in distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#mean-square-convergence"><i class="fa fa-check"></i><b>3.3.3</b> Mean-square convergence</a></li>
<li class="chapter" data-level="3.3.4" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#relationship-between-convergences"><i class="fa fa-check"></i><b>3.3.4</b> Relationship between convergences</a></li>
<li class="chapter" data-level="3.3.5" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#slutzkys-theorem"><i class="fa fa-check"></i><b>3.3.5</b> Slutzky’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>3.4</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="limit-theorems.html"><a href="limit-theorems.html#the-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>3.4.1</b> The (weak) Law of Large Numbers</a></li>
<li class="chapter" data-level="3.4.2" data-path="limit-theorems.html"><a href="limit-theorems.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="3.4.3" data-path="limit-theorems.html"><a href="limit-theorems.html#gauging-the-error-of-sample-mean-estimator"><i class="fa fa-check"></i><b>3.4.3</b> Gauging the error of sample mean estimator</a></li>
<li class="chapter" data-level="3.4.4" data-path="limit-theorems.html"><a href="limit-theorems.html#clt-with-sigma2-unknown"><i class="fa fa-check"></i><b>3.4.4</b> CLT with <span class="math inline">\(\sigma^2\)</span> unknown</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>3.5</b> Delta method</a></li>
<li class="chapter" data-level="3.6" data-path="normal-random-samples.html"><a href="normal-random-samples.html"><i class="fa fa-check"></i><b>3.6</b> Normal random samples</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="normal-random-samples.html"><a href="normal-random-samples.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6.1</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.2" data-path="normal-random-samples.html"><a href="normal-random-samples.html#students-t-distribution"><i class="fa fa-check"></i><b>3.6.2</b> Student’s <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.3" data-path="normal-random-samples.html"><a href="normal-random-samples.html#proof-of-theorem-refthmpropertynormalsamp"><i class="fa fa-check"></i><b>3.6.3</b> Proof of Theorem @ref(thm:propertynormalsamp)</a></li>
<li class="chapter" data-level="3.6.4" data-path="normal-random-samples.html"><a href="normal-random-samples.html#f-distribution"><i class="fa fa-check"></i><b>3.6.4</b> <span class="math inline">\(F\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.5" data-path="normal-random-samples.html"><a href="normal-random-samples.html#the-analysis-of-variance"><i class="fa fa-check"></i><b>3.6.5</b> The analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#hand-in-questions-2"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Inference</b></span></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#readings-3"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="4.1" data-path="the-likelihood.html"><a href="the-likelihood.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="the-likelihood.html"><a href="the-likelihood.html#calculating-the-likelihood"><i class="fa fa-check"></i><b>4.1.1</b> Calculating the likelihood</a></li>
<li class="chapter" data-level="4.1.2" data-path="the-likelihood.html"><a href="the-likelihood.html#likelihood-ratio"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood ratio</a></li>
<li class="chapter" data-level="4.1.3" data-path="the-likelihood.html"><a href="the-likelihood.html#log-likelihood"><i class="fa fa-check"></i><b>4.1.3</b> Log likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sufficiency.html"><a href="sufficiency.html"><i class="fa fa-check"></i><b>4.2</b> Sufficiency</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sufficiency.html"><a href="sufficiency.html#the-factorisation-theorem"><i class="fa fa-check"></i><b>4.2.1</b> The factorisation theorem</a></li>
<li class="chapter" data-level="4.2.2" data-path="sufficiency.html"><a href="sufficiency.html#minimal-sufficient-statistic"><i class="fa fa-check"></i><b>4.2.2</b> Minimal sufficient statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="point-estimators.html"><a href="point-estimators.html"><i class="fa fa-check"></i><b>4.3</b> Point estimators</a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>4.4</b> Method of moments</a></li>
<li class="chapter" data-level="4.5" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>4.5</b> Method of maximum likelihood</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#finding-the-mle"><i class="fa fa-check"></i><b>4.5.1</b> Finding the MLE</a></li>
<li class="chapter" data-level="4.5.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#invariance-of-mle"><i class="fa fa-check"></i><b>4.5.2</b> Invariance of MLE</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html"><i class="fa fa-check"></i><b>4.6</b> Evaluating estimators</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#bias"><i class="fa fa-check"></i><b>4.6.1</b> Bias</a></li>
<li class="chapter" data-level="4.6.2" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#variance-and-standard-error"><i class="fa fa-check"></i><b>4.6.2</b> Variance and standard error</a></li>
<li class="chapter" data-level="4.6.3" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>4.6.3</b> Mean squared error</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html"><i class="fa fa-check"></i><b>4.7</b> Cramér-Rao lower bound (CRLB)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#fisher-information"><i class="fa fa-check"></i><b>4.7.1</b> Fisher information</a></li>
<li class="chapter" data-level="4.7.2" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#variance-reduction-rao-blackwellisation"><i class="fa fa-check"></i><b>4.7.2</b> Variance reduction: Rao-Blackwellisation</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html"><i class="fa fa-check"></i><b>4.8</b> Large sample properties of estimators</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency"><i class="fa fa-check"></i><b>4.8.1</b> Consistency</a></li>
<li class="chapter" data-level="4.8.2" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-vs-unbiasedness"><i class="fa fa-check"></i><b>4.8.2</b> Consistency vs unbiasedness</a></li>
<li class="chapter" data-level="4.8.3" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-of-mles"><i class="fa fa-check"></i><b>4.8.3</b> Consistency of MLEs</a></li>
<li class="chapter" data-level="4.8.4" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency"><i class="fa fa-check"></i><b>4.8.4</b> Efficiency</a></li>
<li class="chapter" data-level="4.8.5" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#asymptotic-normality-and-consistency"><i class="fa fa-check"></i><b>4.8.5</b> Asymptotic normality and consistency</a></li>
<li class="chapter" data-level="4.8.6" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-mle"><i class="fa fa-check"></i><b>4.8.6</b> Efficiency of MLE</a></li>
<li class="chapter" data-level="4.8.7" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-transformations-of-mle"><i class="fa fa-check"></i><b>4.8.7</b> Efficiency of transformations of MLE</a></li>
<li class="chapter" data-level="4.8.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#application-of-asymptotic-normality"><i class="fa fa-check"></i><b>4.8.8</b> Application of asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-3.html"><a href="exercises-3.html#hand-in-questions-3"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#readings-4"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="5.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-2.html"><a href="introduction-2.html#a-general-paradigm"><i class="fa fa-check"></i><b>5.1.1</b> A general paradigm</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-2.html"><a href="introduction-2.html#p-values"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-2.html"><a href="introduction-2.html#accept-h_0"><i class="fa fa-check"></i><b>5.1.3</b> Accept <span class="math inline">\(H_0\)</span>?</a></li>
<li class="chapter" data-level="5.1.4" data-path="introduction-2.html"><a href="introduction-2.html#uniformity-of-p-values"><i class="fa fa-check"></i><b>5.1.4</b> Uniformity of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>5.2</b> Likelihood ratio test</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#log-likelihood-ratio-test-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Log likelihood ratio test statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.2</b> Example: Normal with known variance</a></li>
<li class="chapter" data-level="5.2.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-unknown-variance-t-test"><i class="fa fa-check"></i><b>5.2.3</b> Example: Normal with unknown variance (<span class="math inline">\(t\)</span>-test)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html"><i class="fa fa-check"></i><b>5.3</b> The Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#performance-of-a-test"><i class="fa fa-check"></i><b>5.3.1</b> Performance of a test</a></li>
<li class="chapter" data-level="5.3.2" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#relation-to-p-values"><i class="fa fa-check"></i><b>5.3.2</b> Relation to <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html"><i class="fa fa-check"></i><b>5.4</b> Type I and II errors</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#minimising-errors"><i class="fa fa-check"></i><b>5.4.1</b> Minimising errors</a></li>
<li class="chapter" data-level="5.4.2" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#optimality-of-the-lr-test"><i class="fa fa-check"></i><b>5.4.2</b> Optimality of the LR test</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sided-tests.html"><a href="one-sided-tests.html"><i class="fa fa-check"></i><b>5.5</b> One-sided tests</a></li>
<li class="chapter" data-level="5.6" data-path="approximate-tests.html"><a href="approximate-tests.html"><i class="fa fa-check"></i><b>5.6</b> Approximate tests</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="approximate-tests.html"><a href="approximate-tests.html#asymptotic-distribution-of-lrts"><i class="fa fa-check"></i><b>5.6.1</b> Asymptotic distribution of LRTs</a></li>
<li class="chapter" data-level="5.6.2" data-path="approximate-tests.html"><a href="approximate-tests.html#wilks-theorem"><i class="fa fa-check"></i><b>5.6.2</b> Wilk’s theorem</a></li>
<li class="chapter" data-level="5.6.3" data-path="approximate-tests.html"><a href="approximate-tests.html#the-wald-test"><i class="fa fa-check"></i><b>5.6.3</b> The Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-4.html"><a href="exercises-4.html#hand-in-questions-4"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>6</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#readings-5"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="6.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-3.html"><a href="introduction-3.html#coverage-probability"><i class="fa fa-check"></i><b>6.1.1</b> Coverage probability</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-3.html"><a href="introduction-3.html#confidence-regions"><i class="fa fa-check"></i><b>6.1.2</b> Confidence regions</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-3.html"><a href="introduction-3.html#methods-for-obtaining-confidence-regions"><i class="fa fa-check"></i><b>6.1.3</b> Methods for obtaining confidence regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pivots.html"><a href="pivots.html"><i class="fa fa-check"></i><b>6.2</b> Pivots</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pivots.html"><a href="pivots.html#from-pivot-to-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> From pivot to confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Inverting a test statistic</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html#discrete-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Discrete distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="desirable-confidence-sets.html"><a href="desirable-confidence-sets.html"><i class="fa fa-check"></i><b>6.4</b> Desirable confidence sets</a></li>
<li class="chapter" data-level="6.5" data-path="intervals-based-on-ml-methods.html"><a href="intervals-based-on-ml-methods.html"><i class="fa fa-check"></i><b>6.5</b> Intervals based on ML methods</a></li>
<li class="chapter" data-level="6.6" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>6.6</b> The bootstrap method</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#empirical-distribution"><i class="fa fa-check"></i><b>6.6.1</b> Empirical distribution</a></li>
<li class="chapter" data-level="6.6.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-variance-estimation"><i class="fa fa-check"></i><b>6.6.2</b> Bootstrap variance estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap confidence intervals</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#normal-bootstrap-interval"><i class="fa fa-check"></i><b>6.7.1</b> Normal bootstrap interval</a></li>
<li class="chapter" data-level="6.7.2" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-percentile-interval"><i class="fa fa-check"></i><b>6.7.2</b> Bootstrap percentile interval</a></li>
<li class="chapter" data-level="6.7.3" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-pivotal-interval"><i class="fa fa-check"></i><b>6.7.3</b> Bootstrap pivotal interval</a></li>
<li class="chapter" data-level="6.7.4" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#which-one-to-use"><i class="fa fa-check"></i><b>6.7.4</b> Which one to use?</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-5.html"><a href="exercises-5.html#hand-in-questions-5"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="exam-tips.html"><a href="exam-tips.html"><i class="fa fa-check"></i><b>A</b> Exam tips</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SM-4331 Advanced Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="large-sample-properties-of-estimators" class="section level2" number="4.8">
<h2><span class="header-section-number">4.8</span> Large sample properties of estimators</h2>
<p>All of the criteria we have considered thus far have been finite-sample criteria.
In contrast, we might consider asymptotic properties which describe the behaviour as sample size becomes infinite.</p>
<p>We shall discuss three properties:</p>
<ol style="list-style-type: decimal">
<li>Consistency</li>
<li>Efficiency</li>
<li>Asymptotic normality</li>
</ol>
<p>In particular, we shall see that ML estimators are (generally) consistent, efficient (achieves CRLB), and has an asymptotic normal distribution.</p>
<div id="consistency" class="section level3" number="4.8.1">
<h3><span class="header-section-number">4.8.1</span> Consistency</h3>
<div class="definition">
<p><span id="def:unlabeled-div-133" class="definition"><strong>Definition 4.11  (Consistent estimator) </strong></span>An estimator <span class="math inline">\(\hat\theta_n := \hat\theta(X_1,\dots,X_n)\)</span> is a consistent estimator for <span class="math inline">\(\theta\)</span> if <span class="math inline">\(\hat\theta_n \to \theta\)</span> in probability as <span class="math inline">\(n\to\infty\)</span>.</p>
</div>
<p>Consistency is a natural condition for a reasonable estimator as
<span class="math inline">\(\hat\theta_n\)</span> should converge to <span class="math inline">\(\theta\)</span> if we have a (theoretically)
infinite amount of information. Therefore, a <strong>non-consistent estimator
should not be used in practice!</strong></p>
<p>A practical way of checking consistency is to check mean square convergence: If <span class="math inline">\(\hat\theta_n \xrightarrow{m.s.} \theta\)</span> then <span class="math inline">\(\hat\theta_n\)</span> is consistent (since convergence in mean square implies convergence in probability). Further, since
<span class="math display">\[
\text{MSE}(\hat\theta_n) = \mathop{\mathrm{E}}\left[(\hat\theta_n-\theta)^2 \right] = \left\{\text{Bias}(\hat\theta_n)\right\}^2 + \mathop{\mathrm{Var}}(\hat\theta_n), 
\]</span>
we can also check that both the bias and variance converges to 0.</p>
</div>
<div id="consistency-vs-unbiasedness" class="section level3" number="4.8.2">
<h3><span class="header-section-number">4.8.2</span> Consistency vs unbiasedness</h3>
<p>Consistency and bias are two distinct concepts:</p>
<ul>
<li><p>Unbiasedness (<span class="math inline">\(\mathop{\mathrm{E}}(\hat\theta_n) = \theta\)</span>) is a statement about the
expected value of the <em>sampling distribution</em> of the estimator.</p></li>
<li><p>Consistency (<span class="math inline">\(\mathop{\mathrm{plim}}_{n\to\infty}\hat\theta_n = \theta\)</span>) is a statement relating to the sequence of estimators <span class="math inline">\(\hat\theta_1, \hat\theta_2, \dots\)</span>. It tells us
where the estimator is tending to as the
sample size increases.</p></li>
</ul>
<p>Both are desirable properties of estimators, though it might be possible
for one to be satisfied but not the other (see next example).
As mentioned, and as we shall see, we are probably better off using a consistent but biased estimator rather than an inconsistent but unbiased estimator.</p>
<div class="example">
<p><span id="exm:unlabeled-div-134" class="example"><strong>Example 4.15  </strong></span>Let <span class="math inline">\(X_1,\dots,X_n\)</span> be a sample from <span class="math inline">\(\mathop{\mathrm{N}}(\mu,\sigma^2)\)</span>. Consider the following estimators for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>:</p>
<ul>
<li><span class="math inline">\(\hat\mu=X_1\)</span>; and</li>
<li><span class="math inline">\(\hat\sigma^2=n^{-1}\sum_{i=1}^n (X_i-\bar X_n)^2\)</span></li>
</ul>
<p>The estimator <span class="math inline">\(\hat\mu\)</span> is unbiased since <span class="math inline">\(\mathop{\mathrm{E}}(X_1)=\mu\)</span>, but it is not consistent since the distribution of <span class="math inline">\(\hat\mu\)</span> is always <span class="math inline">\(\mathop{\mathrm{N}}(\mu,\sigma^2)\)</span> and will never concentrate around <span class="math inline">\(\mu\)</span> even with infinite sample size.</p>
<p>It is a fact that
<span class="math inline">\(\mathop{\mathrm{E}}(\hat\sigma^2) = \frac{n-1}{n}\sigma^2\)</span>, which shows that <span class="math inline">\(\hat\sigma^2\)</span>
is biased in finite samples, but this bias vanishes as <span class="math inline">\(n\to\infty\)</span>. We can also show
<span class="math display">\[\mathop{\mathrm{Var}}(\hat\sigma^2) = \frac{2\sigma^4(n-1)}{n^2} \to 0\]</span> as
<span class="math inline">\(n\to\infty\)</span>. Therefore, <span class="math inline">\(\text{MSE}(\hat\sigma^2)\to 0\)</span>, and
<span class="math inline">\(\hat\sigma^2\)</span> is therefore consistent.</p>
</div>
</div>
<div id="consistency-of-mles" class="section level3" number="4.8.3">
<h3><span class="header-section-number">4.8.3</span> Consistency of MLEs</h3>
<div class="theorem">
<p><span id="thm:consistentmle" class="theorem"><strong>Theorem 4.5  (Consistency of MLE) </strong></span>Let <span class="math inline">\(X_1,\dots,X_n \,\overset{\text{iid}}{\sim}\,f(x|\theta)\)</span>, and let <span class="math inline">\(\hat\theta_n:=\mathop{\mathrm{arg\,max}}_\theta L(\theta|{\boldsymbol X})\)</span> denote the MLE of <span class="math inline">\(\theta\)</span>. Let <span class="math inline">\(\psi(\theta)\)</span> be a continuous function of <span class="math inline">\(\theta\)</span>. Under certain regularity conditions, we have that for every <span class="math inline">\(\epsilon &gt;0\)</span> and every <span class="math inline">\(\theta\in\Theta\)</span>,
<span class="math display">\[
\lim_{n\to\infty} \Pr(|\psi(\hat\theta_n) - \psi(\theta)| \geq \epsilon) = 0.
\]</span>
That is, <span class="math inline">\(\psi(\hat\theta_n)\)</span> is a consistent estimator of <span class="math inline">\(\psi(\theta)\)</span>.</p>
</div>
<p>In particular, consider the identity function <span class="math inline">\(\psi(\theta)=\theta\)</span>. Then the theorem states that the MLE <span class="math inline">\(\hat\theta_n\)</span> is consistent. Some notes:</p>
<ul>
<li>The regularity conditions mentioned can be found in Miscellanea 10.6.2 of C&amp;B.</li>
<li>The above theorem is stating the result for unidimensional <span class="math inline">\(\theta\)</span>, but there are similar multidimensional statements too.</li>
<li>We shall defer the proof until we discuss asymptotic normality.</li>
</ul>
</div>
<div id="efficiency" class="section level3" number="4.8.4">
<h3><span class="header-section-number">4.8.4</span> Efficiency</h3>
<p>Efficiency of an estimator concerns the (asymptotic) variance of an estimator.
The CRLB gives the benchmark for efficiency.</p>
<div class="definition">
<p><span id="def:unlabeled-div-135" class="definition"><strong>Definition 4.12  (Asymptotic efficiency) </strong></span>A sequence of estimators <span class="math inline">\(\hat\theta_n := \hat\theta(X_1,\dots,X_n)\)</span> is said to be asymptotically efficient for a parameter <span class="math inline">\(\theta\)</span> if
<span class="math display">\[
\sqrt n \big(\hat\theta_n - \theta \big) \xrightarrow{\text D} \mathop{\mathrm{N}}\big(0, v(\theta)\big),
\]</span>
as <span class="math inline">\(n\to\infty\)</span>, where <span class="math inline">\(v(\theta)\)</span> is the Cramér-Rao lower bound
<span class="math display">\[
v(\theta) = \frac{1}{\mathop{\mathrm{E}}\left[\left(\frac{\partial}{\partial \theta} \log f(X_1|\theta) \right)^2\right]} = {\mathcal I}_1(\theta)^{-1}.
\]</span></p>
</div>
<p>Some remarks:</p>
<ul>
<li>The property that <span class="math inline">\(a_n \big(\hat\theta_n - \theta \big)\)</span> converges in distribution to <span class="math inline">\(\mathop{\mathrm{N}}(0,\sigma^2)\)</span> is called <em>asymptotic normality</em>, and <span class="math inline">\(\sigma^2\)</span> is called the <em>asymptotic variance</em>.</li>
<li>An asymptotically efficient estimator has its asymptotic variance achieving the CRLB.</li>
</ul>
</div>
<div id="asymptotic-normality-and-consistency" class="section level3" number="4.8.5">
<h3><span class="header-section-number">4.8.5</span> Asymptotic normality and consistency</h3>
<p>The phrase ‘efficient and consistent’ is somewhat redundant, because efficiency is defined only when the estimator is asymptotically normal, and as we shall show, asymptotic normality implies consistency.</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-136" class="lemma"><strong>Lemma 4.3  </strong></span>Suppose that <span class="math inline">\(\hat\theta_n\)</span> is an estimator for <span class="math inline">\(\theta\)</span> such that
<span class="math display">\[
\frac{\sqrt n(\hat\theta_n - \theta)}{\sigma} \xrightarrow{\text D} \mathop{\mathrm{N}}(0,1)
\]</span>
then <span class="math inline">\(\hat\theta_n\)</span> is consistent for <span class="math inline">\(\theta\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-137" class="proof"><em>Proof</em>. </span>Notice that
<span class="math display">\[
\hat\theta_n - \theta = \frac{\sigma}{\sqrt n}\frac{\sqrt n(\hat\theta_n - \theta)}{\sigma} \xrightarrow{\text D} 0
\]</span>
by Slutzky’s theorem. Thus, <span class="math inline">\(\hat\theta_n -\theta \xrightarrow{\text P} 0\)</span> which implies <span class="math inline">\(\hat\theta_n \xrightarrow{\text P} \theta\)</span>, and hence <span class="math inline">\(\hat\theta_n\)</span> is consistent.</p>
</div>
</div>
<div id="efficiency-of-mle" class="section level3" number="4.8.6">
<h3><span class="header-section-number">4.8.6</span> Efficiency of MLE</h3>
<p>We’ve seen that MLEs are consistent. Under even stronger regularity conditions, we find that they are also efficient.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-138" class="theorem"><strong>Theorem 4.6  (Asymptotic efficiency of MLE) </strong></span>Let <span class="math inline">\(X_1,\dots,X_n \,\overset{\text{iid}}{\sim}\,f(x|\theta)\)</span>, and let <span class="math inline">\(\hat\theta_n:=\mathop{\mathrm{arg\,max}}_\theta L(\theta|{\boldsymbol X})\)</span> denote the MLE of <span class="math inline">\(\theta\)</span>. Under certain regularity conditions, we have that
<span class="math display">\[
\sqrt n (\hat\theta_n - \theta ) \xrightarrow{\text D} \mathop{\mathrm{N}}\big(0, {\mathcal I}_1(\theta)^{-1}\big), 
\]</span>
where <span class="math inline">\({\mathcal I}_1(\theta)\)</span> is the (unit) Fisher information for <span class="math inline">\(\theta\)</span>. That is, <span class="math inline">\(\hat\theta_n\)</span> is a consistent and asymptotically efficient estimator for <span class="math inline">\(\theta\)</span>.</p>
</div>
<p>In fact, this theorem also holds more widely–the restriction to iid cases presents a simple proof, but is not essential.</p>
<div class="proof">
<p><span id="unlabeled-div-139" class="proof"><em>Proof</em> (Sketch). </span>Taylor expand the score <span class="math inline">\(l&#39;(t|{\boldsymbol X})\)</span> about the parameter value <span class="math inline">\(\theta\)</span>:
<span class="math display">\[
l&#39;(t|{\boldsymbol X}) = l&#39;(\theta|{\boldsymbol X}) + (t - \theta)l&#39;&#39;(\theta|{\boldsymbol X}) 
\]</span>
(ignoring the higher order terms). Evaluate this at the maxima <span class="math inline">\(t=\hat\theta_n\)</span>, we get
<span class="math display">\[\begin{align*}
\cancelto{0}{l&#39;(\hat\theta_n|{\boldsymbol X})} &amp;= l&#39;(\theta|{\boldsymbol X}) + (\hat\theta_n - \theta)l&#39;&#39;(\theta|{\boldsymbol X}) \\
\Rightarrow \sqrt n(\hat\theta_n - \theta) &amp;= -\frac{\frac{1}{\sqrt n}l&#39;(\theta|{\boldsymbol X})}{\frac{1}{n}l&#39;&#39;(\theta|{\boldsymbol X})}
\end{align*}\]</span></p>
<p>As one of the exercises at the end of this chapter, you will show that
<span class="math display">\[\begin{gather*}
-\frac{1}{\sqrt n}l&#39;(\theta|{\boldsymbol X}) \xrightarrow{\text D} \mathop{\mathrm{N}}\big(0,{\mathcal I}_1(\theta)\big)\\
\text{and}\\
\frac{1}{n}l&#39;&#39;(\theta|{\boldsymbol X}) \xrightarrow{\text P} {\mathcal I}_1(\theta),
\end{gather*}\]</span>
Using Slutzky’s theorem, we get
<span class="math display">\[
\sqrt n(\hat\theta_n - \theta) = -\frac{\frac{1}{\sqrt n}l&#39;(\theta|{\boldsymbol X})}{\frac{1}{n}l&#39;&#39;(\theta|{\boldsymbol X})} \xrightarrow{\text D} \mathop{\mathrm{N}}\big(0,{\mathcal I}_1(\theta)^{-1}\big)
\]</span></p>
</div>
</div>
<div id="efficiency-of-transformations-of-mle" class="section level3" number="4.8.7">
<h3><span class="header-section-number">4.8.7</span> Efficiency of transformations of MLE</h3>
<p>Let <span class="math inline">\(\psi(\theta)\)</span> be a continuous function of <span class="math inline">\(\theta\)</span>.
Using the delta method, the following result can be obtained:
<span class="math display">\[
\sqrt n \big(\psi(\hat\theta_n) - \psi(\theta)\big) \xrightarrow{\text D} \mathop{\mathrm{N}}\big(0, |\psi&#39;(\theta)|^2v(\theta)\big).
\]</span>
This is assuming that <span class="math inline">\(\psi(\cdot)\)</span> is differentiable at the value <span class="math inline">\(\theta\)</span>.</p>
<p>Therefore, the transformed MLE <span class="math inline">\(\psi(\hat\theta)\)</span> is a consistent and asymptotically efficient estimator of <span class="math inline">\(\psi(\theta)\)</span>.
Look back to the proof of the CRLB above and notice that the asymptotic variance of <span class="math inline">\(\psi(\hat\theta_n)\)</span> is exactly the general version of the CRLB (using the unit Fisher information):</p>
<p><span class="math display">\[
v(\theta) = \frac{\left[\psi&#39;(\theta) \right]^2}{{\mathcal I}_1(\theta)}.
\]</span></p>
</div>
<div id="application-of-asymptotic-normality" class="section level3" number="4.8.8">
<h3><span class="header-section-number">4.8.8</span> Application of asymptotic normality</h3>
<p>The practical implication of the theorem is that the repeated-sampling distribution of <span class="math inline">\(\hat\theta_n\)</span>, in large samples, is approximately
<span class="math display">\[
\hat\theta \approx \mathop{\mathrm{N}}\left(\theta, {\mathcal I}(\theta)^{-1} \right).
\]</span>
In particular, we can calculate an <em>approximate standard error</em> for <span class="math inline">\(\hat\theta\)</span> by estimating the quantity <span class="math inline">\({\mathcal I}(\theta)\)</span>. Two choices:</p>
<ol style="list-style-type: decimal">
<li><p>The obvious ‘plug-in’ estimator using the <em>expected</em> Fisher information
<span class="math display">\[
\text{se}(\hat\theta_n) \approx 1\Big/\sqrt{{\mathcal I}(\hat\theta_n)}.
\]</span>
This is not usually the best choice, however.</p></li>
<li><p>It is better (and generally more accurate) to use instead the <em>observed</em> Fisher information
<span class="math display">\[
\text{se}(\hat\theta_n) \approx 1\Big/\sqrt{-l&#39;&#39;(\hat\theta_n|{\boldsymbol X})},
\]</span>
which is based directly on the curvature of the log-likelihood of <span class="math inline">\(\hat\theta\)</span>.</p></li>
</ol>
<div class="example">
<p><span id="exm:unlabeled-div-140" class="example"><strong>Example 4.16  </strong></span>Suppose that <span class="math inline">\(X_1,\dots,X_n\,\overset{\text{iid}}{\sim}\,\mathop{\mathrm{Poi}}(\lambda)\)</span>. Then</p>
<p><span class="math display">\[\begin{align*}
l(\lambda|{\boldsymbol X}) &amp;= \text{const.}- n\lambda +\sum_{i=1}^n X_i \log \lambda \\
l&#39;(\lambda|{\boldsymbol X}) &amp;= - n +\sum_{i=1}^n X_i / \lambda \\ 
-l&#39;&#39;(\lambda|{\boldsymbol X}) &amp;=  \sum_{i=1}^n X_i / \lambda^2 \hspace{10pt}\rlap{\color{gray}\text{(the observed Fisher information)}}
\end{align*}\]</span>
Hence <span class="math inline">\(l&#39;(\lambda)=0\)</span> is solved at <span class="math inline">\(\hat\lambda_n = \sum_{i=1}^n X_i / n =: \bar X_n\)</span>.</p>
<p>The large-sample variance of <span class="math inline">\(\hat\lambda_n\)</span> is
<span class="math display">\[
{\mathcal I}(\theta)^{-1} = \mathop{\mathrm{E}}\left[-l&#39;&#39;(\lambda|{\boldsymbol X}) \right]^{-1} = \lambda^2 \big/ \mathop{\mathrm{E}}\bigg(\sum_{i=1}^n X_i\bigg) = \lambda^2 / n\lambda = \lambda /n.
\]</span></p>
<p>As a note, this variance is actually exact, since <span class="math inline">\(\mathop{\mathrm{Var}}(\hat\lambda)=\mathop{\mathrm{Var}}(\bar X_n)=\mathop{\mathrm{Var}}(X_i)/n=\lambda/n\)</span>.</p>
<p>The estimated standard error for <span class="math inline">\(\hat\lambda_n\)</span> is
<span class="math display">\[
\text{se}(\hat\lambda_n) \approx 1\Big/\sqrt{-l&#39;&#39;(\hat\lambda_n|{\boldsymbol X})} = 1\Big/\sqrt{n\hat\lambda_n/\hat\lambda^2} = \sqrt{\hat\lambda_n/n}.
\]</span></p>
</div>
<div class="myalert">
<p>In this example, the plug-in estimator for <span class="math inline">\({\mathcal I}(\theta)\)</span> happens to be the same as the observed information <span class="math inline">\(-l&#39;&#39;(\hat\theta)\)</span>. Sometimes this happens, sometimes they are different.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cramér-rao-lower-bound-crlb.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/haziqj/adv-stats/edit/main/05-point_est.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-adv-stats.pdf", "bookdown-adv-stats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
