<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.6 Normal random samples | SM-4331 Advanced Statistics</title>
  <meta name="description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="3.6 Normal random samples | SM-4331 Advanced Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.6 Normal random samples | SM-4331 Advanced Statistics" />
  
  <meta name="twitter:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

<meta name="author" content="Dr Haziq Jamil" />


<meta name="date" content="2022-01-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="delta-method.html"/>
<link rel="next" href="exercises-2.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="mystyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SM-4331 Advanced Statistics</a></li>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {extensions: ["cancel.js"]}
});
</script>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="" data-path="what-is-statistics.html"><a href="what-is-statistics.html"><i class="fa fa-check"></i>What is statistics?</a>
<ul>
<li class="chapter" data-level="" data-path="learning-statistics.html"><a href="learning-statistics.html"><i class="fa fa-check"></i>Learning statistics</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html"><i class="fa fa-check"></i>Population, sample and parametric models</a>
<ul>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#population-vs-sample"><i class="fa fa-check"></i>Population vs sample</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#parametric-models"><i class="fa fa-check"></i>Parametric models</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#a-sample-a-set-of-data-or-random-variablesa-duality"><i class="fa fa-check"></i>A sample: a set of data or random variables?–A duality</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#variability-of-estimates"><i class="fa fa-check"></i>Variability of estimates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-and-statistics.html"><a href="probability-and-statistics.html"><i class="fa fa-check"></i>Probability and statistics</a></li>
</ul></li>
<li class="part"><span><b>II Prepare</b></span></li>
<li class="chapter" data-level="1" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html"><i class="fa fa-check"></i><b>1</b> Probability theory primer</a>
<ul>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#readings"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html"><i class="fa fa-check"></i><b>1.1</b> Elementary set theory</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#set-operations"><i class="fa fa-check"></i><b>1.1.1</b> Set operations</a></li>
<li class="chapter" data-level="1.1.2" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#partitions"><i class="fa fa-check"></i><b>1.1.2</b> Partitions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html"><i class="fa fa-check"></i><b>1.2</b> Axiomatic probability</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#probability-as-a-measure"><i class="fa fa-check"></i><b>1.2.1</b> Probability as a measure</a></li>
<li class="chapter" data-level="1.2.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>1.2.2</b> Axioms of probability</a></li>
<li class="chapter" data-level="1.2.3" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#derived-probability-results"><i class="fa fa-check"></i><b>1.2.3</b> Derived probability results</a></li>
<li class="chapter" data-level="1.2.4" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#why-measure-theory"><i class="fa fa-check"></i><b>1.2.4</b> Why measure theory?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html"><i class="fa fa-check"></i><b>1.3</b> Conditioning and independence</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#bayes-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Bayes Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="conditioning-and-independence.html"><a href="conditioning-and-independence.html#independence"><i class="fa fa-check"></i><b>1.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>1.4</b> Random variables</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="random-variables.html"><a href="random-variables.html#distribution-functions"><i class="fa fa-check"></i><b>1.4.1</b> Distribution functions</a></li>
<li class="chapter" data-level="1.4.2" data-path="random-variables.html"><a href="random-variables.html#identically-distributed-r.v."><i class="fa fa-check"></i><b>1.4.2</b> Identically distributed r.v.</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-functions.html"><a href="probability-functions.html"><i class="fa fa-check"></i><b>1.5</b> Probability functions</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probability-functions.html"><a href="probability-functions.html#probability-mass-function"><i class="fa fa-check"></i><b>1.5.1</b> Probability mass function</a></li>
<li class="chapter" data-level="1.5.2" data-path="probability-functions.html"><a href="probability-functions.html#probability-density-functions"><i class="fa fa-check"></i><b>1.5.2</b> Probability density functions</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>1.6</b> Transformations</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="transformations.html"><a href="transformations.html#probability-integral-transform"><i class="fa fa-check"></i><b>1.6.1</b> Probability integral transform</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html"><i class="fa fa-check"></i><b>1.7</b> Multiple random variables</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#bivariate-distributions"><i class="fa fa-check"></i><b>1.7.1</b> Bivariate distributions</a></li>
<li class="chapter" data-level="1.7.2" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#marginal-distributions"><i class="fa fa-check"></i><b>1.7.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="1.7.3" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#conditional-distributions"><i class="fa fa-check"></i><b>1.7.3</b> Conditional distributions</a></li>
<li class="chapter" data-level="1.7.4" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>1.7.4</b> Independent random variables</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="expectations.html"><a href="expectations.html"><i class="fa fa-check"></i><b>1.8</b> Expectations</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="expectations.html"><a href="expectations.html#expectations-of-functions-of-r.v."><i class="fa fa-check"></i><b>1.8.1</b> Expectations of functions of r.v.</a></li>
<li class="chapter" data-level="1.8.2" data-path="expectations.html"><a href="expectations.html#properties-of-expectations"><i class="fa fa-check"></i><b>1.8.2</b> Properties of expectations</a></li>
<li class="chapter" data-level="1.8.3" data-path="expectations.html"><a href="expectations.html#variance"><i class="fa fa-check"></i><b>1.8.3</b> Variance</a></li>
<li class="chapter" data-level="1.8.4" data-path="expectations.html"><a href="expectations.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.8.4</b> Covariance and correlation</a></li>
<li class="chapter" data-level="1.8.5" data-path="expectations.html"><a href="expectations.html#properties-of-variances-and-covariances"><i class="fa fa-check"></i><b>1.8.5</b> Properties of variances and covariances</a></li>
<li class="chapter" data-level="1.8.6" data-path="expectations.html"><a href="expectations.html#multivariate-means-and-covariances"><i class="fa fa-check"></i><b>1.8.6</b> Multivariate means and covariances</a></li>
<li class="chapter" data-level="1.8.7" data-path="expectations.html"><a href="expectations.html#conditional-expectations-and-variance"><i class="fa fa-check"></i><b>1.8.7</b> Conditional expectations and variance</a></li>
<li class="chapter" data-level="1.8.8" data-path="expectations.html"><a href="expectations.html#additional-explainers"><i class="fa fa-check"></i><b>1.8.8</b> Additional explainers</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html"><i class="fa fa-check"></i><b>1.9</b> Moment generating functions</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#moment-generating-functions-1"><i class="fa fa-check"></i><b>1.9.1</b> Moment generating functions</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.10</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#hand-in-questions"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html"><i class="fa fa-check"></i><b>2</b> Commonly-used probability models</a>
<ul>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#learning-objectives-1"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#readings-1"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="2.1" data-path="discrete-models.html"><a href="discrete-models.html"><i class="fa fa-check"></i><b>2.1</b> Discrete models</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="discrete-models.html"><a href="discrete-models.html#point-mass-distribution"><i class="fa fa-check"></i><b>2.1.1</b> Point mass distribution</a></li>
<li class="chapter" data-level="2.1.2" data-path="discrete-models.html"><a href="discrete-models.html#uniform-distribution"><i class="fa fa-check"></i><b>2.1.2</b> Uniform distribution</a></li>
<li class="chapter" data-level="2.1.3" data-path="discrete-models.html"><a href="discrete-models.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.1.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.1.4" data-path="discrete-models.html"><a href="discrete-models.html#binomial-distribution"><i class="fa fa-check"></i><b>2.1.4</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.1.5" data-path="discrete-models.html"><a href="discrete-models.html#geometric-distribution"><i class="fa fa-check"></i><b>2.1.5</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.1.6" data-path="discrete-models.html"><a href="discrete-models.html#negative-binomial"><i class="fa fa-check"></i><b>2.1.6</b> Negative binomial</a></li>
<li class="chapter" data-level="2.1.7" data-path="discrete-models.html"><a href="discrete-models.html#poisson-distribution"><i class="fa fa-check"></i><b>2.1.7</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="continuous-models.html"><a href="continuous-models.html"><i class="fa fa-check"></i><b>2.2</b> Continuous models</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="continuous-models.html"><a href="continuous-models.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>2.2.1</b> Continuous uniform distribution</a></li>
<li class="chapter" data-level="2.2.2" data-path="continuous-models.html"><a href="continuous-models.html#exponential-distribution"><i class="fa fa-check"></i><b>2.2.2</b> Exponential distribution</a></li>
<li class="chapter" data-level="2.2.3" data-path="continuous-models.html"><a href="continuous-models.html#gamma-distribution"><i class="fa fa-check"></i><b>2.2.3</b> Gamma distribution</a></li>
<li class="chapter" data-level="2.2.4" data-path="continuous-models.html"><a href="continuous-models.html#beta-distribution"><i class="fa fa-check"></i><b>2.2.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="normal-distribution.html"><a href="normal-distribution.html#location-and-scale-parameter"><i class="fa fa-check"></i><b>2.3.1</b> Location and scale parameter</a></li>
<li class="chapter" data-level="2.3.2" data-path="normal-distribution.html"><a href="normal-distribution.html#linear-transformations-of-normal-random-variables"><i class="fa fa-check"></i><b>2.3.2</b> Linear transformations of normal random variables</a></li>
<li class="chapter" data-level="2.3.3" data-path="normal-distribution.html"><a href="normal-distribution.html#the-normal-cdf"><i class="fa fa-check"></i><b>2.3.3</b> The normal cdf</a></li>
<li class="chapter" data-level="2.3.4" data-path="normal-distribution.html"><a href="normal-distribution.html#rule"><i class="fa fa-check"></i><b>2.3.4</b> 68–95–99.7 Rule</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="some-relationships.html"><a href="some-relationships.html"><i class="fa fa-check"></i><b>2.4</b> Some relationships</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="some-relationships.html"><a href="some-relationships.html#poisson-binomial-relationship"><i class="fa fa-check"></i><b>2.4.1</b> Poisson-Binomial relationship</a></li>
<li class="chapter" data-level="2.4.2" data-path="some-relationships.html"><a href="some-relationships.html#poisson-exponential"><i class="fa fa-check"></i><b>2.4.2</b> Poisson-Exponential</a></li>
<li class="chapter" data-level="2.4.3" data-path="some-relationships.html"><a href="some-relationships.html#poisson-gamma"><i class="fa fa-check"></i><b>2.4.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="2.4.4" data-path="some-relationships.html"><a href="some-relationships.html#normal-approximations"><i class="fa fa-check"></i><b>2.4.4</b> Normal approximations</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.5</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#hand-in-questions-1"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html"><i class="fa fa-check"></i><b>3</b> Inequalities, convergences, and normal random samples</a>
<ul>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#readings-2"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#independent-and-identical-random-variable"><i class="fa fa-check"></i><b>3.1.1</b> Independent and identical random variable</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#statistic"><i class="fa fa-check"></i><b>3.1.2</b> Statistic</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Sampling distribution</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#large-sample-approximation"><i class="fa fa-check"></i><b>3.1.4</b> Large-sample approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>3.2</b> Inequalities</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inequalities.html"><a href="inequalities.html#markovs-inequality"><i class="fa fa-check"></i><b>3.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="3.2.2" data-path="inequalities.html"><a href="inequalities.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>3.2.2</b> Chebyshev’s inequality</a></li>
<li class="chapter" data-level="3.2.3" data-path="inequalities.html"><a href="inequalities.html#cauchy-schwartz-inequality"><i class="fa fa-check"></i><b>3.2.3</b> Cauchy-Schwartz inequality</a></li>
<li class="chapter" data-level="3.2.4" data-path="inequalities.html"><a href="inequalities.html#jensens-inequality"><i class="fa fa-check"></i><b>3.2.4</b> Jensen’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html"><i class="fa fa-check"></i><b>3.3</b> Convergence of random variables</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.3.1</b> Convergence in probability</a></li>
<li class="chapter" data-level="3.3.2" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Convergence in distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#mean-square-convergence"><i class="fa fa-check"></i><b>3.3.3</b> Mean-square convergence</a></li>
<li class="chapter" data-level="3.3.4" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#relationship-between-convergences"><i class="fa fa-check"></i><b>3.3.4</b> Relationship between convergences</a></li>
<li class="chapter" data-level="3.3.5" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#slutzkys-theorem"><i class="fa fa-check"></i><b>3.3.5</b> Slutzky’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>3.4</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="limit-theorems.html"><a href="limit-theorems.html#the-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>3.4.1</b> The (weak) Law of Large Numbers</a></li>
<li class="chapter" data-level="3.4.2" data-path="limit-theorems.html"><a href="limit-theorems.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="3.4.3" data-path="limit-theorems.html"><a href="limit-theorems.html#gauging-the-error-of-sample-mean-estimator"><i class="fa fa-check"></i><b>3.4.3</b> Gauging the error of sample mean estimator</a></li>
<li class="chapter" data-level="3.4.4" data-path="limit-theorems.html"><a href="limit-theorems.html#clt-with-sigma2-unknown"><i class="fa fa-check"></i><b>3.4.4</b> CLT with <span class="math inline">\(\sigma^2\)</span> unknown</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>3.5</b> Delta method</a></li>
<li class="chapter" data-level="3.6" data-path="normal-random-samples.html"><a href="normal-random-samples.html"><i class="fa fa-check"></i><b>3.6</b> Normal random samples</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="normal-random-samples.html"><a href="normal-random-samples.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6.1</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.2" data-path="normal-random-samples.html"><a href="normal-random-samples.html#students-t-distribution"><i class="fa fa-check"></i><b>3.6.2</b> Student’s <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.3" data-path="normal-random-samples.html"><a href="normal-random-samples.html#proof-of-theorem-refthmpropertynormalsamp"><i class="fa fa-check"></i><b>3.6.3</b> Proof of Theorem @ref(thm:propertynormalsamp)</a></li>
<li class="chapter" data-level="3.6.4" data-path="normal-random-samples.html"><a href="normal-random-samples.html#f-distribution"><i class="fa fa-check"></i><b>3.6.4</b> <span class="math inline">\(F\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.5" data-path="normal-random-samples.html"><a href="normal-random-samples.html#the-analysis-of-variance"><i class="fa fa-check"></i><b>3.6.5</b> The analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#hand-in-questions-2"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Inference</b></span></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#readings-3"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="4.1" data-path="the-likelihood.html"><a href="the-likelihood.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="the-likelihood.html"><a href="the-likelihood.html#calculating-the-likelihood"><i class="fa fa-check"></i><b>4.1.1</b> Calculating the likelihood</a></li>
<li class="chapter" data-level="4.1.2" data-path="the-likelihood.html"><a href="the-likelihood.html#likelihood-ratio"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood ratio</a></li>
<li class="chapter" data-level="4.1.3" data-path="the-likelihood.html"><a href="the-likelihood.html#log-likelihood"><i class="fa fa-check"></i><b>4.1.3</b> Log likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sufficiency.html"><a href="sufficiency.html"><i class="fa fa-check"></i><b>4.2</b> Sufficiency</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sufficiency.html"><a href="sufficiency.html#the-factorisation-theorem"><i class="fa fa-check"></i><b>4.2.1</b> The factorisation theorem</a></li>
<li class="chapter" data-level="4.2.2" data-path="sufficiency.html"><a href="sufficiency.html#minimal-sufficient-statistic"><i class="fa fa-check"></i><b>4.2.2</b> Minimal sufficient statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="point-estimators.html"><a href="point-estimators.html"><i class="fa fa-check"></i><b>4.3</b> Point estimators</a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>4.4</b> Method of moments</a></li>
<li class="chapter" data-level="4.5" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>4.5</b> Method of maximum likelihood</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#finding-the-mle"><i class="fa fa-check"></i><b>4.5.1</b> Finding the MLE</a></li>
<li class="chapter" data-level="4.5.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#invariance-of-mle"><i class="fa fa-check"></i><b>4.5.2</b> Invariance of MLE</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html"><i class="fa fa-check"></i><b>4.6</b> Evaluating estimators</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#bias"><i class="fa fa-check"></i><b>4.6.1</b> Bias</a></li>
<li class="chapter" data-level="4.6.2" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#variance-and-standard-error"><i class="fa fa-check"></i><b>4.6.2</b> Variance and standard error</a></li>
<li class="chapter" data-level="4.6.3" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>4.6.3</b> Mean squared error</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html"><i class="fa fa-check"></i><b>4.7</b> Cramér-Rao lower bound (CRLB)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#fisher-information"><i class="fa fa-check"></i><b>4.7.1</b> Fisher information</a></li>
<li class="chapter" data-level="4.7.2" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#variance-reduction-rao-blackwellisation"><i class="fa fa-check"></i><b>4.7.2</b> Variance reduction: Rao-Blackwellisation</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html"><i class="fa fa-check"></i><b>4.8</b> Large sample properties of estimators</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency"><i class="fa fa-check"></i><b>4.8.1</b> Consistency</a></li>
<li class="chapter" data-level="4.8.2" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-vs-unbiasedness"><i class="fa fa-check"></i><b>4.8.2</b> Consistency vs unbiasedness</a></li>
<li class="chapter" data-level="4.8.3" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-of-mles"><i class="fa fa-check"></i><b>4.8.3</b> Consistency of MLEs</a></li>
<li class="chapter" data-level="4.8.4" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency"><i class="fa fa-check"></i><b>4.8.4</b> Efficiency</a></li>
<li class="chapter" data-level="4.8.5" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#asymptotic-normality-and-consistency"><i class="fa fa-check"></i><b>4.8.5</b> Asymptotic normality and consistency</a></li>
<li class="chapter" data-level="4.8.6" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-mle"><i class="fa fa-check"></i><b>4.8.6</b> Efficiency of MLE</a></li>
<li class="chapter" data-level="4.8.7" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-transformations-of-mle"><i class="fa fa-check"></i><b>4.8.7</b> Efficiency of transformations of MLE</a></li>
<li class="chapter" data-level="4.8.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#application-of-asymptotic-normality"><i class="fa fa-check"></i><b>4.8.8</b> Application of asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-3.html"><a href="exercises-3.html#hand-in-questions-3"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#readings-4"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="5.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-1.html"><a href="introduction-1.html#a-general-paradigm"><i class="fa fa-check"></i><b>5.1.1</b> A general paradigm</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-1.html"><a href="introduction-1.html#p-values"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-1.html"><a href="introduction-1.html#accept-h_0"><i class="fa fa-check"></i><b>5.1.3</b> Accept <span class="math inline">\(H_0\)</span>?</a></li>
<li class="chapter" data-level="5.1.4" data-path="introduction-1.html"><a href="introduction-1.html#uniformity-of-p-values"><i class="fa fa-check"></i><b>5.1.4</b> Uniformity of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>5.2</b> Likelihood ratio test</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#log-likelihood-ratio-test-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Log likelihood ratio test statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.2</b> Example: Normal with known variance</a></li>
<li class="chapter" data-level="5.2.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-unknown-variance-t-test"><i class="fa fa-check"></i><b>5.2.3</b> Example: Normal with unknown variance (<span class="math inline">\(t\)</span>-test)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html"><i class="fa fa-check"></i><b>5.3</b> The Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#performance-of-a-test"><i class="fa fa-check"></i><b>5.3.1</b> Performance of a test</a></li>
<li class="chapter" data-level="5.3.2" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#relation-to-p-values"><i class="fa fa-check"></i><b>5.3.2</b> Relation to <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html"><i class="fa fa-check"></i><b>5.4</b> Type I and II errors</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#minimising-errors"><i class="fa fa-check"></i><b>5.4.1</b> Minimising errors</a></li>
<li class="chapter" data-level="5.4.2" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#optimality-of-the-lr-test"><i class="fa fa-check"></i><b>5.4.2</b> Optimality of the LR test</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sided-tests.html"><a href="one-sided-tests.html"><i class="fa fa-check"></i><b>5.5</b> One-sided tests</a></li>
<li class="chapter" data-level="5.6" data-path="approximate-tests.html"><a href="approximate-tests.html"><i class="fa fa-check"></i><b>5.6</b> Approximate tests</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="approximate-tests.html"><a href="approximate-tests.html#asymptotic-distribution-of-lrts"><i class="fa fa-check"></i><b>5.6.1</b> Asymptotic distribution of LRTs</a></li>
<li class="chapter" data-level="5.6.2" data-path="approximate-tests.html"><a href="approximate-tests.html#wilks-theorem"><i class="fa fa-check"></i><b>5.6.2</b> Wilk’s theorem</a></li>
<li class="chapter" data-level="5.6.3" data-path="approximate-tests.html"><a href="approximate-tests.html#the-wald-test"><i class="fa fa-check"></i><b>5.6.3</b> The Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-4.html"><a href="exercises-4.html#hand-in-questions-4"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>6</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#readings-5"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="6.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-2.html"><a href="introduction-2.html#coverage-probability"><i class="fa fa-check"></i><b>6.1.1</b> Coverage probability</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-2.html"><a href="introduction-2.html#confidence-regions"><i class="fa fa-check"></i><b>6.1.2</b> Confidence regions</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-2.html"><a href="introduction-2.html#methods-for-obtaining-confidence-regions"><i class="fa fa-check"></i><b>6.1.3</b> Methods for obtaining confidence regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pivots.html"><a href="pivots.html"><i class="fa fa-check"></i><b>6.2</b> Pivots</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pivots.html"><a href="pivots.html#from-pivot-to-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> From pivot to confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Inverting a test statistic</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html#discrete-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Discrete distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="desirable-confidence-sets.html"><a href="desirable-confidence-sets.html"><i class="fa fa-check"></i><b>6.4</b> Desirable confidence sets</a></li>
<li class="chapter" data-level="6.5" data-path="intervals-based-on-ml-methods.html"><a href="intervals-based-on-ml-methods.html"><i class="fa fa-check"></i><b>6.5</b> Intervals based on ML methods</a></li>
<li class="chapter" data-level="6.6" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>6.6</b> The bootstrap method</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#empirical-distribution"><i class="fa fa-check"></i><b>6.6.1</b> Empirical distribution</a></li>
<li class="chapter" data-level="6.6.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-variance-estimation"><i class="fa fa-check"></i><b>6.6.2</b> Bootstrap variance estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap confidence intervals</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#normal-bootstrap-interval"><i class="fa fa-check"></i><b>6.7.1</b> Normal bootstrap interval</a></li>
<li class="chapter" data-level="6.7.2" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-percentile-interval"><i class="fa fa-check"></i><b>6.7.2</b> Bootstrap percentile interval</a></li>
<li class="chapter" data-level="6.7.3" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-pivotal-interval"><i class="fa fa-check"></i><b>6.7.3</b> Bootstrap pivotal interval</a></li>
<li class="chapter" data-level="6.7.4" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#which-one-to-use"><i class="fa fa-check"></i><b>6.7.4</b> Which one to use?</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-5.html"><a href="exercises-5.html#hand-in-questions-5"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="exam-tips.html"><a href="exam-tips.html"><i class="fa fa-check"></i><b>A</b> Exam tips</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SM-4331 Advanced Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="normal-random-samples" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Normal random samples</h2>
<p>Given that the normal distribution is very often used, the properties of normal random samples have been studied extensively.</p>
<div class="theorem">
<p><span id="thm:propertynormalsamp" class="theorem"><strong>Theorem 3.5  </strong></span>Let <span class="math inline">\(\{X_1,\dots,X_n \}\)</span> be a sample from <span class="math inline">\(\mathop{\mathrm{N}}(\mu,\sigma^2)\)</span>, and let</p>
<p><span class="math display">\[\bar X = \frac{1}{n}\sum_{i=1}^n X_i, \hspace{2em} 
    S^2 =  \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar X)^2, \hspace{1em} 
    \text{ and } \hspace{1em} \text{SE}(\bar X) = S/\sqrt{n}.\]</span></p>
<p>Then,</p>
<ul>
<li><span class="math inline">\(\bar X\)</span> and <span class="math inline">\(S^2\)</span> are independent random variables</li>
<li><span class="math inline">\(\bar X \sim \mathop{\mathrm{N}}(\mu,\sigma^2/n)\)</span></li>
<li><span class="math inline">\((n-1)S^2/\sigma^2 \sim \chi^2_{n-1}\)</span></li>
<li><span class="math inline">\(\frac{\sqrt n (\bar X - \mu)}{S} = \frac{\bar X - \mu}{\text{SE}(\bar X)} \sim t_{n-1}\)</span></li>
</ul>
</div>
<p>The above theorem mentions two kinds of distribution (that you may have heard of) but we are yet to discuss.
We’ll circle back to the proof othis theorem after covering the <span class="math inline">\(\chi^2\)</span> and <span class="math inline">\(t\)</span> distributions.</p>
<div id="chi2-distribution" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> <span class="math inline">\(\chi^2\)</span>-distribution</h3>
<p>The <span class="math inline">\(\chi^2\)</span>-distribution is an important distribution in statistics.
It is closely linked with the normal, Student’s <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> distributions. Inference for the variance parameter <span class="math inline">\(\sigma^2\)</span> relies on <span class="math inline">\(\chi^2\)</span>-distributions.
More importantly, most goodness-of-fit tests are based on <span class="math inline">\(\chi^2\)</span>-distributions.</p>
<div class="definition">
<p><span id="def:chisq" class="definition"><strong>Definition 3.6  ($\chi^2$-distribution) </strong></span>Let <span class="math inline">\(Z_1,\dots,Z_k \,\overset{\text{iid}}{\sim}\,\mathop{\mathrm{N}}(0,1)\)</span>, i.e. each <span class="math inline">\(Z_i\)</span> has pdf <span class="math inline">\(f(z_i) = (2\pi)^{-1/2}e^{-z_i^2/2}\)</span> for <span class="math inline">\(i=1,\dots,k\)</span>.
Then,
<span class="math display">\[X = Z_1^2 + \dots + Z_k^2 = \sum_{i=1}^k Z_i^2\]</span>
follows a <span class="math inline">\(\chi^2\)</span>-distribution with <span class="math inline">\(k\in\mathbb{N}\)</span> degrees of freedom.
We write
<span class="math inline">\(X \sim \chi^2_k\)</span>.</p>
</div>
<p>Out of curiosity, the pdf of a <span class="math inline">\(\chi^2_k\)</span> distribution is <span class="math inline">\(f(x) = Cx^{k/2-1}e^{-x/2}\)</span>, where the normalising constant <span class="math inline">\(C\)</span> is equal to <span class="math inline">\(2^{-k/2}\Gamma^{-1}(k/2)\)</span> (<span class="math inline">\(\Gamma(\cdot)\)</span> is the gamma function).
The form of the pdf is less important to know than the definition of <span class="math inline">\(\chi^2_k\)</span> distribution given in Definition <a href="normal-random-samples.html#def:chisq">3.6</a>.</p>
<p>Here are some important properties of the <span class="math inline">\(\chi^2_k\)</span> distribution.</p>
<ul>
<li><span class="math inline">\(X\)</span> has support over <span class="math inline">\([0,\infty)\)</span>.</li>
<li><span class="math inline">\(\mathop{\mathrm{E}}(X)=k\)</span>.</li>
<li><span class="math inline">\(\mathop{\mathrm{Var}}(X) = 2k\)</span>.</li>
<li>If <span class="math inline">\(X_1\sim\chi^2_{k_1}\)</span> and <span class="math inline">\(X_2\sim\chi^2_{k_2}\)</span>, and
<span class="math inline">\(X_1 \perp X_2\)</span>, then <span class="math inline">\(X_1+X_2\sim \chi^2_{k_1+k_2}\)</span>.</li>
</ul>
<div class="mycheck">
<p>There is a question at the end of this chapter where you will prove the above statements.</p>
</div>
<p>Pdf of <span class="math inline">\(\chi^2_k\)</span></p>
<p><img src="bookdown-adv-stats_files/figure-html/chisqdist-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Probabilities such as</p>
<p><span class="math display">\[\Pr(\chi_k^2 \leq x) = \int_0^x f_X(\tilde x) \mathop{\mathrm{d}}\hspace{0.5pt}\!\tilde x\]</span> where <span class="math inline">\(f_X\)</span> is the pdf of <span class="math inline">\(\chi^2_k\)</span> cannot be found in closed form.
Instead, the integral is calculated using computer approximations for the integral above.
In <code>R</code>,</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="normal-random-samples.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="dv">2</span>, <span class="at">df =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.4275933</code></pre>
<p>Alternatively, statistical tables are used.
You will find tables for percentiles of the <span class="math inline">\(\chi^2\)</span>-distribution.
That is, you are able to find the value of <span class="math inline">\(x:=\chi^2_k(\alpha)\)</span> such that</p>
<p><span class="math display">\[\Pr(\chi_k^2 \leq x) = \int_0^x f_X(\tilde x) \mathop{\mathrm{d}}\hspace{0.5pt}\!\tilde x = A = 1-\alpha\]</span>
for various values of <span class="math inline">\(A\)</span> and <span class="math inline">\(k\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-101" class="example"><strong>Example 3.9  </strong></span>Let <span class="math inline">\(Y_1,\dots,Y_n\,\overset{\text{iid}}{\sim}\,\mathop{\mathrm{N}}(\mu,\sigma^2)\)</span>.
Then, <span class="math inline">\(Z_i = \frac{Y_i-\mu}{\sigma} \sim \mathop{\mathrm{N}}(0,1)\)</span>, and hence</p>
<p><span class="math display">\[\frac{1}{\sigma^2} \sum_{i=1}^n (Y_i-\mu)^2 = \sum_{i=1}^n Z_i^2 \sim \chi^2_n .\]</span></p>
<p>Note that
<span class="math display" id="eq:chisqdecomp">\[\begin{equation}
    \frac{1}{\sigma^2} \sum_{i=1}^n (Y_i-\mu)^2
    = \frac{1}{\sigma^2} \sum_{i=1}^n (Y_i-\bar Y_n)^2 +  \frac{n}{\sigma^2} (\bar Y_n -\mu)^2. \tag{3.3}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(\bar Y_n \sim \mathop{\mathrm{N}}(\mu, \sigma^2/n)\)</span>, it must be that
<span class="math inline">\(\frac{n}{\sigma^2} (\bar Y_n -\mu)^2 \sim \chi^2_1\)</span>.
Thus, by the properties of the <span class="math inline">\(\chi^2\)</span>-distribution, the decomposition in <a href="normal-random-samples.html#eq:chisqdecomp">(3.3)</a> may be written as
<span class="math inline">\(\chi^2_n = \chi^2_{n-1} + \chi^2_{1}\)</span>.
In particular, we now know
<span class="math display">\[\frac{1}{\sigma^2} \sum_{i=1}^n (Y_i-\bar Y_n)^2 \sim \chi^2_{n-1} .\]</span></p>
</div>
</div>
<div id="students-t-distribution" class="section level3" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> Student’s <span class="math inline">\(t\)</span>-distribution</h3>
<p>This is another important distribution in
statistics, because:</p>
<ul>
<li>The <span class="math inline">\(t\)</span>-test is a widely used distribution for statistical tests in many
application.</li>
<li>Confidence intervals for normal mean with unknown variance may be
constructed based on the <span class="math inline">\(t\)</span>-distribution.</li>
</ul>
<div class="definition">
<p><span id="def:unlabeled-div-102" class="definition"><strong>Definition 3.7  ($t$-distribution) </strong></span>Suppose we have two random variable <span class="math inline">\(Z\sim\mathop{\mathrm{N}}(0,1)\)</span> and <span class="math inline">\(X\sim\chi^2_k\)</span> such that <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> are independent.
Then, the distribution of the random variable
<span class="math display">\[T = \frac{Z}{\sqrt{X/k}}\]</span> is called the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(k\in\mathbb{N}\)</span>
degrees of freedom. We write <span class="math inline">\(T\sim t_k\)</span>.</p>
</div>
<p>The pdf for <span class="math inline">\(T \sim t_k\)</span> is given by
<span class="math display">\[f(t) \propto \left(1 + \frac{t^2}{k} \right)^{-\frac{k+1}{2}},\]</span> but
once again the actual form of the pdf is not as important as the
definition of the <span class="math inline">\(t\)</span>-distribution.</p>
<p>Some important properties of the <span class="math inline">\(t\)</span>-distribution:</p>
<ul>
<li><span class="math inline">\(T\)</span> is continuous and symmetric over <span class="math inline">\((-\infty,\infty)\)</span>.</li>
<li><span class="math inline">\(\mathop{\mathrm{E}}(T)=0\)</span>, provided <span class="math inline">\(\mathop{\mathrm{E}}(|T|) &lt; \infty\)</span> (<span class="math inline">\(k&gt;1\)</span>).</li>
<li><span class="math inline">\(\mathop{\mathrm{Var}}(T) = \frac{k}{k-2}\)</span>.</li>
<li>Technically, <span class="math inline">\(k\in\mathbb{R}\)</span>, but we will usually deal with <span class="math inline">\(k\in\mathbb{N}\)</span>.</li>
</ul>
<p>Pdf of <span class="math inline">\(t_k\)</span></p>
<p><img src="bookdown-adv-stats_files/figure-html/tdist-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:student"></span>
<img src="figure/student.jpg" alt="William Sealy Gosset. 13 June 1876 -- 16 October 1937." width="60%" />
<p class="caption">
Figure 3.1: William Sealy Gosset. 13 June 1876 – 16 October 1937.
</p>
</div>
<p>The <span class="math inline">\(t\)</span>-distribution<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> has what is known as <strong>heavy tails</strong>.
That is, if <span class="math inline">\(T\sim t_k\)</span>, its mgf is undefined and hence <span class="math inline">\(\mathop{\mathrm{E}}(|T|^k) = \infty\)</span>.
Comparing this to the normal distribution:
<span class="math inline">\(X\sim\mathop{\mathrm{N}}(\mu,\sigma^2)\)</span>, <span class="math inline">\(\mathop{\mathrm{E}}(|X|^k) &lt; \infty\)</span> for any <span class="math inline">\(k&gt;0\)</span>.
This ‘heavy-tails’ property is a useful property in modelling
abnormal phenomena or outliers (e.g. in financial or insurance data).
c.f. “robust statistics”</p>
<p>The connection between the <span class="math inline">\(t_k\)</span> distribution and the normal distribution, is that the <span class="math inline">\(t_k\)</span> actually approaches the standard normal as the degrees of freedom increases.</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-103" class="lemma"><strong>Lemma 3.6  </strong></span><span class="math inline">\(t_k \xrightarrow{\text{D}} \mathop{\mathrm{N}}(0,1)\)</span> as <span class="math inline">\(k\to\infty\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-104" class="proof"><em>Proof</em>. </span>If <span class="math inline">\(X\sim\chi^2_k\)</span>, then by definition
<span class="math inline">\(X = Z_1^2 + \dots + Z_k^2\)</span>, where <span class="math inline">\(Z_i\,\overset{\text{iid}}{\sim}\,\mathop{\mathrm{N}}(0,1)\)</span>. By the LLN,
<span class="math display">\[\frac{X}{k} = \frac{Z_1^2 + \dots + Z_k^2}{k} \xrightarrow{\text{P}} \mathop{\mathrm{E}}(Z_1^2) = 1.\]</span>
as <span class="math inline">\(k\to\infty\)</span>. Therefore, <span class="math inline">\(\sqrt{X/k} \xrightarrow{\text{P}} 1\)</span>, and
in particular,
<span class="math display">\[T = \frac{Z}{\sqrt{X/k}} \xrightarrow{\text{D}} \mathop{\mathrm{N}}(0,1)\]</span>
following Slutzky’s theorem.</p>
</div>
</div>
<div id="proof-of-theorem-refthmpropertynormalsamp" class="section level3" number="3.6.3">
<h3><span class="header-section-number">3.6.3</span> Proof of Theorem <a href="normal-random-samples.html#thm:propertynormalsamp">3.5</a></h3>
<p>Back to this theorem. Let’s prove it.</p>
<div class="proof">
<ol start="2" style="list-style-type: lower-roman">
<li></li>
<li>follows directly from properties of normal distributions, and
earlier we showed that <span class="math inline">\(\frac{1}{\sigma^2}\sum_{i=1}^n (X_i - \bar X)^2 \sim \chi^2_{n-1}\)</span> which settles iii.</li>
</ol>
<p>To prove i., consider any <span class="math inline">\(X_j\)</span>, <span class="math inline">\(j\in\{1,\dots,n\}\)</span> and
<span class="math inline">\(\mathop{\mathrm{Cov}}( X_j - \bar X, \bar X)\)</span>: <span class="math display">\[\begin{aligned}
    \mathop{\mathrm{Cov}}( X_j - \bar X, \bar X)
    &amp;= \mathop{\mathrm{Cov}}( X_j, \bar X) - \mathop{\mathrm{Cov}}(\bar X, \bar X) \\
    &amp;= \mathop{\mathrm{Cov}}\left(X_j, \frac{1}{n}\sum_{i=1}^n X_i\right) - \mathop{\mathrm{Var}}(\bar X) \\
    &amp;= \frac{1}{n} \sum_{i=1}^n \mathop{\mathrm{Cov}}(X_j,X_i) - \sigma^2/n = \sigma^2 /n - \sigma^2 /n = 0
  \end{aligned}\]</span>
Since the covariance is zero and they are normal, they
are independent.</p>
<p>Following this, if <span class="math inline">\(\bar X\)</span> is independent of <span class="math inline">\(X_j - \bar X\)</span> for
any <span class="math inline">\(j\)</span>, it stands to reason that <span class="math inline">\(\bar X\)</span> is also independent of
<span class="math inline">\(\tilde {\boldsymbol X}= (X_1-\bar X,\dots,X_n-\bar X)^\top\)</span>, and also of
<span class="math display">\[\tilde{\boldsymbol X}^\top\tilde{\boldsymbol X}= 
    \begin{pmatrix}
      X_1-\bar X &amp;
      \cdots &amp;
      X_n-\bar X
    \end{pmatrix}
    \begin{pmatrix}
      X_1-\bar X \\
      \vdots \\
      X_n-\bar X
    \end{pmatrix}
    = \sum_{i=1}^n (X_i - \bar X)^2 = (n-1)S^2,\]</span> and thus also of
<span class="math inline">\(S^2\)</span>. Here we used the fact that if <span class="math inline">\(X \perp Y_i\)</span>, then <span class="math inline">\(g(X)\perp g(Y_i)\)</span>,
and also <span class="math inline">\(g(X) \perp \{g(Y_1) + \cdots + g(Y_n)\}\)</span>.</p>
<p>Finally, putting everything together,
<span class="math display">\[\frac{\overbrace{\sqrt n(\bar X - \mu)/\sigma}^{\mathop{\mathrm{N}}(0,1)}}{\sqrt{\frac{\overbrace{(n-1)S^2/\sigma^2}^{\chi^2_{n-1}}}{n-1}}}
    = \frac{\bar X - \mu}{S/\sqrt{n}}
    = \frac{\bar X - \mu}{\text{SE}(\bar X)} \sim t_{n-1}.\]</span></p>
</div>
<p>This is why for normal distributions where <span class="math inline">\(\sigma^2\)</span> is unknown,
and is estimated by the unbiased sample variance <span class="math inline">\(s^2\)</span>, the standardised
sample mean follows a <span class="math inline">\(t\)</span>-distribution! This gives rise to the <span class="math inline">\(t\)</span>-test.</p>
</div>
<div id="f-distribution" class="section level3" number="3.6.4">
<h3><span class="header-section-number">3.6.4</span> <span class="math inline">\(F\)</span>-distribution</h3>
<p>The <span class="math inline">\(F\)</span>-distribution is another notable distribution in
statistics. It commonly arises as the null distribution of a test
statistic, particularly in the analysis of variance (ANOVA).</p>
<div class="definition">
<p><span id="def:unlabeled-div-106" class="definition"><strong>Definition 3.8  ($F$-distribution) </strong></span>Let <span class="math inline">\(X_1 \sim \chi^2_{k_1}\)</span> and <span class="math inline">\(X_2 \sim \chi^2_{k_2}\)</span>.
Then, the distribution of <span class="math display">\[Y = \frac{X_1/k_1}{X_2/k_2}\]</span> is called the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\((k_1,k_2)\)</span> degrees of freedom.
We write <span class="math inline">\(Y\sim F_{k_1,k_2}\)</span>.</p>
</div>
<p>Not even going to bother writing down the pdf! See for yourself:
<a href="https://en.wikipedia.org/wiki/F-distribution" class="uri">https://en.wikipedia.org/wiki/F-distribution</a>.
Remember the definition, though.</p>
<p>Some important properties of the <span class="math inline">\(F\)</span>-distribution:</p>
<ul>
<li><span class="math inline">\(Y\)</span> is continuous and has support over <span class="math inline">\([0,\infty)\)</span>, provided
<span class="math inline">\(k_1&gt;1\)</span>.</li>
<li><span class="math inline">\(\mathop{\mathrm{E}}(Y)=\frac{k_2}{k_2 - 2}\)</span>, provided <span class="math inline">\(k_2&gt;2\)</span>.</li>
<li><span class="math inline">\(\mathop{\mathrm{Var}}(Y) = \frac{2k_2^2(k_1+k_2-2)}{k_1(k_2-2)^2(k_2-4)}\)</span>, provided
<span class="math inline">\(k_2&gt;4\)</span>.</li>
<li>Technically, <span class="math inline">\(k_1,k_2\in\mathbb{R}_{&gt;0}\)</span>, but we will usually deal with
<span class="math inline">\(k_1,k_2\in\mathbb{N}\)</span>.</li>
<li>If <span class="math inline">\(Y\sim F_{k_1,k_2}\)</span>, then <span class="math inline">\(Y^{-1}\sim F_{k_2,k_1}\)</span>.</li>
<li>If <span class="math inline">\(T\sim t_{k}\)</span>, then <span class="math inline">\(T^2 \sim F_{1,k}\)</span>.</li>
</ul>
<div class="mycheck">
<p>Attempt to prove some of these in the exercises!</p>
</div>
<p><img src="bookdown-adv-stats_files/figure-html/Fdist-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-analysis-of-variance" class="section level3" number="3.6.5">
<h3><span class="header-section-number">3.6.5</span> The analysis of variance</h3>
<p>The ANOVA, despite its name, is a (collection of) methods used to analyse differences among group means in a sample.</p>
<p><img src="bookdown-adv-stats_files/figure-html/anovasamp-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The setup is as follows:
Let <span class="math inline">\(Y_{ij}\sim\mathop{\mathrm{N}}(\mu_j,\sigma^2)\)</span>, <span class="math inline">\(i=1,\dots,n_j\)</span> and <span class="math inline">\(j=1,\dots,m\)</span> with both <span class="math inline">\(\mu_j\)</span> and <span class="math inline">\(\sigma^2\)</span> unknown.
Let <span class="math inline">\(n=\sum_{j=1}^m n_j\)</span> be the total sample size.
Define</p>
<ul>
<li>the grand mean <span class="math inline">\(\bar Y = n^{-1}\sum_{i,j} Y_{ij}\)</span>; and</li>
<li>the group means <span class="math inline">\(\bar Y_j = n_j^{-1} \sum_{i=1}^{n_j} Y_{ij}\)</span>, <span class="math inline">\(j=1,\dots,m\)</span>.</li>
</ul>
<p>Consider the “total sum of squares” <span class="math inline">\(TSS = \sum_{i,j}(Y_{ij} - \bar Y)^2\)</span>, which can be decomposed into <span class="math display">\[TSS = 
  {\color{gray!70}\overbrace{\color{black}\sum_{i,j} (Y_{ij} - \bar Y_j)^2}^{WSS}} +
  {\color{gray!70}\overbrace{\color{black}\sum_{j} n_j(\bar Y_j - \bar Y)^2}^{BSS}}\]</span> where</p>
<ul>
<li><span class="math inline">\(WSS\)</span> is the “within sum of squares” (how much variation among individuals
in each group); and</li>
<li><span class="math inline">\(BSS\)</span> is the “between sum of squares” (how much
variation in the mean among groups).</li>
</ul>
<p>There is a concept of <em>degrees of freedom</em>: <span class="math inline">\(n-1\)</span> in the TSS, <span class="math inline">\(m-1\)</span> in
the BSS, and therefore <span class="math inline">\(n-m\)</span> in the WSS.</p>
<p>This gives rise to the ANOVA table:</p>
<table>
<thead>
<tr class="header">
<th align="left">Source</th>
<th align="center">SS</th>
<th align="center">d.f.</th>
<th align="center">MSS</th>
<th align="center">F-statistic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Between</td>
<td align="center"><span class="math inline">\(\sum_{j} n_j(\bar Y_j - \bar Y)^2\)</span></td>
<td align="center"><span class="math inline">\(m-1\)</span></td>
<td align="center"><span class="math inline">\(\frac{\sum_{j} n_j(\bar Y_j - \bar Y)^2}{m-1}\)</span></td>
<td align="center"><span class="math inline">\(\frac{\sum_{j} n_j(\bar Y_j - \bar Y)^2/(m-1)}{\sum_{i,j} (Y_{ij} - \bar Y_j)^2/(n-m)}\)</span></td>
</tr>
<tr class="even">
<td align="left">Within</td>
<td align="center"><span class="math inline">\(\sum_{i,j} (Y_{ij} - \bar Y_j)^2\)</span></td>
<td align="center"><span class="math inline">\(n-m\)</span></td>
<td align="center"><span class="math inline">\(\frac{\sum_{i,j} (Y_{ij} - \bar Y_j)^2}{n-m}\)</span></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center"><span class="math inline">\(\sum_{i,j}(Y_{ij} - \bar Y)^2\)</span></td>
<td align="center"><span class="math inline">\(n-1\)</span></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Suppose we want to test the hypothesis that all group means are identical (i.e. <span class="math inline">\(\mu_j=\mu, \forall j\)</span>), what is the distribution of <span class="math inline">\(F\)</span>?</p>
<p>We have seen that
<span class="math display">\[TSS/\sigma^2 = \frac{1}{\sigma^2}\sum_{i,j}(Y_{ij} - \bar Y)^2 \sim \chi^2_{n-1}.\]</span>
In fact, we can also show similarly that
<span class="math display">\[WSS/\sigma^2 =\frac{1}{\sigma^2}\sum_{i,j} (Y_{ij} - \bar Y_j)^2 \sim \chi^2_{n-m}.\]</span>
Using these two facts, we deduce that
<span class="math display">\[BSS/\sigma^2=\frac{1}{\sigma^2}\sum_{j} n_j(\bar Y_j - \bar Y)^2 \sim \chi^2_{m-1}\]</span>
from the property of <span class="math inline">\(\chi^2\)</span>-distributions.</p>
<p>So now, <span class="math display">\[\begin{aligned}
    F = \frac{\text{mean }BSS}{\text{mean }WSS} = \frac{ \overbrace{1/\sigma^2\sum_{j} n_j(\bar Y_j - \bar Y)^2}^{\chi^2_{m-1}} / (m-1)}{ \overbrace{1/\sigma^2\sum_{i,j}(Y_{ij} - \bar Y_j)^2}^{\chi^2_{n-m}} / (n-m)}
  \end{aligned}\]</span> is a ratio of two <span class="math inline">\(\chi^2\)</span>-distributions, which means
that <span class="math inline">\(F\)</span> follows an <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\((m-1,n-m)\)</span> degrees of
freedom.</p>
<!-- ### The analysis of variance -->
<!-- Stop to think What happens when there are only two groups ($m=2$)? -->
<!-- -   What is the distribution of $\chi^2_1$ equal to? -->
<!-- -   What is the distribution of the test statistic $F$? -->
<!-- -   What is the distribution of $\sqrt F$? -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fisher"></span>
<img src="figure/fisher.jpg" alt="Sir Ronald Aylmer Fisher. 17 February 1890 -- 29 July 1962." width="50%" />
<p class="caption">
Figure 3.2: Sir Ronald Aylmer Fisher. 17 February 1890 – 29 July 1962.
</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="30">
<li id="fn30"><p>Explore the <span class="math inline">\(t\)</span>-distribution vs normal distribution here:
<a href="https://eripoll12.shinyapps.io/t_Student/" class="uri">https://eripoll12.shinyapps.io/t_Student/</a><a href="normal-random-samples.html#fnref30" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="delta-method.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/haziqj/adv-stats/edit/main/04-inequalities_etc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-adv-stats.pdf", "bookdown-adv-stats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
