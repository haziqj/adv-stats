<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Axiomatic probability | SM-4331 Advanced Statistics</title>
  <meta name="description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Axiomatic probability | SM-4331 Advanced Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Axiomatic probability | SM-4331 Advanced Statistics" />
  
  <meta name="twitter:description" content="Course notes for SM-4331 Advanced Statistics (UBD)." />
  

<meta name="author" content="Dr Haziq Jamil" />


<meta name="date" content="2021-11-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="elementary-set-theory.html"/>
<link rel="next" href="conditional-probabilities.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="mystyle.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SM-4331 Advanced Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html"><i class="fa fa-check"></i>Contents</a>
<ul>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html#goals"><i class="fa fa-check"></i>Goals</a></li>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html#incidental-learning-outcomes"><i class="fa fa-check"></i>Incidental learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html"><i class="fa fa-check"></i>Module information</a>
<ul>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#class-format"><i class="fa fa-check"></i>Class format</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#assessment"><i class="fa fa-check"></i>Assessment</a></li>
<li class="chapter" data-level="" data-path="module-information.html"><a href="module-information.html#key-data"><i class="fa fa-check"></i>Key data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html"><i class="fa fa-check"></i>Course policy</a>
<ul>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#communication-policy"><i class="fa fa-check"></i>Communication policy</a></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#attendance-policy"><i class="fa fa-check"></i>Attendance policy</a></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#conduct"><i class="fa fa-check"></i>Conduct</a></li>
<li class="chapter" data-level="" data-path="course-policy.html"><a href="course-policy.html#learning-management-system"><i class="fa fa-check"></i>Learning Management System</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html"><i class="fa fa-check"></i>Resources</a>
<ul>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html#this-course"><i class="fa fa-check"></i>This course</a></li>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html#textbooks"><i class="fa fa-check"></i>Textbooks</a></li>
<li class="chapter" data-level="" data-path="resources.html"><a href="resources.html#miscellaneous"><i class="fa fa-check"></i>Miscellaneous</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="" data-path="what-is-statistics.html"><a href="what-is-statistics.html"><i class="fa fa-check"></i>What is statistics?</a>
<ul>
<li class="chapter" data-level="" data-path="learning-statistics.html"><a href="learning-statistics.html"><i class="fa fa-check"></i>Learning statistics</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html"><i class="fa fa-check"></i>Population, sample and parametric models</a>
<ul>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#population-vs-sample"><i class="fa fa-check"></i>Population vs sample</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#parametric-models"><i class="fa fa-check"></i>Parametric models</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#a-sample-a-set-of-data-or-random-variablesa-duality"><i class="fa fa-check"></i>A sample: a set of data or random variables?–A duality</a></li>
<li class="chapter" data-level="" data-path="population-sample-and-parametric-models.html"><a href="population-sample-and-parametric-models.html#variability-of-estimates"><i class="fa fa-check"></i>Variability of estimates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-and-statistics.html"><a href="probability-and-statistics.html"><i class="fa fa-check"></i>Probability and statistics</a></li>
</ul></li>
<li class="part"><span><b>II Prepare</b></span></li>
<li class="chapter" data-level="1" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html"><i class="fa fa-check"></i><b>1</b> Probability theory primer</a>
<ul>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="probability-theory-primer.html"><a href="probability-theory-primer.html#readings"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html"><i class="fa fa-check"></i><b>1.1</b> Elementary set theory</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#set-operations"><i class="fa fa-check"></i><b>1.1.1</b> Set operations</a></li>
<li class="chapter" data-level="1.1.2" data-path="elementary-set-theory.html"><a href="elementary-set-theory.html#partitions"><i class="fa fa-check"></i><b>1.1.2</b> Partitions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html"><i class="fa fa-check"></i><b>1.2</b> Axiomatic probability</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#probability-as-a-measure"><i class="fa fa-check"></i><b>1.2.1</b> Probability as a measure</a></li>
<li class="chapter" data-level="1.2.2" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>1.2.2</b> Axioms of probability</a></li>
<li class="chapter" data-level="1.2.3" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#derived-probability-results"><i class="fa fa-check"></i><b>1.2.3</b> Derived probability results</a></li>
<li class="chapter" data-level="1.2.4" data-path="axiomatic-probability.html"><a href="axiomatic-probability.html#why-measure-theory"><i class="fa fa-check"></i><b>1.2.4</b> Why measure theory?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="conditional-probabilities.html"><a href="conditional-probabilities.html"><i class="fa fa-check"></i><b>1.3</b> Conditional probabilities</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="conditional-probabilities.html"><a href="conditional-probabilities.html#conditional-probability"><i class="fa fa-check"></i><b>1.3.1</b> Conditional probability</a></li>
<li class="chapter" data-level="1.3.2" data-path="conditional-probabilities.html"><a href="conditional-probabilities.html#bayes-theorem"><i class="fa fa-check"></i><b>1.3.2</b> Bayes Theorem</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="independent-events.html"><a href="independent-events.html"><i class="fa fa-check"></i><b>1.4</b> Independent events</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="independent-events.html"><a href="independent-events.html#independence"><i class="fa fa-check"></i><b>1.4.1</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>1.5</b> Random variables</a></li>
<li class="chapter" data-level="1.6" data-path="distribution-functions.html"><a href="distribution-functions.html"><i class="fa fa-check"></i><b>1.6</b> Distribution functions</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="distribution-functions.html"><a href="distribution-functions.html#properties-of-cdfs"><i class="fa fa-check"></i><b>1.6.1</b> Properties of cdfs</a></li>
<li class="chapter" data-level="1.6.2" data-path="distribution-functions.html"><a href="distribution-functions.html#identically-distributed-r.v."><i class="fa fa-check"></i><b>1.6.2</b> Identically distributed r.v.</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="probability-functions.html"><a href="probability-functions.html"><i class="fa fa-check"></i><b>1.7</b> Probability functions</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="probability-functions.html"><a href="probability-functions.html#probability-mass-function"><i class="fa fa-check"></i><b>1.7.1</b> Probability mass function</a></li>
<li class="chapter" data-level="1.7.2" data-path="probability-functions.html"><a href="probability-functions.html#probability-density-functions"><i class="fa fa-check"></i><b>1.7.2</b> Probability density functions</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html"><i class="fa fa-check"></i><b>1.8</b> Multiple random variables</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#bivariate-distributions"><i class="fa fa-check"></i><b>1.8.1</b> Bivariate distributions</a></li>
<li class="chapter" data-level="1.8.2" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#marginal-distributions"><i class="fa fa-check"></i><b>1.8.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="1.8.3" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#conditional-distributions"><i class="fa fa-check"></i><b>1.8.3</b> Conditional distributions</a></li>
<li class="chapter" data-level="1.8.4" data-path="multiple-random-variables.html"><a href="multiple-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>1.8.4</b> Independent random variables</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="expectations.html"><a href="expectations.html"><i class="fa fa-check"></i><b>1.9</b> Expectations</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="expectations.html"><a href="expectations.html#expected-values"><i class="fa fa-check"></i><b>1.9.1</b> Expected values</a></li>
<li class="chapter" data-level="1.9.2" data-path="expectations.html"><a href="expectations.html#expectations-of-functions-of-r.v."><i class="fa fa-check"></i><b>1.9.2</b> Expectations of functions of r.v.</a></li>
<li class="chapter" data-level="1.9.3" data-path="expectations.html"><a href="expectations.html#properties-of-expectations"><i class="fa fa-check"></i><b>1.9.3</b> Properties of expectations</a></li>
<li class="chapter" data-level="1.9.4" data-path="expectations.html"><a href="expectations.html#variance"><i class="fa fa-check"></i><b>1.9.4</b> Variance</a></li>
<li class="chapter" data-level="1.9.5" data-path="expectations.html"><a href="expectations.html#covariance-and-correlation"><i class="fa fa-check"></i><b>1.9.5</b> Covariance and correlation</a></li>
<li class="chapter" data-level="1.9.6" data-path="expectations.html"><a href="expectations.html#properties-of-variances-and-covariances"><i class="fa fa-check"></i><b>1.9.6</b> Properties of variances and covariances</a></li>
<li class="chapter" data-level="1.9.7" data-path="expectations.html"><a href="expectations.html#variance-covariance-matrix"><i class="fa fa-check"></i><b>1.9.7</b> Variance-covariance matrix</a></li>
<li class="chapter" data-level="1.9.8" data-path="expectations.html"><a href="expectations.html#conditional-expectations"><i class="fa fa-check"></i><b>1.9.8</b> Conditional expectations</a></li>
<li class="chapter" data-level="1.9.9" data-path="expectations.html"><a href="expectations.html#conditional-variance"><i class="fa fa-check"></i><b>1.9.9</b> Conditional variance</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html"><i class="fa fa-check"></i><b>1.10</b> Moment generating functions</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#moment-generating-functions-1"><i class="fa fa-check"></i><b>1.10.1</b> Moment generating functions</a></li>
<li class="chapter" data-level="1.10.2" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#generating-moments"><i class="fa fa-check"></i><b>1.10.2</b> Generating moments</a></li>
<li class="chapter" data-level="1.10.3" data-path="moment-generating-functions.html"><a href="moment-generating-functions.html#properties-of-mgf"><i class="fa fa-check"></i><b>1.10.3</b> Properties of mgf</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.11</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises.html"><a href="exercises.html#hand-in-questions"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html"><i class="fa fa-check"></i><b>2</b> Commonly-used probability models</a>
<ul>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#learning-objectives-1"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="commonly-used-probability-models.html"><a href="commonly-used-probability-models.html#readings-1"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="discrete-models.html"><a href="discrete-models.html"><i class="fa fa-check"></i><b>2.2</b> Discrete models</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="discrete-models.html"><a href="discrete-models.html#point-mass-distribution"><i class="fa fa-check"></i><b>2.2.1</b> Point mass distribution</a></li>
<li class="chapter" data-level="2.2.2" data-path="discrete-models.html"><a href="discrete-models.html#uniform-distribution"><i class="fa fa-check"></i><b>2.2.2</b> Uniform distribution</a></li>
<li class="chapter" data-level="2.2.3" data-path="discrete-models.html"><a href="discrete-models.html#bernoulli-distribution"><i class="fa fa-check"></i><b>2.2.3</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="2.2.4" data-path="discrete-models.html"><a href="discrete-models.html#binomial-distribution"><i class="fa fa-check"></i><b>2.2.4</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.2.5" data-path="discrete-models.html"><a href="discrete-models.html#geometric-distribution"><i class="fa fa-check"></i><b>2.2.5</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.2.6" data-path="discrete-models.html"><a href="discrete-models.html#negative-binomial"><i class="fa fa-check"></i><b>2.2.6</b> Negative binomial</a></li>
<li class="chapter" data-level="2.2.7" data-path="discrete-models.html"><a href="discrete-models.html#poisson-distribution"><i class="fa fa-check"></i><b>2.2.7</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="continuous-models.html"><a href="continuous-models.html"><i class="fa fa-check"></i><b>2.3</b> Continuous models</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="continuous-models.html"><a href="continuous-models.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>2.3.1</b> Continuous uniform distribution</a></li>
<li class="chapter" data-level="2.3.2" data-path="continuous-models.html"><a href="continuous-models.html#exponential-distribution"><i class="fa fa-check"></i><b>2.3.2</b> Exponential distribution</a></li>
<li class="chapter" data-level="2.3.3" data-path="continuous-models.html"><a href="continuous-models.html#gamma-distribution"><i class="fa fa-check"></i><b>2.3.3</b> Gamma distribution</a></li>
<li class="chapter" data-level="2.3.4" data-path="continuous-models.html"><a href="continuous-models.html#beta-distribution"><i class="fa fa-check"></i><b>2.3.4</b> Beta distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>2.4</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="normal-distribution.html"><a href="normal-distribution.html#location-parameter"><i class="fa fa-check"></i><b>2.4.1</b> Location parameter</a></li>
<li class="chapter" data-level="2.4.2" data-path="normal-distribution.html"><a href="normal-distribution.html#scale-parameter"><i class="fa fa-check"></i><b>2.4.2</b> Scale parameter</a></li>
<li class="chapter" data-level="2.4.3" data-path="normal-distribution.html"><a href="normal-distribution.html#linear-transformations-of-normal-random-variables"><i class="fa fa-check"></i><b>2.4.3</b> Linear transformations of normal random variables</a></li>
<li class="chapter" data-level="2.4.4" data-path="normal-distribution.html"><a href="normal-distribution.html#the-normal-cdf"><i class="fa fa-check"></i><b>2.4.4</b> The normal cdf</a></li>
<li class="chapter" data-level="2.4.5" data-path="normal-distribution.html"><a href="normal-distribution.html#rule"><i class="fa fa-check"></i><b>2.4.5</b> 68–95–99.7 Rule</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="some-relationships.html"><a href="some-relationships.html"><i class="fa fa-check"></i><b>2.5</b> Some relationships</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="some-relationships.html"><a href="some-relationships.html#poisson-binomial-relationship"><i class="fa fa-check"></i><b>2.5.1</b> Poisson-Binomial relationship</a></li>
<li class="chapter" data-level="2.5.2" data-path="some-relationships.html"><a href="some-relationships.html#poisson-exponential"><i class="fa fa-check"></i><b>2.5.2</b> Poisson-Exponential</a></li>
<li class="chapter" data-level="2.5.3" data-path="some-relationships.html"><a href="some-relationships.html#poisson-gamma"><i class="fa fa-check"></i><b>2.5.3</b> Poisson-Gamma</a></li>
<li class="chapter" data-level="2.5.4" data-path="some-relationships.html"><a href="some-relationships.html#normal-approximations"><i class="fa fa-check"></i><b>2.5.4</b> Normal approximations</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>2.6</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html#hand-in-questions-1"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html"><i class="fa fa-check"></i><b>3</b> Inequalities, convergences, and normal random samples</a>
<ul>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#learning-objectives-2"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="inequalities-convergences-and-normal-random-samples.html"><a href="inequalities-convergences-and-normal-random-samples.html#readings-2"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="3.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-1.html"><a href="introduction-1.html#random-sampling"><i class="fa fa-check"></i><b>3.1.1</b> Random sampling</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction-1.html"><a href="introduction-1.html#independent-and-identical-r.v."><i class="fa fa-check"></i><b>3.1.2</b> Independent and identical r.v.</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction-1.html"><a href="introduction-1.html#statistic"><i class="fa fa-check"></i><b>3.1.3</b> Statistic</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction-1.html"><a href="introduction-1.html#sampling-distribution"><i class="fa fa-check"></i><b>3.1.4</b> Sampling distribution</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction-1.html"><a href="introduction-1.html#large-sample-approximation"><i class="fa fa-check"></i><b>3.1.5</b> Large-sample approximation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>3.2</b> Inequalities</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="inequalities.html"><a href="inequalities.html#markovs-inequality"><i class="fa fa-check"></i><b>3.2.1</b> Markov’s inequality</a></li>
<li class="chapter" data-level="3.2.2" data-path="inequalities.html"><a href="inequalities.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>3.2.2</b> Chebyshev’s inequality</a></li>
<li class="chapter" data-level="3.2.3" data-path="inequalities.html"><a href="inequalities.html#cauchy-schwartz-inequality"><i class="fa fa-check"></i><b>3.2.3</b> Cauchy-Schwartz inequality</a></li>
<li class="chapter" data-level="3.2.4" data-path="inequalities.html"><a href="inequalities.html#jensens-inequality"><i class="fa fa-check"></i><b>3.2.4</b> Jensen’s inequality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html"><i class="fa fa-check"></i><b>3.3</b> Convergence of random variables</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.3.1</b> Convergence in probability</a></li>
<li class="chapter" data-level="3.3.2" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.3.2</b> Convergence in distribution</a></li>
<li class="chapter" data-level="3.3.3" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#mean-square-convergence"><i class="fa fa-check"></i><b>3.3.3</b> Mean-square convergence</a></li>
<li class="chapter" data-level="3.3.4" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#relationship-between-convergences"><i class="fa fa-check"></i><b>3.3.4</b> Relationship between convergences</a></li>
<li class="chapter" data-level="3.3.5" data-path="convergence-of-random-variables.html"><a href="convergence-of-random-variables.html#slutzkys-theorem"><i class="fa fa-check"></i><b>3.3.5</b> Slutzky’s Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>3.4</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="limit-theorems.html"><a href="limit-theorems.html#the-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>3.4.1</b> The (weak) Law of Large Numbers</a></li>
<li class="chapter" data-level="3.4.2" data-path="limit-theorems.html"><a href="limit-theorems.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.4.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="3.4.3" data-path="limit-theorems.html"><a href="limit-theorems.html#gauging-the-error-of-sample-mean-estimator"><i class="fa fa-check"></i><b>3.4.3</b> Gauging the error of sample mean estimator</a></li>
<li class="chapter" data-level="3.4.4" data-path="limit-theorems.html"><a href="limit-theorems.html#clt-with-sigma2-unknown"><i class="fa fa-check"></i><b>3.4.4</b> CLT with <span class="math inline">\(\sigma^2\)</span> unknown</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="delta-method.html"><a href="delta-method.html"><i class="fa fa-check"></i><b>3.5</b> Delta method</a></li>
<li class="chapter" data-level="3.6" data-path="normal-random-samples.html"><a href="normal-random-samples.html"><i class="fa fa-check"></i><b>3.6</b> Normal random samples</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="normal-random-samples.html"><a href="normal-random-samples.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6.1</b> <span class="math inline">\(\chi^2\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.2" data-path="normal-random-samples.html"><a href="normal-random-samples.html#students-t-distribution"><i class="fa fa-check"></i><b>3.6.2</b> Student’s <span class="math inline">\(t\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.3" data-path="normal-random-samples.html"><a href="normal-random-samples.html#proof-of-theorem-refthmpropertynormalsamp"><i class="fa fa-check"></i><b>3.6.3</b> Proof of Theorem @ref(thm:propertynormalsamp)</a></li>
<li class="chapter" data-level="3.6.4" data-path="normal-random-samples.html"><a href="normal-random-samples.html#f-distribution"><i class="fa fa-check"></i><b>3.6.4</b> <span class="math inline">\(F\)</span>-distribution</a></li>
<li class="chapter" data-level="3.6.5" data-path="normal-random-samples.html"><a href="normal-random-samples.html#the-analysis-of-variance"><i class="fa fa-check"></i><b>3.6.5</b> The analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-2.html"><a href="exercises-2.html#hand-in-questions-2"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Inference</b></span></li>
<li class="chapter" data-level="4" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>4</b> Point estimation</a>
<ul>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#learning-objectives-3"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="point-estimation.html"><a href="point-estimation.html#readings-3"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="4.1" data-path="the-likelihood.html"><a href="the-likelihood.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="the-likelihood.html"><a href="the-likelihood.html#calculating-the-likelihood"><i class="fa fa-check"></i><b>4.1.1</b> Calculating the likelihood</a></li>
<li class="chapter" data-level="4.1.2" data-path="the-likelihood.html"><a href="the-likelihood.html#likelihood-ratio"><i class="fa fa-check"></i><b>4.1.2</b> Likelihood ratio</a></li>
<li class="chapter" data-level="4.1.3" data-path="the-likelihood.html"><a href="the-likelihood.html#log-likelihood"><i class="fa fa-check"></i><b>4.1.3</b> Log likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sufficiency.html"><a href="sufficiency.html"><i class="fa fa-check"></i><b>4.2</b> Sufficiency</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sufficiency.html"><a href="sufficiency.html#the-factorisation-theorem"><i class="fa fa-check"></i><b>4.2.1</b> The factorisation theorem</a></li>
<li class="chapter" data-level="4.2.2" data-path="sufficiency.html"><a href="sufficiency.html#minimal-sufficient-statistic"><i class="fa fa-check"></i><b>4.2.2</b> Minimal sufficient statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="point-estimators.html"><a href="point-estimators.html"><i class="fa fa-check"></i><b>4.3</b> Point estimators</a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>4.4</b> Method of moments</a></li>
<li class="chapter" data-level="4.5" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>4.5</b> Method of maximum likelihood</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#finding-the-mle"><i class="fa fa-check"></i><b>4.5.1</b> Finding the MLE</a></li>
<li class="chapter" data-level="4.5.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html#invariance-of-mle"><i class="fa fa-check"></i><b>4.5.2</b> Invariance of MLE</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html"><i class="fa fa-check"></i><b>4.6</b> Evaluating estimators</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#bias"><i class="fa fa-check"></i><b>4.6.1</b> Bias</a></li>
<li class="chapter" data-level="4.6.2" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#variance-and-standard-error"><i class="fa fa-check"></i><b>4.6.2</b> Variance and standard error</a></li>
<li class="chapter" data-level="4.6.3" data-path="evaluating-estimators.html"><a href="evaluating-estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>4.6.3</b> Mean squared error</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html"><i class="fa fa-check"></i><b>4.7</b> Cramér-Rao lower bound (CRLB)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#fisher-information"><i class="fa fa-check"></i><b>4.7.1</b> Fisher information</a></li>
<li class="chapter" data-level="4.7.2" data-path="cramér-rao-lower-bound-crlb.html"><a href="cramér-rao-lower-bound-crlb.html#variance-reduction-rao-blackwellisation"><i class="fa fa-check"></i><b>4.7.2</b> Variance reduction: Rao-Blackwellisation</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html"><i class="fa fa-check"></i><b>4.8</b> Large sample properties of estimators</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency"><i class="fa fa-check"></i><b>4.8.1</b> Consistency</a></li>
<li class="chapter" data-level="4.8.2" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-vs-unbiasedness"><i class="fa fa-check"></i><b>4.8.2</b> Consistency vs unbiasedness</a></li>
<li class="chapter" data-level="4.8.3" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#consistency-of-mles"><i class="fa fa-check"></i><b>4.8.3</b> Consistency of MLEs</a></li>
<li class="chapter" data-level="4.8.4" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency"><i class="fa fa-check"></i><b>4.8.4</b> Efficiency</a></li>
<li class="chapter" data-level="4.8.5" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#asymptotic-normality-and-consistency"><i class="fa fa-check"></i><b>4.8.5</b> Asymptotic normality and consistency</a></li>
<li class="chapter" data-level="4.8.6" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-mle"><i class="fa fa-check"></i><b>4.8.6</b> Efficiency of MLE</a></li>
<li class="chapter" data-level="4.8.7" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#efficiency-of-transformations-of-mle"><i class="fa fa-check"></i><b>4.8.7</b> Efficiency of transformations of MLE</a></li>
<li class="chapter" data-level="4.8.8" data-path="large-sample-properties-of-estimators.html"><a href="large-sample-properties-of-estimators.html#application-of-asymptotic-normality"><i class="fa fa-check"></i><b>4.8.8</b> Application of asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>4.9</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-3.html"><a href="exercises-3.html#hand-in-questions-3"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-objectives-4"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#readings-4"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="5.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-2.html"><a href="introduction-2.html#a-general-paradigm"><i class="fa fa-check"></i><b>5.1.1</b> A general paradigm</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-2.html"><a href="introduction-2.html#p-values"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-2.html"><a href="introduction-2.html#accept-h_0"><i class="fa fa-check"></i><b>5.1.3</b> Accept <span class="math inline">\(H_0\)</span>?</a></li>
<li class="chapter" data-level="5.1.4" data-path="introduction-2.html"><a href="introduction-2.html#uniformity-of-p-values"><i class="fa fa-check"></i><b>5.1.4</b> Uniformity of <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>5.2</b> Likelihood ratio test</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#log-likelihood-ratio-test-statistic"><i class="fa fa-check"></i><b>5.2.1</b> Log likelihood ratio test statistic</a></li>
<li class="chapter" data-level="5.2.2" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-known-variance"><i class="fa fa-check"></i><b>5.2.2</b> Example: Normal with known variance</a></li>
<li class="chapter" data-level="5.2.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html#example-normal-with-unknown-variance-t-test"><i class="fa fa-check"></i><b>5.2.3</b> Example: Normal with unknown variance (<span class="math inline">\(t\)</span>-test)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html"><i class="fa fa-check"></i><b>5.3</b> The Neyman-Pearson approach</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#performance-of-a-test"><i class="fa fa-check"></i><b>5.3.1</b> Performance of a test</a></li>
<li class="chapter" data-level="5.3.2" data-path="the-neyman-pearson-approach.html"><a href="the-neyman-pearson-approach.html#relation-to-p-values"><i class="fa fa-check"></i><b>5.3.2</b> Relation to <span class="math inline">\(p\)</span>-values</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html"><i class="fa fa-check"></i><b>5.4</b> Type I and II errors</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#minimising-errors"><i class="fa fa-check"></i><b>5.4.1</b> Minimising errors</a></li>
<li class="chapter" data-level="5.4.2" data-path="type-i-and-ii-errors.html"><a href="type-i-and-ii-errors.html#optimality-of-the-lr-test"><i class="fa fa-check"></i><b>5.4.2</b> Optimality of the LR test</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sided-tests.html"><a href="one-sided-tests.html"><i class="fa fa-check"></i><b>5.5</b> One-sided tests</a></li>
<li class="chapter" data-level="5.6" data-path="approximate-tests.html"><a href="approximate-tests.html"><i class="fa fa-check"></i><b>5.6</b> Approximate tests</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="approximate-tests.html"><a href="approximate-tests.html#asymptotic-distribution-of-lrts"><i class="fa fa-check"></i><b>5.6.1</b> Asymptotic distribution of LRTs</a></li>
<li class="chapter" data-level="5.6.2" data-path="approximate-tests.html"><a href="approximate-tests.html#wilks-theorem"><i class="fa fa-check"></i><b>5.6.2</b> Wilk’s theorem</a></li>
<li class="chapter" data-level="5.6.3" data-path="approximate-tests.html"><a href="approximate-tests.html#the-wald-test"><i class="fa fa-check"></i><b>5.6.3</b> The Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-4.html"><a href="exercises-4.html#hand-in-questions-4"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>6</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#learning-objectives-5"><i class="fa fa-check"></i>Learning objectives</a></li>
<li class="chapter" data-level="" data-path="interval-estimation.html"><a href="interval-estimation.html#readings-5"><i class="fa fa-check"></i>Readings</a></li>
<li class="chapter" data-level="6.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-3.html"><a href="introduction-3.html#coverage-probability"><i class="fa fa-check"></i><b>6.1.1</b> Coverage probability</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-3.html"><a href="introduction-3.html#confidence-regions"><i class="fa fa-check"></i><b>6.1.2</b> Confidence regions</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-3.html"><a href="introduction-3.html#methods-for-obtaining-confidence-regions"><i class="fa fa-check"></i><b>6.1.3</b> Methods for obtaining confidence regions</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pivots.html"><a href="pivots.html"><i class="fa fa-check"></i><b>6.2</b> Pivots</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pivots.html"><a href="pivots.html#from-pivot-to-confidence-interval"><i class="fa fa-check"></i><b>6.2.1</b> From pivot to confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Inverting a test statistic</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="inverting-a-test-statistic.html"><a href="inverting-a-test-statistic.html#discrete-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Discrete distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="desirable-confidence-sets.html"><a href="desirable-confidence-sets.html"><i class="fa fa-check"></i><b>6.4</b> Desirable confidence sets</a></li>
<li class="chapter" data-level="6.5" data-path="intervals-based-on-ml-methods.html"><a href="intervals-based-on-ml-methods.html"><i class="fa fa-check"></i><b>6.5</b> Intervals based on ML methods</a></li>
<li class="chapter" data-level="6.6" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>6.6</b> The bootstrap method</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#empirical-distribution"><i class="fa fa-check"></i><b>6.6.1</b> Empirical distribution</a></li>
<li class="chapter" data-level="6.6.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-variance-estimation"><i class="fa fa-check"></i><b>6.6.2</b> Bootstrap variance estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap confidence intervals</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#normal-bootstrap-interval"><i class="fa fa-check"></i><b>6.7.1</b> Normal bootstrap interval</a></li>
<li class="chapter" data-level="6.7.2" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-percentile-interval"><i class="fa fa-check"></i><b>6.7.2</b> Bootstrap percentile interval</a></li>
<li class="chapter" data-level="6.7.3" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#bootstrap-pivotal-interval"><i class="fa fa-check"></i><b>6.7.3</b> Bootstrap pivotal interval</a></li>
<li class="chapter" data-level="6.7.4" data-path="bootstrap-confidence-intervals.html"><a href="bootstrap-confidence-intervals.html#which-one-to-use"><i class="fa fa-check"></i><b>6.7.4</b> Which one to use?</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>6.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="exercises-5.html"><a href="exercises-5.html#hand-in-questions-5"><i class="fa fa-check"></i>Hand-in questions</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="exam-tips.html"><a href="exam-tips.html"><i class="fa fa-check"></i><b>A</b> Exam tips</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SM-4331 Advanced Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="axiomatic-probability" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Axiomatic probability</h2>
<p>In principle, we can understand and easily grasp the notion of probability as the “frequency of an event occurring”.
But how do we operationalise this concept? That is, by what rules and mechanisms are we allowed to assign probabilities to events?
If we can overcome this task and are able to assign probabilities to (random) events in an experiment, then we can start to analyse them statistically!</p>
<div id="probability-as-a-measure" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Probability as a measure</h3>
<p>Let us take a measure-theoretic approach to defining probabilities.
We will dive straight into the rigors of definitions before providing a somewhat apologetic rationale as to why such mathematical difficulties are required for probability theory.</p>
<p>As the name implies, measure theory is the theory about how we measure things (duh!).
Measure itself is a fundamental concept in mathematics, and it would be useful to come up with a mathematical framework for how we deal with everyday concepts like length, mass, area, volume, and so on.
Importantly, such a framework allow us to reliably measure in even higher dimensions or onto more abstract constructs not yet imaginable.</p>
<p>Intuitively, a measure is simply a function whose input is the thing we want to measure (let’s call it a set), and whose output is a non-negative number.
Don’t worry, a formal definition will follow, but for now, call this function <span class="math inline">\(\mu\)</span>.
It would be fair to expect a measure <span class="math inline">\(\mu\)</span> to satisfy</p>
<ul>
<li><span class="math inline">\(A \subseteq B \Rightarrow \mu(A) \leq \mu(B)\)</span></li>
<li><span class="math inline">\(A \subseteq B \Rightarrow \mu(B-A)= \mu(B) - \mu(A)\)</span></li>
<li>If <span class="math inline">\(\{A_1,A_2,\dots\}\)</span> are mutually exclusive sets (disjoint), then <span class="math inline">\(\mu\left(\cup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty \mu(A_i)\)</span></li>
</ul>
<p>The first property simply says that if <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(B\)</span>, then the measure of <span class="math inline">\(A\)</span> is at most the measure of <span class="math inline">\(B\)</span>.
The second property follows this up by saying that the measure of the set <span class="math inline">\(B-A\)</span>, that is, the set that is obtained by starting with <span class="math inline">\(B\)</span> and taking away the parts that is contained in <span class="math inline">\(A\)</span>, then the measure of this created set is the difference between the measures of <span class="math inline">\(B\)</span> and <span class="math inline">\(A\)</span>.
Finally, the third property, also known as <em>countable additivity</em>, simply states that the measure of the whole is equal to the sum of the parts.
It turns out that the first and second properties follow from the third (and the fact that a measure cannot be negative)–see Definition <a href="axiomatic-probability.html#def:measure">1.2</a>.</p>
<p>So we have this intuition about what the measure should be, but what about the stuff we want to measure?
For our purposes, we are interested in measuring subsets of <span class="math inline">\(\Omega\)</span>.
We ask, are we able to measure all possible subsets of <span class="math inline">\(\Omega\)</span>?
At a glance, perhaps if <span class="math inline">\(\Omega\)</span> is countable (e.g. <span class="math inline">\(\Omega=\{1,2,3\}\)</span>), it is easy to describe the subsets of <span class="math inline">\(\Omega\)</span> through the power set<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> <span class="math inline">\({\mathcal P}(\Omega)\)</span>, which is the set of all possible subsets of <span class="math inline">\(\Omega\)</span>, but what about when <span class="math inline">\(\Omega\)</span> is uncountable (e.g. an interval <span class="math inline">\(\Omega=[0,1]\in\mathbb{R}\)</span>).
Given a sample space <span class="math inline">\(\Omega\)</span>, we need to define the largest possible collection of subsets of <span class="math inline">\(\Omega\)</span> that can be observed and on which we can assign valid measure.</p>
<div class="definition">
<p><span id="def:sigmaalgebra" class="definition"><strong>Definition 1.1  (\(\sigma\)-algebra) </strong></span>A collection <span class="math inline">\({\mathcal F}\)</span> of subsets of a set <span class="math inline">\(\Omega\)</span> is called a <strong><span class="math inline">\(\sigma\)</span>-algebra</strong> if it satisfies the following conditions:</p>
<ol style="list-style-type: lower-roman">
<li>If <span class="math inline">\(A \in {\mathcal F}\)</span>, then <span class="math inline">\(A^c \in cF\)</span> <em>[closed under complementation]</em>.</li>
<li>If <span class="math inline">\(A_1,A_2,\cdots \in {\mathcal F}\)</span>, then <span class="math inline">\(\cup_{i=1}^\infty A_i \in {\mathcal F}\)</span> <em>[closed under countable unions]</em>.</li>
<li><span class="math inline">\(\{\} \in {\mathcal F}\)</span> <em>[contains the empty set]</em>.</li>
</ol>
</div>
<p>As a remark, condition iii. can be replaced with <span class="math inline">\(\Omega\in{\mathcal F}\)</span> by virtue of condition i..
The <span class="math inline">\(\sigma\)</span>-algebra is a collection of events or subsets of the sample space <span class="math inline">\(\Omega\)</span>, including <span class="math inline">\(\Omega\)</span> itself and the empty set <span class="math inline">\(\{\}\)</span>, which is closed under countable applications of set operations.
This is because DeMorgan’s Law allows us to write the countable union property in iii. also as <em>countable intersections</em>: If <span class="math inline">\(A_1,A_2,\cdots \in {\mathcal F}\)</span>, then by i. <span class="math inline">\(A_1^c,A_2^c,\cdots \in {\mathcal F}\)</span>, and hence <span class="math inline">\(\cup_{i=1}^\infty A_i\in{\mathcal F}\)</span> and also its complement. By DeMorgan’s Law,
<span class="math display">\[
\left( \cup_{i=1}^\infty A_i^c \right)^c = \cap_{i=1}^\infty A_i.
\]</span></p>
<p>Sets contained in <span class="math inline">\({\mathcal F}\)</span> are called <strong>measurable sets</strong>.</p>
<div class="mynote">
<p>The <span class="math inline">\(\sigma\)</span>-algebra is an important condition for measure to not breakdown, because it helps draw a line as to which subsets of the sample space is measurable, and which is not.
Out of interest, condition iii. in Definition <a href="axiomatic-probability.html#def:sigmaalgebra">1.1</a> is the condition that makes <span class="math inline">\({\mathcal F}\)</span> a <span class="math inline">\(\sigma\)</span>-algebra (the <span class="math inline">\(\sigma\)</span> stands for countable <u><strong>s</strong></u>um).
Without this condition, one ends up with just an <em>algebra</em> of sets, one that is most likely <em>too small</em>, failing to contain sets that we would like assign a measure.</p>
</div>
<p>Let’s take a look at some examples of <span class="math inline">\(\sigma\)</span>-algebras.</p>
<div class="example">
<p><span id="exm:unlabeled-div-5" class="example"><strong>Example 1.5  </strong></span><br></p>
<ol style="list-style-type: decimal">
<li><p>The trivial <span class="math inline">\(\sigma\)</span>-algebra: <span class="math display">\[\big\{ \{\}, \Omega \big\}.\]</span> This corresponds the case of no information.</p></li>
<li><p>The power set of the sample space <span class="math inline">\(\Omega\)</span>: <span class="math display">\[\big\{ A | A \subseteq \Omega \big\}.\]</span> This corresponds the case of full information.</p></li>
<li><p>The collection <span class="math inline">\(\big\{ \{\}, A, A^c, \Omega \big\}\)</span> is a <span class="math inline">\(\sigma\)</span>-algebra, for any <span class="math inline">\(A\subseteq \Omega\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\Omega = \{a,b,c,d\}\)</span>. A possible<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> <span class="math inline">\(\sigma\)</span>-algebra is <span class="math display">\[\big\{\{\}, \{a,b,c,d\}, \{a,b\}, \{c,d\} \big\}.\]</span></p></li>
<li><p>Define <span class="math inline">\(B(s)\)</span> to be a square of side length <span class="math inline">\(s\)</span>. Let <span class="math inline">\(\Omega\)</span> be the collection of points in <span class="math inline">\((0,1)\times(0,1)\subset \mathbb{R}^2\)</span> contained within the a unit square <span class="math inline">\(B(1)\)</span>. Then <span class="math display">\[{\mathcal F}=\{ \text{Collection of points contained in the square } B(s) \text{ with } s \in (0,1) \}.\]</span> It should be clear there are uncountably many such squares that can be fit within the unit square.</p></li>
</ol>
</div>
<p>Just as a remark, most introduction to probability measure will deal with finite or countable sets when introducing <span class="math inline">\(\sigma\)</span>-algebras, giving readers an impression that it’s only possible to define <span class="math inline">\(\sigma\)</span>-algebras on such sets. The fifth example above gives an example of a <span class="math inline">\(\sigma\)</span>-algebra which is uncountable.</p>
<p>The twin <span class="math inline">\((\Omega,{\mathcal F})\)</span> is called a <em>measurable space</em>. This sort of defines the “parts” of our problem which are measurable, as per Definition <a href="axiomatic-probability.html#def:sigmaalgebra">1.1</a>. What’s missing is a measure, i.e. the thing that actually tells us ‘how long a piece of string is’, so to speak<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. We now define a measure as follows.</p>
<div class="definition">
<p><span id="def:measure" class="definition"><strong>Definition 1.2  (Measure) </strong></span>A <em>measure</em> <span class="math inline">\(\mu\)</span> is a non-negative real valued function defined on a <span class="math inline">\(\sigma\)</span>-algebra, i.e. <span class="math inline">\(\mu:{\mathcal F}\to\mathbb{R}_{\geq 0}\)</span>, where <span class="math inline">\(\mathbb{R}_{\geq 0}\)</span> are the non-negative real numbers and <span class="math inline">\({\mathcal F}\)</span> a <span class="math inline">\(\sigma\)</span>-algebra of subsets of <span class="math inline">\(\Omega\)</span>. The measure <span class="math inline">\(\mu\)</span> satisfies the following properties:</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(\mu(\{\})=0\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is countably additive, i.e. if <span class="math inline">\(A_1,A_2,\dots\)</span> are disjoint events, then <span class="math display">\[\mu\left( \cup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty \mu(A_i).\]</span></li>
</ol>
</div>
<p>If, in addition the measure of the entire sample space is normalised (i.e. <span class="math inline">\(\mu(\Omega)=1\)</span>), then <span class="math inline">\(\mu\)</span> is called a <strong>probability measure</strong>. We will see this in the next section.</p>
<p>The triplet <span class="math inline">\((\Omega,{\mathcal F},\mu)\)</span> is called a <em>measure space</em> (note that without the measure it is called a measurable space).
This space simply tells us the parts needed for well-defined measure to take place on the subsets of <span class="math inline">\(\Omega\)</span>.</p>
<!-- ![Andrey Nikolaevich Kolmogorov. 25 April 1903 -- 20 October 1987.](figure/kolmogorov.jpg) -->
<!-- ::: {.remark} -->
<!-- See Defn 1.2.1 in C&B and the following examples, as well as §1.9 in Wasserman. -->
<!-- ::: -->
<!-- ::: {.remark} -->
<!-- There are alternative formulations/approaches to defining probabilities, e.g. Cox's Theorem (logical probabilities). -->
<!-- ::: -->
<div class="example">
<p><span id="exm:unlabeled-div-6" class="example"><strong>Example 1.6  </strong></span><br></p>
<ol style="list-style-type: decimal">
<li><p>The counting measure. Let <span class="math inline">\(\Omega\)</span> be a countable set [You may be creative as you like here to make this less abstract, e.g. the books on your shelf or the members of your family, although the set need not be finite]. Let <span class="math inline">\({\mathcal F}={\mathcal P}(\Omega)\)</span> be the power set of <span class="math inline">\(\Omega\)</span>. For all sets <span class="math inline">\(A\in{\mathcal A}\)</span>, define <span class="math display">\[\mu(A) = \begin{cases} |A| &amp; A \text{ has finitely many elements}\\ \infty &amp;\text{otherwise} \end{cases}\]</span> where the operator <span class="math inline">\(|\cdot|\)</span> represents the <em>cardinality</em> of the set, i.e. the number of elements it contains (its size).</p></li>
<li><p>The Lebesgue measure in one dimension. Let <span class="math inline">\(\Omega=\mathbb{R}\)</span>, and define <span class="math inline">\({\mathcal F}\)</span> to contain all sets of the form</p>
<ul>
<li>[a,b], i.e. closed intervals,</li>
<li>(a,b), i.e. open intervals,</li>
<li>(a,b], i.e. open-closed intervals; and</li>
<li>[a,b), i.e. closed-open intervals.</li>
</ul>
<p>for all real numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. We can deduce that the <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\({\mathcal F}\)</span> contains all possible “nice” intervals of the real line, including unbounded intervals and even singletons, which means any continuous partition of the real line can be measured (including a point, which should have measure zero). To see this, using the properties of <span class="math inline">\(\sigma\)</span>-algebras,</p>
<ul>
<li><p>unbounded intervals are in <span class="math inline">\({\mathcal F}\)</span>, since, for instance <span class="math display">\[(x,+\infty)=\cup_{i=1}^\infty(x,x+i).\]</span></p></li>
<li><p>singletons are in <span class="math inline">\({\mathcal F}\)</span>, since <span class="math display">\[\{x\}=\cap_{i=1}^\infty (x-1/i,x+1/i).\]</span></p></li>
</ul>
<p>This set <span class="math inline">\({\mathcal F}\)</span> has a special name, called the Borel <span class="math inline">\(\sigma\)</span>-algebra.</p>
<p>All that’s left is to define the measure. The Lebesgue measure <span class="math inline">\(\mu\)</span> assigns the usual concept of length to any continuous interval on <span class="math inline">\(\mathbb{R}\)</span> (to be precise, the Borel <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span>): <span class="math display">\[\mu\left(A\right)=b-a\]</span>
where <span class="math inline">\(A\)</span> is any interval of <span class="math inline">\(\mathbb{R}\)</span> of the above forms (closed, open, open-closed, closed-open). This measure works even for singleton sets or unbounded intervals.</p></li>
</ol>
</div>
</div>
<div id="axioms-of-probability" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Axioms of probability</h3>
<p><span class="math inline">\(\mathbb{P}:{\mathcal B}\to[0,1]\)</span> is a <strong>probability measure</strong> on <span class="math inline">\((\Omega, {\mathcal B})\)</span> if it satisfies the the following three axioms:</p>
<ul>
<li>Axiom 1: <span class="math inline">\(\mathbb{P}(A) \geq 0, \forall A \in \Omega\)</span>.</li>
<li>Axiom 2: <span class="math inline">\(\mathbb{P}(\Omega) = 1\)</span>.</li>
<li>Axiom 3: For pairwise disjoint events <span class="math inline">\(A_1,A_2,\dots\)</span>,
<span class="math display">\[
\mathbb{P}\bigg( \bigcup_{i=1}^\infty A_i  \bigg) = \sum_{i=1}^\infty A_i.
\]</span></li>
</ul>
<div class="remark">
<p><span id="unlabeled-div-7" class="remark"><em>Remark</em>. </span>There are two main interpretation of probabilities.</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>frequentist</strong> interpretation is that if we flip the coin many times, then the proportion of heads that is observed will be 50% in the long run.</p></li>
<li><p>The <strong>subjectivist</strong> interpretation is that the probability measures an observer’s strength of belief that the event is true.</p></li>
</ol>
<p>In either interpretation, the three axioms must be satisfied.</p>
</div>
</div>
<div id="derived-probability-results" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Derived probability results</h3>
<p>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be measurable events from the sample space <span class="math inline">\(\Omega\)</span>.
The following results can be derived using only the three axioms:</p>
<ul>
<li><span class="math inline">\(\mathbb{P}(\{ \}) = 0\)</span></li>
<li><span class="math inline">\(0\leq\mathbb{P}(A)\leq 1\)</span></li>
<li><span class="math inline">\(\mathbb{P}(A^c)=1-\mathbb{P}(A)\)</span></li>
<li><span class="math inline">\(\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)\)</span></li>
<li>If <span class="math inline">\(A \subseteq B\)</span>, then <span class="math inline">\(\mathbb{P}(A) \leq \mathbb{P}(B)\)</span></li>
<li><span class="math inline">\(\mathbb{P}(A) = \sum_{i=1}^\infty \mathbb{P}(A \cap C_i)\)</span> for any partition <span class="math inline">\(C_1,C_2,\dots\)</span> of <span class="math inline">\(\Omega\)</span> (<em>Law of Total Probability</em>)</li>
</ul>
</div>
<div id="why-measure-theory" class="section level3" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Why measure theory?</h3>
<p>Consider the uniform distribution on a random variable <span class="math inline">\(X\)</span> on the unit interval, denoted <span class="math inline">\(X\sim\mathop{\mathrm{Unif}}(0,1)\)</span>. You may have come across this before, and know that the probability that <span class="math inline">\(X\)</span> lies in any interval contained in <span class="math inline">\([0,1]\)</span> is simply the length of the interval, i.e.
<span class="math display" id="eq:meas1">\[\begin{equation}
\mathbb{P}\big([a,b]\big) = \mathbb{P}\big([a,b)\big) = \mathbb{P}\big((a,b]\big) = \mathbb{P}\big((a,b)\big) = b-a, \tag{1.1}
\end{equation}\]</span>
for <span class="math inline">\(0 \leq a \leq b \leq 1\)</span>. This definition works fine for the degenerate case <span class="math inline">\(\mathbb{P}(\{a\})=0\)</span> for the singleton set <span class="math inline">\(\{a|a\in(0,1)\}\)</span>.
In general, if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are disjoint subsets of <span class="math inline">\([0,1]\)</span> then
<span class="math display">\[\begin{equation}
\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B),
\end{equation}\]</span>
and we can even extend this notion to that of <em>countable additivity</em>
<span class="math display" id="eq:meas2">\[\begin{equation}
\mathbb{P}\left( \cup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty \mathbb{P}(A_i), \tag{1.2}
\end{equation}\]</span>
for disjoint sets <span class="math inline">\(\{A_1,A_2,\dots\}\)</span><a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.</p>
<p>For a uniform measure on <span class="math inline">\([0,1]\)</span>, one expects that the measure of some subset <span class="math inline">\(A \subseteq [0,1]\)</span> to be unaffected by “shifting” (with wrap-around) of that subset by some fixed amount <span class="math inline">\(r\in[0,1]\)</span>.
Define the <em><span class="math inline">\(r\)</span>-shift</em> of <span class="math inline">\(A\subseteq [0,1]\)</span> by
<span class="math display">\[
A \oplus r := \left\{ a + r \mid a \in A, a+r \leq 1 \right\} \cup \left\{ a + r - 1 \mid a \in A, a+r &gt; 1 \right\}.
\]</span>
Then we should have
<span class="math display" id="eq:meas3">\[\begin{equation}
\mathbb{P}(A \oplus r) = \mathbb{P}(A). \tag{1.3}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wraparoundmeasureanim"></span>
<img src="bookdown-adv-stats_files/figure-html/wraparoundmeasureanim-1.gif" alt="An interval in [0,1] shifted by some fixed amount, with wrap-around, should have consistent length." width="100%" />
<p class="caption">
Figure 1.1: An interval in [0,1] shifted by some fixed amount, with wrap-around, should have consistent length.
</p>
</div>
<p>At this point you might notice that all of this resonates with the previous example on the Lebesgue measure, except perhaps the shifting part, and indeed that is the case.
Suppose that we dispense with measure theory and do not define things like the <span class="math inline">\(\sigma\)</span>-algebra on the <span class="math inline">\([0,1]\)</span> or the triplet <span class="math inline">\((\Omega,{\mathcal F},\mathbb{P})\)</span>, and only use the above probability definitions given in <a href="axiomatic-probability.html#eq:meas1">(1.1)</a>, <a href="axiomatic-probability.html#eq:meas2">(1.2)</a>, and <a href="axiomatic-probability.html#eq:meas3">(1.3)</a>.
How far can we push the boundaries of such probability definitions before things start to breakdown?</p>
<p>Consider these questions:</p>
<ul>
<li>What is the probability that <span class="math inline">\(X\)</span> is rational?</li>
<li>What is the probability that <span class="math inline">\(X^n\)</span> is rational for some positive integer <span class="math inline">\(n\)</span>?</li>
<li>What is the probability that <span class="math inline">\(X\)</span> is <em>algebraic</em><a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>?</li>
</ul>
<p>All seemingly fair and interesting questions, but are they well defined? Can we actually measure them and assign probabilities to such events? Taking a step back further, we ask:</p>
<blockquote>
<p>Are all possible subsets <span class="math inline">\(A\subseteq [0,1]\)</span> measurable? Does <span class="math inline">\(\mathbb{P}(A)\)</span> even make <em>sense</em> for any event <span class="math inline">\(A\)</span> we can think of?</p>
</blockquote>
<p>It turns out the answer is no, and can be proven by contradiction with the help of equivalence relations.
You may skip this part if you wish, but I’ll try to keep the technicalities to a minimum (or at least provide some helpful intuition where needed).
This shows the need for the heavy machinery that is measure theory for assigning probabilities to events<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>.</p>
<!-- Before we go there, there's one helpful property of measures that we should expect it to have (at least, when considering lengths of intervals such as in the uniform distribution above): *translation invariance*. -->
<!-- What we mean by this is that the measure of a set should remain unchanged even if it is subjected to fixed amount of "shift". -->
<!-- In particular, this is reflected in a more general form of the uniform distribution on an interval $(c,d)$, where -->
<!-- \begin{equation} -->
<!-- \bbP([a,b]) = \frac{b-a}{d-c} = \Pr\big(Y\in[a,b] \big\mid Y\sim\Unif(c,d)\big), (\#eq:uniformshift) -->
<!-- \end{equation} -->
<!-- for $c\leq a\leq b\leq d$.  -->
<!-- If our random variable $X\sim\Unif(0,1)$ is shifted by some amount $k\in\bbR$, then the values of $c$ and $d$ in \@ref(eq:uniformshift) are $c=r$ and $d=1+r$, whence  -->
<!-- $$ -->
<!-- \Pr\big(Y\in[a,b]  \big\mid Y\sim\Unif(r,1+r)\big) = b-a = \Pr\big(X\in[a,b]  \big\mid X\sim\Unif(0,1)\big). -->
<!-- $$ -->
<div class="proposition">
<p><span id="prp:unlabeled-div-8" class="proposition"><strong>Proposition 1.1  </strong></span>There does not exist a definition of <span class="math inline">\(\mathbb{P}(A)\)</span>, defined for all subsets <span class="math inline">\(A\subseteq[0,1]\)</span>, satisfying <a href="axiomatic-probability.html#eq:meas1">(1.1)</a>, <a href="axiomatic-probability.html#eq:meas2">(1.2)</a>, and <a href="axiomatic-probability.html#eq:meas3">(1.3)</a>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-9" class="proof"><em>Proof</em>. </span>All we need to show is the existence of one such subset of <span class="math inline">\([0,1]\)</span> whose measure is undefined. The set we are about to construct is called the Vitali set<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>, after Giuseppe Vitali who described it in 1905.</p>
<p>Define an equivalence relation on <span class="math inline">\([0,1]\)</span> by the following:
<span class="math display">\[x\sim y \Rightarrow x-y \in \mathbb{Q}\]</span>
That is, two real numbers <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are deemed to be the same if their difference is a rational number. We would like to separate all the real numbers between 0 and 1 inclusive by this equivalence relation, and collect them into groups called equivalence classes. For instance, the numbers 0 and 0.5 will be in the same category, since their difference is rational, but the numbers 0.5 and <span class="math inline">\(\pi^{-1}\)</span> would be in separate categories. There will be infinitely many such equivalence classes, but we’re not concerned so much about how many there are, <em>except</em> that they are countable.</p>
<p>Construct the Vitali set <span class="math inline">\(V\)</span> as follows: Take precisely one element from each equivalent class, and put it in <span class="math inline">\(V\)</span>. As a remark, such a <span class="math inline">\(V\)</span> must surely exist by the Axiom of Choice<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>.</p>
<p>Consider now the union of shifted Vitali sets by some value rational value <span class="math inline">\(r\in[0,1]\)</span>,
<span class="math display">\[
\bigcup_{r} (V \oplus r)
\]</span>
As a reminder, the set of rational numbers is countably infinite<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>. We make a few observations:</p>
<ul>
<li><p>The equivalence relation partitions the interval <span class="math inline">\([0,1]\)</span> into a disjoint union of equivalence classes. In other words, the sets <span class="math inline">\((V \oplus r)\)</span> and <span class="math inline">\((V \oplus s)\)</span> are disjoint for any rationals <span class="math inline">\(r\neq s\)</span>, such that <span class="math inline">\(r,s\in[0,1]\)</span>. If they were not disjoint, this would mean that there exists some <span class="math inline">\(x,y\in[0,1]\)</span> with <span class="math inline">\(x+r\in(V \oplus r)\)</span> and <span class="math inline">\(y+s\in (V \oplus s)\)</span> such that <span class="math inline">\(x+r=y+s\)</span>. But then this means that <span class="math inline">\(x-y=s-r\in\mathbb{Q}\)</span> so <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are in the same equivalent class, and this is a contradiction.</p></li>
<li><p>Every point in <span class="math inline">\([0,1]\)</span> is contained in the union <span class="math inline">\(\bigcup_{r} (V \oplus r)\)</span>. This is because each <span class="math inline">\(x\in [0,1]\)</span> belongs to one equivalence class, and is subsequently shifted by some rational value <span class="math inline">\(r\)</span> in the corresponding Vitali set <span class="math inline">\((V \oplus r)\)</span>. Therefore, <span class="math display">\[[0,1] \subseteq  \bigcup_{r} (V \oplus r).\]</span> and we may write <span class="math display">\[1 = \mathbb{P}([0,1]) \leq \mathbb{P}\left(\bigcup_{r} (V \oplus r)\right),\]</span> since the measure of any set contained in another must have smaller measure: <span class="math inline">\(A \subseteq B \Rightarrow \mu(A) \leq \mu(B)\)</span>.</p></li>
<li><p>The disjoint union <span class="math inline">\(\bigcup_{r} (V \oplus r)\)</span> has probability measure (according to our definitions in <a href="axiomatic-probability.html#eq:meas1">(1.1)</a>, <a href="axiomatic-probability.html#eq:meas2">(1.2)</a>, and <a href="axiomatic-probability.html#eq:meas3">(1.3)</a>)
<span class="math display">\[\begin{align*}
 \mathbb{P}\left(\bigcup_{r} (V \oplus r)\right) 
 &amp;= \sum_r \mathbb{P}(V \oplus r) \\
 &amp;= \sum_r \mathbb{P}(V)
 \end{align*}\]</span></p></li>
</ul>
<p>Putting these three observations together gives us
<span class="math display">\[
1 = \mathbb{P}\left(\bigcup_{r} (V \oplus r)\right)  = \sum_r \mathbb{P}(V).
\]</span>
This leads to the desired contradiction: A countably infinite sum of the same quantity repeated can only equal 0, <span class="math inline">\(+\infty\)</span>, or <span class="math inline">\(-\infty\)</span>, but it can never equal 1.</p>
</div>
<p>In summary,</p>
<ul>
<li>Not all subsets of uncountable sets are measurable. Admitting all subsets of uncountable sets will break mathematics.</li>
<li><span class="math inline">\(\sigma\)</span>-algebras are the patch that fixes mathematics. It gatekeeps the subsets of uncountable sets and disregards those which are not measurable.</li>
<li>Actually, if you have been following along, you might realise that we are at risk of breaking mathematics when dealing with uncountable sets. Strictly speaking, we only need <span class="math inline">\(\sigma\)</span>-algebras when working in a set with uncountable cardinality.</li>
</ul>
<p>Finally, what on earth is an “unmeasurable” set? Wouldn’t it be (even arbitrarily) possible to just define a measure for whatever set we can think of? If the above example hasn’t convinced you enough, some other mathematicians have tried to resolve this but it seems it is not possible to do so without encountering paradoxes, such as the one below.</p>
<blockquote>
<p>The Banach–Tarski paradox states that a ball in the ordinary Euclidean space can be doubled using only the operations of partitioning into subsets, replacing a set with a congruent set, and reassembly.</p>
</blockquote>
<p><img src="figure/banach_tarski.png" /></p>
<p>To be clear, no rule of mathematics are broken in the Banach-Tarski paradox, but the result defies intuition. Another statement of this paradox is that <em>we can chop up a pea into finitely many pieces and reassemble it into the sun</em> (pea-sun paradox). If we don’t lay out the foundations for measuring probabilities rigorously, we can end up with nonsensical answers!</p>
<p>This section was highly inspired by the following references:</p>
<ul>
<li>Rosenthal, J. (2006). A first look at rigorous probability.</li>
<li>The discussion here: <a href="https://stats.stackexchange.com/q/199280" class="uri">https://stats.stackexchange.com/q/199280</a></li>
<li>This YouTube video on Vitali Sets: <a href="https://youtu.be/ameugr-wjeI" class="uri">https://youtu.be/ameugr-wjeI</a></li>
</ul>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>For the example at hand, the power set is <span class="math inline">\({\mathcal P}(\Omega)=\{ \{\}, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\}, \{1,2,3\} \}\)</span><a href="axiomatic-probability.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>You may notice that other <span class="math inline">\(\sigma\)</span>-algebras are indeed possible, e.g. the power set of <span class="math inline">\(\Omega\)</span> in this case. There is a notion of the <em>smallest</em> <span class="math inline">\(\sigma\)</span>-algebra containing the collection of “basic events”. Luckily for us, the event space that we will usually be working with will be the smallest <span class="math inline">\(\sigma\)</span>-algebra without much technicalities, so we shall not explore this concept any further.<a href="axiomatic-probability.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p><a href="https://idioms.thefreedictionary.com/How+long+is+a+piece+of+string%3F" class="uri">https://idioms.thefreedictionary.com/How+long+is+a+piece+of+string%3F</a><a href="axiomatic-probability.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>A concrete example of this is for the sets <span class="math inline">\(A_1=(0,1/2)\)</span>, <span class="math inline">\(A_2=(1/2, 3/4)\)</span>, <span class="math inline">\(A_3=(3/4,7/8)\)</span>, and so on (adding half the interval at each iteration). One finds that the measure of the countable union is <span class="math inline">\(\sum_{i=1}^\infty (1/2)^i=1\)</span>.<a href="axiomatic-probability.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>An algebraic number is a number that is a root of a non-zero polynomial in one variable with integer coefficients.<a href="axiomatic-probability.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Or at least, for cases where “not so nice” events need to be measured.<a href="axiomatic-probability.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p><a href="https://en.wikipedia.org/wiki/Vitali_set" class="uri">https://en.wikipedia.org/wiki/Vitali_set</a><a href="axiomatic-probability.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Given a collection of some countably many non-empty sets, it is always possible to construct a new set by taking one element from each set in the original collection. See <a href="https://brilliant.org/wiki/axiom-of-choice/" class="uri">https://brilliant.org/wiki/axiom-of-choice/</a><a href="axiomatic-probability.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p><a href="https://www.homeschoolmath.net/teaching/rational-numbers-countable.php" class="uri">https://www.homeschoolmath.net/teaching/rational-numbers-countable.php</a><a href="axiomatic-probability.html#fnref15" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="elementary-set-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conditional-probabilities.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/haziqj/adv-stats/edit/main/02-prob_theory.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-adv-stats.pdf", "bookdown-adv-stats.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
